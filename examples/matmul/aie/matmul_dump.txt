// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After AutoInputConversionPipeline (iree-auto-input-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After IREEImportPublic (iree-import-public) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After ImportMLProgram (iree-import-ml-program) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After SanitizeModuleNames (iree-sanitize-module-names) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::ConvertStreamableOpsPass (iree-abi-convert-streamable-ops) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::ABI::WrapEntryPointsPass (iree-abi-wrap-entry-points) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1] -> (s0 ceildiv s1)>
#map1 = affine_map<()[s0, s1] -> (s0 * s1)>
#map2 = affine_map<(d0)[s0, s1] -> (-d0 + s1, s0)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
    %c0 = arith.constant 0 : index
    %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
    %c1 = arith.constant 1 : index
    %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%dim, %workgroup_count_0]
      %3 = affine.apply #map1()[%workgroup_id_0, %2]
      %4 = affine.apply #map1()[%workgroup_id_0, %2]
      %5 = affine.min #map2(%3)[%2, %dim]
      %6 = affine.min #map2(%4)[%2, %dim_0]
      %extracted_slice = tensor.extract_slice %arg0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %0[%3, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %6 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%4, %5, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %6 into %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
    %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %3 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %4 = affine.min #map1()[%dim, %workgroup_id_0, %workgroup_count_0]
      %5 = affine.min #map2()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %arg0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %6 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%4, %5, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %6 into %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %6 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%4, %5, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %6 into %0[%2, %3] [%4, %5] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
    %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %3 = affine.min #map1()[%dim, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min #map2()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After DemoteF64ToF32 (iree-util-demote-f64-to-f32) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
    %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %3 = affine.min #map1()[%dim, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min #map2()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After RemoveZeroExtentTensors (iree-flow-remove-zero-extent-tensors) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After RemoveZeroExtentTensors (iree-flow-remove-zero-extent-tensors) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After DetachElementwiseFromNamedOps (iree-flow-detach-elementwise-from-named-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After DetachElementwiseFromNamedOps (iree-flow-detach-elementwise-from-named-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After LinalgNamedOpConversion (linalg-named-op-conversion) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After LinalgNamedOpConversion (linalg-named-op-conversion) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After Convert1X1FilterConv2DToMatmul (iree-flow-convert-1x1-filter-conv2d-to-matmul) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After Convert1X1FilterConv2DToMatmul (iree-flow-convert-1x1-filter-conv2d-to-matmul) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After EraseUnusedLinalgOperands (iree-flow-erase-unused-linalg-operands) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
    %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
    %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %2 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %3 = affine.min #map1()[%dim, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min #map2()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg2: index) -> (index, index, index) {
      flow.return %arg2, %c1, %c1 : index, index, index
    }
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After TopLevelSCFToCFG (iree-top-level-scf-to-cfg) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: tensor<?x?xf32>) -> tensor<?x?xf32> {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %arg0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %arg0, %c1 : tensor<?x?xf32>
  %0 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %1 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %2 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %arg0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %arg1[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %5 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %5 into %0[%2, %2] [%3, %4] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg2: index) -> (index, index, index) {
    flow.return %arg2, %c1, %c1 : index, index, index
  }
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After TopLevelSCFToCFG (iree-top-level-scf-to-cfg) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %5) : (tensor<?x?xf32>, tensor<?x?xf32>) -> tensor<?x?xf32>
  %dim = tensor.dim %6, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %6, %c1 : tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ExpandTensorShapes (iree-flow-expand-tensor-shapes) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6:3 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> (tensor<?x?xf32>, index, index)
    %7 = flow.tensor.tie_shape %6#0 : tensor<?x?xf32>{%6#1, %6#2}
    %dim = tensor.dim %7, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %7, %c1 : tensor<?x?xf32>
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> (tensor<?x?xf32>, index, index) {
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
    %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
    %2 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %dim, %workgroup_count_0]
      %5 = affine.min #map1()[%dim, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_2 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3, %dim, %dim_0 : tensor<?x?xf32>, index, index
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6:3 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> (tensor<?x?xf32>, index, index)
  %7 = flow.tensor.tie_shape %6#0 : tensor<?x?xf32>{%6#1, %6#2}
  %dim = tensor.dim %7, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %7, %c1 : tensor<?x?xf32>
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%dim, %dim_0} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> (tensor<?x?xf32>, index, index) {
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %c2 = arith.constant 2 : index
  %dim = tensor.dim %0, %c0 : tensor<?x?xf32>
  %dim_0 = tensor.dim %0, %c1 : tensor<?x?xf32>
  %2 = tensor.empty(%dim, %dim_0) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%dim, %dim_0}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %dim, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%dim, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%dim_0, %workgroup_id_0, %dim, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_2 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_1 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_2 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3, %dim, %dim_0 : tensor<?x?xf32>, index, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6:3 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> (tensor<?x?xf32>, index, index)
    %7 = flow.tensor.tie_shape %6#0 : tensor<?x?xf32>{%6#1, %6#2}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%6#1, %6#2} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> (tensor<?x?xf32>, index, index) {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3, %arg1, %arg2 : tensor<?x?xf32>, index, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6:3 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> (tensor<?x?xf32>, index, index)
    %7 = flow.tensor.tie_shape %6#0 : tensor<?x?xf32>{%6#1, %6#2}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%6#1, %6#2} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> (tensor<?x?xf32>, index, index) {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3, %arg1, %arg2 : tensor<?x?xf32>, index, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After JitGlobals (iree-consteval-jit-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index, iree.fixedpoint.modified} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 1 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 1 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 1 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After HoistIntoGlobals (iree-util-hoist-into-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 1 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After JitGlobals (iree-consteval-jit-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 1 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After VerifyInputLegality (iree-verify-input-legality) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After TensorPadToTensorInsertSlice (iree-flow-tensor-pad-to-tensor-insert-slice) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#map1 = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map2 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
    %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %4 = affine.apply #map()[%workgroup_id_0, %arg1, %workgroup_count_0]
      %5 = affine.min #map1()[%arg1, %workgroup_id_0, %workgroup_count_0]
      %6 = affine.min #map2()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
      %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
      %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
      flow.return %inserted_slice : tensor<?x?xf32>
    } count(%arg6: index) -> (index, index, index) {
      flow.return %arg6, %c1, %c1 : index, index, index
    }
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After ConvertElementwiseToLinalg (convert-elementwise-to-linalg) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ConvertElementwiseToLinalg (convert-elementwise-to-linalg) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After GeneralizeLinalgNamedOps (iree-flow-generalize-linalg-named-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After GeneralizeLinalgNamedOps (iree-flow-generalize-linalg-named-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FuseDequantizationMatmul (iree-flow-fuse-dequantization-matmul) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FuseDequantizationMatmul (iree-flow-fuse-dequantization-matmul) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_1 = tensor.extract_slice %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%extracted_slice_1 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %7 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FoldUnitExtentDims (iree-flow-fold-unit-extent-dims) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FoldUnitExtentDims (iree-flow-fold-unit-extent-dims) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After RaiseSpecialOps (iree-flow-raise-special-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CollapseDims (iree-flow-collapse-dims) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CollapseDims (iree-flow-collapse-dims) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FusionOfTensorOps (iree-flow-fusion-of-tensor-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FusionOfTensorOps (iree-flow-fusion-of-tensor-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After SplitReduction (iree-flow-split-reduction-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After SplitReduction (iree-flow-split-reduction-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After InterchangeGenericOps (iree-flow-interchange-generic-ops) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FormScalarDispatches (iree-flow-form-scalar-dispatches) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FormScalarDispatches (iree-flow-form-scalar-dispatches) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FormDispatchRegions (iree-flow-form-dispatch-regions) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchRegions (iree-flow-form-dispatch-regions) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CollapseDimensions (iree-flow-collapse-dimensions) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegions (iree-flow-clone-producers-into-dispatch-regions) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CollapseDimensions (iree-flow-collapse-dimensions) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After FormDispatchWorkgroups (iree-flow-form-dispatch-workgroups) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CaptureDispatchDynamicDims (iree-flow-capture-dispatch-dynamic-dims) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CloneProducersIntoDispatchRegions (iree-flow-clone-producers-into-dispatch-regions) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.region[%c2] -> (tensor<?x?xf32>{%arg1, %arg2}) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg1, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg1, %workgroup_id_0, %workgroup_count_0]
    %6 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg2, %workgroup_id_0, %arg1, %workgroup_count_0]
    %extracted_slice = tensor.extract_slice %0[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %extracted_slice_0 = tensor.extract_slice %1[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> to tensor<?x?xf32>
    %7 = tensor.empty(%5, %6) : tensor<?x?xf32>
    %8 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%extracted_slice, %extracted_slice_0 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%7 : tensor<?x?xf32>) (%5, %6, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %inserted_slice = tensor.insert_slice %8 into %2[%4, %4] [%5, %6] [1, 1] : tensor<?x?xf32> into tensor<?x?xf32>
    flow.return %inserted_slice : tensor<?x?xf32>
  } count(%arg6: index) -> (index, index, index) {
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After FormDispatchWorkgroups (iree-flow-form-dispatch-workgroups) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.workgroups[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2} =
      (%arg6: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg7: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg8: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg9: index, %arg10: index, %arg11: index, %arg12: index) {
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %4 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg9, %workgroup_id_0, %workgroup_count_0]
    %5 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg10, %workgroup_id_0, %arg9, %workgroup_count_0]
    %6 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %7 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %8 = flow.dispatch.tensor.load %arg6, offsets = [%6, %7], sizes = [%4, %5], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10} -> tensor<?x?xf32>
    %9 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %10 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %11 = flow.dispatch.tensor.load %arg7, offsets = [%9, %10], sizes = [%4, %5], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12} -> tensor<?x?xf32>
    %12 = tensor.empty(%4, %5) : tensor<?x?xf32>
    %13 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%8, %11 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%12 : tensor<?x?xf32>) (%4, %5, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %14 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %15 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    flow.dispatch.tensor.store %13, %arg8, offsets = [%14, %15], sizes = [%4, %5], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    flow.return
  } count(%arg6: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After InitializeEmptyTensors (iree-flow-initialize-empty-tensors) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After CaptureDispatchDynamicDims (iree-flow-capture-dispatch-dynamic-dims) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.workgroups[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2} =
      (%arg6: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg7: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg8: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg9: index, %arg10: index, %arg11: index, %arg12: index) {
    %4 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10}
    %5 = flow.dispatch.tie_shape %arg7 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12}
    %6 = flow.dispatch.tie_shape %arg8 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %7 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg9, %workgroup_id_0, %workgroup_count_0]
    %8 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg10, %workgroup_id_0, %arg9, %workgroup_count_0]
    %9 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %10 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %11 = flow.dispatch.tensor.load %4, offsets = [%9, %10], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10} -> tensor<?x?xf32>
    %12 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %13 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %14 = flow.dispatch.tensor.load %5, offsets = [%12, %13], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12} -> tensor<?x?xf32>
    %15 = tensor.empty(%7, %8) : tensor<?x?xf32>
    %16 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%11, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%15 : tensor<?x?xf32>) (%7, %8, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %17 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %18 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    flow.dispatch.tensor.store %16, %6, offsets = [%17, %18], sizes = [%7, %8], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    flow.return
  } count(%arg6: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.workgroups[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2} =
      (%arg6: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg7: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg8: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg9: index, %arg10: index, %arg11: index, %arg12: index) {
    %4 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10}
    %5 = flow.dispatch.tie_shape %arg7 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12}
    %6 = flow.dispatch.tie_shape %arg8 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %7 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg9, %workgroup_id_0, %workgroup_count_0]
    %8 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg10, %workgroup_id_0, %arg9, %workgroup_count_0]
    %9 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %10 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %11 = flow.dispatch.tensor.load %4, offsets = [%9, %10], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10} -> tensor<?x?xf32>
    %12 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %13 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %14 = flow.dispatch.tensor.load %5, offsets = [%12, %13], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12} -> tensor<?x?xf32>
    %15 = tensor.empty(%7, %8) : tensor<?x?xf32>
    %16 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%11, %14 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%15 : tensor<?x?xf32>) (%7, %8, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    %17 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %18 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    flow.dispatch.tensor.store %16, %6, offsets = [%17, %18], sizes = [%7, %8], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    flow.return
  } count(%arg6: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = tensor.empty(%arg1, %arg2) : tensor<?x?xf32>
  %3 = flow.dispatch.workgroups[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2} =
      (%arg6: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg7: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg8: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg9: index, %arg10: index, %arg11: index, %arg12: index) {
    %4 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10}
    %5 = flow.dispatch.tie_shape %arg7 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12}
    %6 = flow.dispatch.tie_shape %arg8 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %7 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg9, %workgroup_id_0, %workgroup_count_0]
    %8 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg10, %workgroup_id_0, %arg9, %workgroup_count_0]
    %9 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %10 = flow.dispatch.tensor.load %4, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10} -> tensor<?x?xf32>
    %11 = flow.dispatch.tensor.load %5, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12} -> tensor<?x?xf32>
    %12 = tensor.empty(%7, %8) : tensor<?x?xf32>
    %13 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%10, %11 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%12 : tensor<?x?xf32>) (%7, %8, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %13, %6, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    flow.return
  } count(%arg6: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After InitializeEmptyTensors (iree-flow-initialize-empty-tensors) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %3 = flow.dispatch.workgroups[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2} =
      (%arg6: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg7: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg8: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg9: index, %arg10: index, %arg11: index, %arg12: index) {
    %4 = flow.dispatch.tie_shape %arg6 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10}
    %5 = flow.dispatch.tie_shape %arg7 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12}
    %6 = flow.dispatch.tie_shape %arg8 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
    %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
    %7 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg9, %workgroup_id_0, %workgroup_count_0]
    %8 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg10, %workgroup_id_0, %arg9, %workgroup_count_0]
    %9 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg9, %workgroup_count_0]
    %10 = flow.dispatch.tensor.load %4, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg9, %arg10} -> tensor<?x?xf32>
    %11 = flow.dispatch.tensor.load %5, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg11, %arg12} -> tensor<?x?xf32>
    %12 = tensor.empty(%7, %8) : tensor<?x?xf32>
    %13 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%10, %11 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%12 : tensor<?x?xf32>) (%7, %8, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %13, %6, offsets = [%9, %9], sizes = [%7, %8], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg9, %arg10}
    flow.return
  } count(%arg6: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg6, %c1, %c1 : index, index, index
  }
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After OutlineDispatchRegions (iree-flow-outline-dispatch-regions) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %3 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2}
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After StripDebugOps (iree-util-strip-debug-ops) //----- //
flow.executable private @_matmul_aie_offload_dispatch_0 {
  flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
      %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
      %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
      %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg3, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
      %5 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg3, %workgroup_count_0]
      %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
      %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
      %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
      %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
  %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %8 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
  %2 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %3 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2}
  return %3 : tensor<?x?xf32>
}

// -----// IR Dump After DeduplicateExecutables (iree-flow-deduplicate-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = flow.tensor.tie_shape %6 : tensor<?x?xf32>{%0, %1}
    %8 = hal.tensor.export %7 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %8 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.tie_shape %arg0 : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.tensor.tie_shape %arg3 : tensor<?x?xf32>{%arg4, %arg5}
    %2 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %3 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%0, %1, %2, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %2{%arg1, %arg2}
    return %3 : tensor<?x?xf32>
  }
}


// -----// IR Dump After CleanupTensorShapes (iree-flow-cleanup-tensor-shapes) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CleanupTensorShapes (iree-flow-cleanup-tensor-shapes) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
flow.executable private @_matmul_aie_offload_dispatch_0 {
  flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
      %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
      %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
      %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg3, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
      %5 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg3, %workgroup_count_0]
      %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
      %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
      %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
      %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
flow.executable private @_matmul_aie_offload_dispatch_0 {
  flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    flow.return %arg0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
      %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
      %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
      %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg3, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
      %5 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg3, %workgroup_count_0]
      %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
      %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
      %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
      %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After VerifyInput (iree-stream-verify-input) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After OutlineConstants (iree-util-outline-constants) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
  %c2 = arith.constant 2 : index
  %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
  %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
  return %1 : tensor<?x?xf32>
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
  %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
  %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
  %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
  return %7 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %2 = hal.tensor.import %arg0 "input 0" : !hal.buffer_view -> tensor<?x?xf32>{%0, %1}
    %3 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %5 = hal.tensor.import %arg1 "input 1" : !hal.buffer_view -> tensor<?x?xf32>{%3, %4}
    %6 = call @_matmul_aie_offload(%2, %0, %1, %5, %3, %4) : (tensor<?x?xf32>, index, index, tensor<?x?xf32>, index, index) -> tensor<?x?xf32>
    %7 = hal.tensor.export %6 "output 0" : tensor<?x?xf32>{%0, %1} -> !hal.buffer_view
    return %7 : !hal.buffer_view
  }
  flow.executable private @_matmul_aie_offload_dispatch_0 {
    flow.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      flow.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg1: !flow.dispatch.tensor<readonly:tensor<?x?xf32>>, %arg2: !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %0 = flow.dispatch.tie_shape %arg0 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = flow.dispatch.tie_shape %arg1 : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = flow.dispatch.tie_shape %arg2 : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: tensor<?x?xf32>, %arg1: index, %arg2: index, %arg3: tensor<?x?xf32>, %arg4: index, %arg5: index) -> tensor<?x?xf32> {
    %c2 = arith.constant 2 : index
    %0 = flow.tensor.empty : tensor<?x?xf32>{%arg1, %arg2}
    %1 = flow.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0, %arg3, %0, %arg1, %arg2, %arg4, %arg5) : (tensor<?x?xf32>{%arg1, %arg2}, tensor<?x?xf32>{%arg4, %arg5}, tensor<?x?xf32>{%arg1, %arg2}, index, index, index, index) -> %0{%arg1, %arg2}
    return %1 : tensor<?x?xf32>
  }
}


// -----// IR Dump After ConvertToStream (iree-stream-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %c553648160_i32_0 = arith.constant 553648160 : i32
    %c1_i32_1 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32_0) encoding(%c1_i32_1)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = builtin.unrealized_conversion_cast %10#0, %10#1 : !stream.resource<*>, index to tensor<?x?xf32>
    %12 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %c0 = arith.constant 0 : index
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After VerifyLoweringToTensors (iree-stream-verify-lowering-to-tensors) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    %c553648160_i32_0 = arith.constant 553648160 : i32
    %c1_i32_1 = arith.constant 1 : i32
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32_0) encoding(%c1_i32_1)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = builtin.unrealized_conversion_cast %10#0, %10#1 : !stream.resource<*>, index to tensor<?x?xf32>
    %12 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %c0 = arith.constant 0 : index
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
  %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
  %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
  %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
  %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
  %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
  return %1, %0 : !stream.resource<*>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
  %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
  %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
  %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
  %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
  %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
  %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
  %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
  %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
  %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
  %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
  return %1, %0 : !stream.resource<*>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
  %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
  %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
  return %1, %0 : !stream.resource<*>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = stream.tensor.sizeof tensor<?x?xf32>{%0, %1} : index
    %3 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%2}
    %4 = stream.async.transfer %3 : !stream.resource<external>{%2} -> !stream.resource<*>{%2}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = stream.tensor.sizeof tensor<?x?xf32>{%5, %6} : index
    %8 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%7}
    %9 = stream.async.transfer %8 : !stream.resource<external>{%7} -> !stream.resource<*>{%7}
    %10:2 = call @_matmul_aie_offload(%4, %2, %0, %1, %9, %7, %5, %6) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %11 = stream.async.transfer %10#0 : !stream.resource<*>{%10#1} -> !stream.resource<external>{%10#1}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = stream.tensor.sizeof tensor<?x?xf32>{%arg2, %arg3} : index
    %empty = stream.tensor.empty : tensor<?x?xf32>{%arg2, %arg3} in !stream.resource<*>{%0}
    %1 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %empty[%c0 to %0 for %0], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%0}, index, index, index, index) -> %empty{%0}
    return %1, %0 : !stream.resource<*>, index
  }
}


// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After EncodeHostTensors (iree-stream-encode-host-tensors) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After EncodeDeviceTensors (iree-stream-encode-device-tensors) //----- //
stream.executable private @_matmul_aie_offload_dispatch_0 {
  stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
    %c1 = arith.constant 1 : index
    stream.return %arg0, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
      %c0 = arith.constant 0 : index
      %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
      %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
      %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
      %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
      %3 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%arg3, %workgroup_id_0, %workgroup_count_0]
      %4 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
      %5 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_0, %arg3, %workgroup_count_0]
      %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
      %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
      %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
      %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
      return
    }
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
    %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<*>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<*>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
    %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<*>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<*>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
    %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<*>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<*>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
    %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<*>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<*>, index
  }
}


// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After MaterializeCopyOnWrite (iree-stream-materialize-copy-on-write) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After ElideAsyncCopies (iree-stream-elide-async-copies) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
    %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
    %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<*>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<*>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<*>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<*>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<*>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<*>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<*>{%arg1}, !stream.resource<*>{%arg5}, !stream.resource<*>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<*>, index
}

// -----// IR Dump After EmplaceAllocations (iree-stream-emplace-allocations) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = stream.async.transfer %4 : !stream.resource<external>{%3} -> !stream.resource<*>{%3}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11 = stream.async.transfer %10 : !stream.resource<external>{%9} -> !stream.resource<*>{%9}
  %12:2 = call @_matmul_aie_offload(%5, %3, %0, %1, %11, %9, %6, %7) : (!stream.resource<*>, index, index, index, !stream.resource<*>, index, index, index) -> (!stream.resource<*>, index)
  %13 = stream.async.transfer %12#0 : !stream.resource<*>{%12#1} -> !stream.resource<external>{%12#1}
  %14 = stream.tensor.export %13 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#1} -> !hal.buffer_view
  return %14 : !hal.buffer_view
}

// -----// IR Dump After RefineUsage (iree-stream-refine-usage) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
  %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<external>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
  %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
  %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<external>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.async.alloca : !stream.resource<external>{%1}
  %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
  return %3, %1 : !stream.resource<external>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After VerifyAsyncAccessRanges (iree-stream-verify-async-access-ranges) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
    %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
    return %11 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.async.alloca : !stream.resource<external>{%1}
    %3 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg0[%c0 to %arg1 for %arg1], %arg4[%c0 to %arg5 for %arg5], %2[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %2{%1}
    return %3, %1 : !stream.resource<external>, index
  }
}


// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
  %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:2 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.resource<external>, index)
  %11 = stream.tensor.export %10#0 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#1} -> !hal.buffer_view
  return %11 : !hal.buffer_view
}

// -----// IR Dump After ScheduleExecution (iree-stream-schedule-execution) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %results, %result_timepoint = stream.async.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}) -> !stream.resource<external>{%1} {
    %3 = stream.async.alloca : !stream.resource<external>{%1}
    %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg8[%c0 to %arg1 for %arg1], %arg9[%c0 to %arg5 for %arg5], %3[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
    stream.yield %4 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  return %2, %1 : !stream.resource<external>, index
}

// -----// IR Dump After ScheduleConcurrency (iree-stream-schedule-concurrency) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.resource<external>, index) {
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %results, %result_timepoint = stream.async.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}) -> !stream.resource<external>{%1} {
    %3 = stream.async.alloca : !stream.resource<external>{%1}
    %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg8[%c0 to %arg1 for %arg1], %arg9[%c0 to %arg5 for %arg5], %3[%c0 to %1 for %1], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
    stream.yield %4 : !stream.resource<external>{%1}
  } => !stream.timepoint
  %2 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%1}
  return %2, %1 : !stream.resource<external>, index
}

// -----// IR Dump After PropagateTimepoints (iree-stream-propagate-timepoints) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10 = stream.timepoint.immediate => !stream.timepoint
    %11 = stream.timepoint.immediate => !stream.timepoint
    %12:3 = call @_matmul_aie_offload(%10, %4, %3, %0, %1, %11, %9, %8, %5, %6) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %13 = stream.resource.size %12#1 : !stream.resource<external>
    %14 = stream.timepoint.await %12#0 => %12#1 : !stream.resource<external>{%13}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#2} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %0 = stream.timepoint.await %arg0 => %arg1 : !stream.resource<external>{%arg2}
    %1 = stream.timepoint.await %arg5 => %arg6 : !stream.resource<external>{%arg7}
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %2 = arith.muli %arg3, %c4 : index
    %3 = arith.muli %2, %arg4 : index
    %4 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%3} {
      %6 = stream.async.alloca : !stream.resource<external>{%3}
      %7 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %6[%c0 to %3 for %3], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%3}, index, index, index, index) -> %6{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    return %result_timepoint, %results, %3 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After MaterializeBuiltins (iree-stream-materialize-builtins) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10 = stream.timepoint.immediate => !stream.timepoint
    %11 = stream.timepoint.immediate => !stream.timepoint
    %12:3 = call @_matmul_aie_offload(%10, %4, %3, %0, %1, %11, %9, %8, %5, %6) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %13 = stream.resource.size %12#1 : !stream.resource<external>
    %14 = stream.timepoint.await %12#0 => %12#1 : !stream.resource<external>{%13}
    %15 = stream.tensor.export %14 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%12#2} -> !hal.buffer_view
    return %15 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %0 = stream.timepoint.await %arg0 => %arg1 : !stream.resource<external>{%arg2}
    %1 = stream.timepoint.await %arg5 => %arg6 : !stream.resource<external>{%arg7}
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %2 = arith.muli %arg3, %c4 : index
    %3 = arith.muli %2, %arg4 : index
    %4 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%3} {
      %6 = stream.async.alloca : !stream.resource<external>{%3}
      %7 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %6[%c0 to %3 for %3], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%3}, index, index, index, index) -> %6{%3}
      stream.yield %7 : !stream.resource<external>{%3}
    } => !stream.timepoint
    %5 = stream.timepoint.await %result_timepoint => %results : !stream.resource<external>{%3}
    return %result_timepoint, %results, %3 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %0 = arith.muli %arg3, %c4 : index
  %1 = arith.muli %0, %arg4 : index
  %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
    %3 = stream.async.alloca : !stream.resource<external>{%1}
    %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
    stream.yield %4 : !stream.resource<external>{%1}
  } => !stream.timepoint
  return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %0 = arith.muli %arg3, %c4 : index
  %1 = arith.muli %0, %arg4 : index
  %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
    %3 = stream.async.alloca : !stream.resource<external>{%1}
    %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
    stream.yield %4 : !stream.resource<external>{%1}
  } => !stream.timepoint
  return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %0 = arith.muli %arg3, %c4 : index
  %1 = arith.muli %0, %arg4 : index
  %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
  %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
    %3 = stream.async.alloca : !stream.resource<external>{%1}
    %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
    stream.yield %4 : !stream.resource<external>{%1}
  } => !stream.timepoint
  return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %0 = arith.muli %arg3, %c4 : index
    %1 = arith.muli %0, %arg4 : index
    %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
      %3 = stream.async.alloca : !stream.resource<external>{%1}
      %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
      stream.yield %4 : !stream.resource<external>{%1}
    } => !stream.timepoint
    return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %0 = arith.muli %arg3, %c4 : index
    %1 = arith.muli %0, %arg4 : index
    %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
      %3 = stream.async.alloca : !stream.resource<external>{%1}
      %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
      stream.yield %4 : !stream.resource<external>{%1}
    } => !stream.timepoint
    return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%0, %5, %4, %1, %2, %0, %10, %9, %6, %7) : (!stream.timepoint, !stream.resource<external>, index, index, index, !stream.timepoint, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.timepoint, %arg1: !stream.resource<external>, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.timepoint, %arg6: !stream.resource<external>, %arg7: index, %arg8: index, %arg9: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %0 = arith.muli %arg3, %c4 : index
    %1 = arith.muli %0, %arg4 : index
    %2 = stream.timepoint.join max(%arg0, %arg5) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%2) => with(%arg1 as %arg10: !stream.resource<external>{%arg2}, %arg6 as %arg11: !stream.resource<external>{%arg7}) -> !stream.resource<external>{%1} {
      %3 = stream.async.alloca : !stream.resource<external>{%1}
      %4 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg10[%c0 to %arg2 for %arg2], %arg11[%c0 to %arg7 for %arg7], %3[%c0 to %1 for %1], %arg3, %arg4, %arg8, %arg9) : (!stream.resource<external>{%arg2}, !stream.resource<external>{%arg7}, !stream.resource<external>{%1}, index, index, index, index) -> %3{%1}
      stream.yield %4 : !stream.resource<external>{%1}
    } => !stream.timepoint
    return %result_timepoint, %results, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %1 = stream.timepoint.immediate => !stream.timepoint
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %2 = arith.muli %arg2, %c4 : index
    %3 = arith.muli %2, %arg3 : index
    %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}) -> !stream.resource<external>{%3} {
      %5 = stream.async.alloca : !stream.resource<external>{%3}
      %6 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg8[%c0 to %arg1 for %arg1], %arg9[%c0 to %arg5 for %arg5], %5[%c0 to %3 for %3], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%3}, index, index, index, index) -> %5{%3}
      stream.yield %6 : !stream.resource<external>{%3}
    } => !stream.timepoint
    return %result_timepoint, %results, %3 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After VerifyLoweringToAsync (iree-stream-verify-lowering-to-async) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %1 = stream.timepoint.immediate => !stream.timepoint
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %2 = arith.muli %arg2, %c4 : index
    %3 = arith.muli %2, %arg3 : index
    %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
    %results, %result_timepoint = stream.async.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}) -> !stream.resource<external>{%3} {
      %5 = stream.async.alloca : !stream.resource<external>{%3}
      %6 = stream.async.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg8[%c0 to %arg1 for %arg1], %arg9[%c0 to %arg5 for %arg5], %5[%c0 to %3 for %3], %arg2, %arg3, %arg6, %arg7) : (!stream.resource<external>{%arg1}, !stream.resource<external>{%arg5}, !stream.resource<external>{%3}, index, index, index, index) -> %5{%3}
      stream.yield %6 : !stream.resource<external>{%3}
    } => !stream.timepoint
    return %result_timepoint, %results, %3 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After ScheduleAllocation (iree-stream-schedule-allocation) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %0 = stream.timepoint.immediate => !stream.timepoint
    %1 = stream.timepoint.immediate => !stream.timepoint
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %2 = arith.muli %arg2, %c4 : index
    %3 = arith.muli %2, %arg3 : index
    %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
    %c0_0 = arith.constant 0 : index
    %5 = stream.resource.alloc uninitialized : !stream.resource<external>{%3}
    %6 = stream.cmd.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %5 as %arg10: !stream.resource<external>{%3}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %3] : !stream.resource<external>{%3}
      }
    } => !stream.timepoint
    return %6, %5, %3 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After PackConstants (iree-stream-pack-constants) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %1 = stream.timepoint.immediate => !stream.timepoint
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %2 = arith.muli %arg2, %c4 : index
  %3 = arith.muli %2, %arg3 : index
  %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
  %c0_0 = arith.constant 0 : index
  %5 = stream.resource.alloc uninitialized : !stream.resource<external>{%3}
  %6 = stream.cmd.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %5 as %arg10: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  return %6, %5, %3 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After PackAllocations (iree-stream-pack-allocations) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %1 = stream.timepoint.immediate => !stream.timepoint
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %2 = arith.muli %arg2, %c4 : index
  %3 = arith.muli %2, %arg3 : index
  %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
  %c0_0 = arith.constant 0 : index
  %5 = stream.resource.alloc uninitialized : !stream.resource<external>{%3}
  %6 = stream.cmd.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %5 as %arg10: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  return %6, %5, %3 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %1 = stream.timepoint.immediate => !stream.timepoint
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %2 = arith.muli %arg2, %c4 : index
  %3 = arith.muli %2, %arg3 : index
  %4 = stream.timepoint.join max(%0, %1) => !stream.timepoint
  %c0_0 = arith.constant 0 : index
  %5 = stream.resource.alloc uninitialized : !stream.resource<external>{%3}
  %6 = stream.cmd.execute await(%4) => with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %5 as %arg10: !stream.resource<external>{%3}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %3] : !stream.resource<external>{%3}
    }
  } => !stream.timepoint
  return %6, %5, %3 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After PackAllocations (iree-stream-pack-allocations) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After LayoutSlices (iree-stream-layout-slices) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %0 = stream.timepoint.immediate => !stream.timepoint
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
  %3 = arith.muli %1, %c4 : index
  %4 = arith.muli %3, %2 : index
  %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
  %11:3 = call @_matmul_aie_offload(%5, %4, %1, %2, %10, %9, %6, %7) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %12 = stream.timepoint.await %11#0 => %11#1 : !stream.resource<external>{%11#2}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#2} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %0 = stream.timepoint.immediate => !stream.timepoint
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %2 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%1, %2]) type(%c553648160_i32) encoding(%c1_i32)
    %3 = arith.muli %1, %c4 : index
    %4 = arith.muli %3, %2 : index
    %5 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%4}
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %7 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%6, %7]) type(%c553648160_i32) encoding(%c1_i32)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%6, %7} in !stream.resource<external>{%9}
    %11:6 = call @_matmul_aie_offload(%5, %4, %c0, %4, %4, %1, %2, %10, %9, %c0, %9, %9, %6, %7) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
    %12 = stream.resource.subview %11#1[%11#3] : !stream.resource<external>{%11#2} -> !stream.resource<external>{%11#4}
    %13 = stream.timepoint.await %11#0 => %12 : !stream.resource<external>{%11#5}
    %14 = stream.tensor.export %13 : tensor<?x?xf32>{%1, %2} in !stream.resource<external>{%11#5} -> !hal.buffer_view
    return %14 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
    %0 = stream.resource.subview %arg0[%arg2] : !stream.resource<external>{%arg1} -> !stream.resource<external>{%arg3}
    %1 = stream.resource.subview %arg7[%arg9] : !stream.resource<external>{%arg8} -> !stream.resource<external>{%arg10}
    %c0 = arith.constant 0 : index
    %2 = stream.timepoint.immediate => !stream.timepoint
    %3 = stream.timepoint.immediate => !stream.timepoint
    %c2 = arith.constant 2 : index
    %c0_0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %4 = arith.muli %arg5, %c4 : index
    %5 = arith.muli %4, %arg6 : index
    %6 = stream.timepoint.join max(%2, %3) => !stream.timepoint
    %c0_1 = arith.constant 0 : index
    %7 = stream.resource.alloc uninitialized : !stream.resource<external>{%5}
    %8 = stream.cmd.execute await(%6) => with(%0 as %arg14: !stream.resource<external>{%arg4}, %1 as %arg15: !stream.resource<external>{%arg11}, %7 as %arg16: !stream.resource<external>{%5}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
        ro %arg14[%c0_0 for %arg4] : !stream.resource<external>{%arg4},
        ro %arg15[%c0_0 for %arg11] : !stream.resource<external>{%arg11},
        rw %arg16[%c0_0 for %5] : !stream.resource<external>{%5}
      }
    } => !stream.timepoint
    return %8, %7, %5, %c0, %5, %5 : !stream.timepoint, !stream.resource<external>, index, index, index, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
  %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
  return %13 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %0 = arith.muli %arg5, %c4 : index
  %1 = arith.muli %0, %arg6 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
      ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
      ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
      rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %0 = arith.muli %arg5, %c4 : index
  %1 = arith.muli %0, %arg6 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
      ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
      ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
      rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %c0 = arith.constant 0 : index
  %0 = arith.muli %arg5, %c4 : index
  %1 = arith.muli %0, %arg6 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
      ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
      ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
      rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %0 = arith.muli %arg5, %c4 : index
    %1 = arith.muli %0, %arg6 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
        ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
        ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
        rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %0 = arith.muli %arg5, %c4 : index
    %1 = arith.muli %0, %arg6 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
        ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
        ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
        rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:6 = call @_matmul_aie_offload(%4, %3, %c0, %3, %3, %0, %1, %9, %8, %c0, %8, %8, %5, %6) : (!stream.resource<external>, index, index, index, index, index, index, !stream.resource<external>, index, index, index, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.resource.subview %11[%10#3] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#4}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#5} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: !stream.resource<external>, %arg8: index, %arg9: index, %arg10: index, %arg11: index, %arg12: index, %arg13: index) -> (!stream.timepoint, !stream.resource<external>, index, index, index, index) {
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %0 = arith.muli %arg5, %c4 : index
    %1 = arith.muli %0, %arg6 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg14: !stream.resource<external>{%arg1}, %arg7 as %arg15: !stream.resource<external>{%arg8}, %2 as %arg16: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg5, %arg6, %arg12, %arg13 : index, index, index, index) {
        ro %arg14[%arg2 for %arg4] : !stream.resource<external>{%arg1},
        ro %arg15[%arg9 for %arg11] : !stream.resource<external>{%arg8},
        rw %arg16[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1, %c0, %1, %1 : !stream.timepoint, !stream.resource<external>, index, index, index, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %c0_0 = arith.constant 0 : index
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.resource.subview %11[%c0_0] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c0_0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0_1 = arith.constant 0 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0_0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0_1 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After VerifyLoweringToCmd (iree-stream-verify-lowering-to-cmd) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %c0_0 = arith.constant 0 : index
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.resource.subview %11[%c0_0] : !stream.resource<external>{%10#2} -> !stream.resource<external>{%10#2}
    %13 = stream.tensor.export %12 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %13 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c0_0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %c0_1 = arith.constant 0 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0_0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0_1 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After ElideTimepoints (iree-stream-elide-timepoints) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4}
        %1 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6}
        %2 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg3, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg4, %workgroup_id_0, %arg3, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg3, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg3, %arg4} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg5, %arg6} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg3, %arg4}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%arg2, %arg3, %arg6, %arg7 : index, index, index, index) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseDispatchBindings (iree-stream-fuse-dispatch-bindings) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: index, %arg8: index, %arg9: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg6, %arg7}
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg8, %arg9}
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg6, %arg7}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg6, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg7, %workgroup_id_0, %arg6, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg6, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg6, %arg7} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg8, %arg9} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg6, %arg7}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %c0_0 = arith.constant 0 : index
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0, %c0, %c0, %arg2, %arg3, %arg6, %arg7 : index, index, index, index, index, index, index) {
        ro %arg8[%c0_0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0_0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After AnnotateDispatchArguments (iree-stream-annotate-dispatch-arguments) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: index {stream.values = [0 : index]}, %arg4: index {stream.values = [0 : index]}, %arg5: index {stream.values = [0 : index]}, %arg6: index, %arg7: index, %arg8: index, %arg9: index) {
        %c0 = arith.constant 0 : index
        %0 = stream.binding.subspan %arg0[%arg3] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg6, %arg7}
        %1 = stream.binding.subspan %arg1[%arg4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg8, %arg9}
        %2 = stream.binding.subspan %arg2[%arg5] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg6, %arg7}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %3 = affine.min #map()[%arg6, %workgroup_id_0, %workgroup_count_0]
        %4 = affine.min #map1()[%arg7, %workgroup_id_0, %arg6, %workgroup_count_0]
        %5 = affine.apply #map2()[%workgroup_id_0, %arg6, %workgroup_count_0]
        %6 = flow.dispatch.tensor.load %0, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg6, %arg7} -> tensor<?x?xf32>
        %7 = flow.dispatch.tensor.load %1, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%arg8, %arg9} -> tensor<?x?xf32>
        %8 = tensor.empty(%3, %4) : tensor<?x?xf32>
        %9 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%6, %7 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%8 : tensor<?x?xf32>) (%3, %4, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %9, %2, offsets = [%5, %5], sizes = [%3, %4], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%arg6, %arg7}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %c0_0 = arith.constant 0 : index
    %3 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0, %c0, %c0, %arg2, %arg3, %arg6, %arg7 : index, index, index, index, index, index, index) {
        ro %arg8[%c0_0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0_0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %3, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After PackDispatchOperands (iree-stream-pack-dispatch-operands) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %c32_i64_0 = arith.constant 32 : i64
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64_0 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %c32_i64_1 = arith.constant 32 : i64
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64_1 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %c32_i64_2 = arith.constant 32 : i64
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64_2 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %c32_i64_3 = arith.constant 32 : i64
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64_3 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %c32_i64_4 = arith.constant 32 : i64
        %25 = arith.extui %arg14 : i32 to i64
        %26 = arith.shli %25, %c32_i64_4 : i64
        %27 = arith.extui %arg13 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %c32_i64_5 = arith.constant 32 : i64
        %30 = arith.extui %arg16 : i32 to i64
        %31 = arith.shli %30, %c32_i64_5 : i64
        %32 = arith.extui %arg15 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %c0 = arith.constant 0 : index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %c0_0 = arith.constant 0 : index
    %c0_i64 = arith.constant 0 : i64
    %c0_i32 = arith.constant 0 : i32
    %c32_i64 = arith.constant 32 : i64
    %c0_i64_1 = arith.constant 0 : i64
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i64_3 = arith.constant 0 : i64
    %c0_i32_4 = arith.constant 0 : i32
    %c32_i64_5 = arith.constant 32 : i64
    %c0_i64_6 = arith.constant 0 : i64
    %c0_i32_7 = arith.constant 0 : i32
    %c0_i64_8 = arith.constant 0 : i64
    %c0_i32_9 = arith.constant 0 : i32
    %c32_i64_10 = arith.constant 32 : i64
    %c0_i64_11 = arith.constant 0 : i64
    %c0_i32_12 = arith.constant 0 : i32
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %c32_i64_13 = arith.constant 32 : i64
    %5 = arith.shrui %3, %c32_i64_13 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %c32_i64_14 = arith.constant 32 : i64
    %9 = arith.shrui %7, %c32_i64_14 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %c32_i64_15 = arith.constant 32 : i64
    %13 = arith.shrui %11, %c32_i64_15 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %c32_i64_16 = arith.constant 32 : i64
    %17 = arith.shrui %15, %c32_i64_16 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32_2, %c0_i32_4, %c0_i32_7, %c0_i32_9, %c0_i32_12, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0_0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0_0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0_0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0_i32 = arith.constant 0 : i32
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25 = arith.extui %arg14 : i32 to i64
        %26 = arith.shli %25, %c32_i64 : i64
        %27 = arith.extui %arg13 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %30 = arith.extui %arg16 : i32 to i64
        %31 = arith.shli %30, %c32_i64 : i64
        %32 = arith.extui %arg15 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25 = arith.extui %arg14 : i32 to i64
        %26 = arith.shli %25, %c32_i64 : i64
        %27 = arith.extui %arg13 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %30 = arith.extui %arg16 : i32 to i64
        %31 = arith.shli %30, %c32_i64 : i64
        %32 = arith.extui %arg15 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25 = arith.extui %arg14 : i32 to i64
        %26 = arith.shli %25, %c32_i64 : i64
        %27 = arith.extui %arg13 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %30 = arith.extui %arg16 : i32 to i64
        %31 = arith.shli %30, %c32_i64 : i64
        %32 = arith.extui %arg15 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32, %arg16: i32) {
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg12 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg11 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25 = arith.extui %arg14 : i32 to i64
        %26 = arith.shli %25, %c32_i64 : i64
        %27 = arith.extui %arg13 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %30 = arith.extui %arg16 : i32 to i64
        %31 = arith.shli %30, %c32_i64 : i64
        %32 = arith.extui %arg15 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %c0_i32, %4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldUniformOperands (iree-stream-fold-uniform-operands) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0_i32 = arith.constant 0 : i32
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %c0_i32 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %c0_i32 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 {stream.values = [0 : index]} : i64 to index
        %5 = arith.extui %c0_i32 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %c0_i32 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 {stream.values = [0 : index]} : i64 to index
        %10 = arith.extui %c0_i32 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %c0_i32 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 {stream.values = [0 : index]} : i64 to index
        %15 = arith.extui %arg4 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg3 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = arith.extui %arg6 : i32 to i64
        %21 = arith.shli %20, %c32_i64 : i64
        %22 = arith.extui %arg5 : i32 to i64
        %23 = arith.ori %22, %21 : i64
        %24 = arith.index_castui %23 : i64 to index
        %25 = arith.extui %arg8 : i32 to i64
        %26 = arith.shli %25, %c32_i64 : i64
        %27 = arith.extui %arg7 : i32 to i64
        %28 = arith.ori %27, %26 : i64
        %29 = arith.index_castui %28 : i64 to index
        %30 = arith.extui %arg10 : i32 to i64
        %31 = arith.shli %30, %c32_i64 : i64
        %32 = arith.extui %arg9 : i32 to i64
        %33 = arith.ori %32, %31 : i64
        %34 = arith.index_castui %33 : i64 to index
        %35 = stream.binding.subspan %arg0[%4] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24}
        %36 = stream.binding.subspan %arg1[%9] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34}
        %37 = stream.binding.subspan %arg2[%14] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %38 = affine.min #map()[%19, %workgroup_id_0, %workgroup_count_0]
        %39 = affine.min #map1()[%24, %workgroup_id_0, %19, %workgroup_count_0]
        %40 = affine.apply #map2()[%workgroup_id_0, %19, %workgroup_count_0]
        %41 = flow.dispatch.tensor.load %35, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%19, %24} -> tensor<?x?xf32>
        %42 = flow.dispatch.tensor.load %36, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%29, %34} -> tensor<?x?xf32>
        %43 = tensor.empty(%38, %39) : tensor<?x?xf32>
        %44 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%41, %42 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%43 : tensor<?x?xf32>) (%38, %39, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %44, %37, offsets = [%40, %40], sizes = [%38, %39], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%19, %24}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0_i32 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CSE (cse) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After CSE (cse) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    }
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::AssignTargetDevicesPass (iree-hal-assign-target-devices) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::VerifyTargetEnvironmentPass (iree-hal-verify-target-environment) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  stream.executable private @_matmul_aie_offload_dispatch_0 {
    stream.executable.export public @_matmul_aie_offload_dispatch_0 workgroups(%arg0: index) -> (index, index, index) {
      %c1 = arith.constant 1 : index
      stream.return %arg0, %c1, %c1 : index, index, index
    }
    builtin.module {
      func.func @_matmul_aie_offload_dispatch_0(%arg0: !stream.binding {stream.alignment = 64 : index}, %arg1: !stream.binding {stream.alignment = 64 : index}, %arg2: !stream.binding {stream.alignment = 64 : index}, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32) {
        %c0 = arith.constant 0 : index
        %c32_i64 = arith.constant 32 : i64
        %0 = arith.extui %arg4 : i32 to i64
        %1 = arith.shli %0, %c32_i64 : i64
        %2 = arith.extui %arg3 : i32 to i64
        %3 = arith.ori %2, %1 : i64
        %4 = arith.index_castui %3 : i64 to index
        %5 = arith.extui %arg6 : i32 to i64
        %6 = arith.shli %5, %c32_i64 : i64
        %7 = arith.extui %arg5 : i32 to i64
        %8 = arith.ori %7, %6 : i64
        %9 = arith.index_castui %8 : i64 to index
        %10 = arith.extui %arg8 : i32 to i64
        %11 = arith.shli %10, %c32_i64 : i64
        %12 = arith.extui %arg7 : i32 to i64
        %13 = arith.ori %12, %11 : i64
        %14 = arith.index_castui %13 : i64 to index
        %15 = arith.extui %arg10 : i32 to i64
        %16 = arith.shli %15, %c32_i64 : i64
        %17 = arith.extui %arg9 : i32 to i64
        %18 = arith.ori %17, %16 : i64
        %19 = arith.index_castui %18 : i64 to index
        %20 = stream.binding.subspan %arg0[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9}
        %21 = stream.binding.subspan %arg1[%c0] : !stream.binding -> !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19}
        %22 = stream.binding.subspan %arg2[%c0] : !stream.binding -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        %workgroup_id_0 = flow.dispatch.workgroup.id[0] : index
        %workgroup_count_0 = flow.dispatch.workgroup.count[0] : index
        %23 = affine.min #map()[%4, %workgroup_id_0, %workgroup_count_0]
        %24 = affine.min #map1()[%9, %workgroup_id_0, %4, %workgroup_count_0]
        %25 = affine.apply #map2()[%workgroup_id_0, %4, %workgroup_count_0]
        %26 = flow.dispatch.tensor.load %20, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%4, %9} -> tensor<?x?xf32>
        %27 = flow.dispatch.tensor.load %21, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%14, %19} -> tensor<?x?xf32>
        %28 = tensor.empty(%23, %24) : tensor<?x?xf32>
        %29 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%26, %27 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%28 : tensor<?x?xf32>) (%23, %24, %workgroup_id_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
        flow.dispatch.tensor.store %29, %22, offsets = [%25, %25], sizes = [%23, %24], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%4, %9}
        return
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      }
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::{anonymous}::MaterializeInterfacesPass (iree-hal-materialize-interfaces) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#map = affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>
#map1 = affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>
#map2 = affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
    %7 = arith.muli %5, %c4 : index
    %8 = arith.muli %7, %6 : index
    %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
    %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
    %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
    %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
    return %12 : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module {
        func.func @_matmul_aie_offload_dispatch_0() {
          %c32_i64 = arith.constant 32 : i64
          %c0 = arith.constant 0 : index
          %0 = hal.interface.constant.load[0] : i32
          %1 = hal.interface.constant.load[1] : i32
          %2 = hal.interface.constant.load[2] : i32
          %3 = hal.interface.constant.load[3] : i32
          %4 = hal.interface.constant.load[4] : i32
          %5 = hal.interface.constant.load[5] : i32
          %6 = hal.interface.constant.load[6] : i32
          %7 = hal.interface.constant.load[7] : i32
          %8 = arith.extui %1 : i32 to i64
          %9 = arith.shli %8, %c32_i64 : i64
          %10 = arith.extui %0 : i32 to i64
          %11 = arith.ori %10, %9 : i64
          %12 = arith.index_castui %11 : i64 to index
          %13 = arith.extui %3 : i32 to i64
          %14 = arith.shli %13, %c32_i64 : i64
          %15 = arith.extui %2 : i32 to i64
          %16 = arith.ori %15, %14 : i64
          %17 = arith.index_castui %16 : i64 to index
          %18 = arith.extui %5 : i32 to i64
          %19 = arith.shli %18, %c32_i64 : i64
          %20 = arith.extui %4 : i32 to i64
          %21 = arith.ori %20, %19 : i64
          %22 = arith.index_castui %21 : i64 to index
          %23 = arith.extui %7 : i32 to i64
          %24 = arith.shli %23, %c32_i64 : i64
          %25 = arith.extui %6 : i32 to i64
          %26 = arith.ori %25, %24 : i64
          %27 = arith.index_castui %26 : i64 to index
          %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
          %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
          %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
          %workgroup_id_x = hal.interface.workgroup.id[0] : index
          %workgroup_count_x = hal.interface.workgroup.count[0] : index
          %31 = affine.min #map()[%12, %workgroup_id_x, %workgroup_count_x]
          %32 = affine.min #map1()[%17, %workgroup_id_x, %12, %workgroup_count_x]
          %33 = affine.apply #map2()[%workgroup_id_x, %12, %workgroup_count_x]
          %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
          %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
          %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
          %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
          flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
          return
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
    %3 = arith.index_castui %arg2 : index to i64
    %4 = arith.trunci %3 : i64 to i32
    %5 = arith.shrui %3, %c32_i64 : i64
    %6 = arith.trunci %5 : i64 to i32
    %7 = arith.index_castui %arg3 : index to i64
    %8 = arith.trunci %7 : i64 to i32
    %9 = arith.shrui %7, %c32_i64 : i64
    %10 = arith.trunci %9 : i64 to i32
    %11 = arith.index_castui %arg6 : index to i64
    %12 = arith.trunci %11 : i64 to i32
    %13 = arith.shrui %11, %c32_i64 : i64
    %14 = arith.trunci %13 : i64 to i32
    %15 = arith.index_castui %arg7 : index to i64
    %16 = arith.trunci %15 : i64 to i32
    %17 = arith.shrui %15, %c32_i64 : i64
    %18 = arith.trunci %17 : i64 to i32
    %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
      stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
        ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
        ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
        rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
      } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>]}
    } => !stream.timepoint
    return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
  }
}


// -----// IR Dump After CPUMaterializeUpperBoundTileSize (iree-cpu-materialize-upper-bound-tile-size) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import %arg0 : !hal.buffer_view -> tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%3}
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %6 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%5, %6]) type(%c553648160_i32) encoding(%c1_i32)
  %7 = arith.muli %5, %c4 : index
  %8 = arith.muli %7, %6 : index
  %9 = stream.tensor.import %arg1 : !hal.buffer_view -> tensor<?x?xf32>{%5, %6} in !stream.resource<external>{%8}
  %10:3 = call @_matmul_aie_offload(%4, %3, %0, %1, %9, %8, %5, %6) : (!stream.resource<external>, index, index, index, !stream.resource<external>, index, index, index) -> (!stream.timepoint, !stream.resource<external>, index)
  %11 = stream.timepoint.await %10#0 => %10#1 : !stream.resource<external>{%10#2}
  %12 = stream.tensor.export %11 : tensor<?x?xf32>{%0, %1} in !stream.resource<external>{%10#2} -> !hal.buffer_view
  return %12 : !hal.buffer_view
}

// -----// IR Dump After CPUMaterializeUpperBoundTileSize (iree-cpu-materialize-upper-bound-tile-size) //----- //
func.func private @_matmul_aie_offload(%arg0: !stream.resource<external>, %arg1: index, %arg2: index, %arg3: index, %arg4: !stream.resource<external>, %arg5: index, %arg6: index, %arg7: index) -> (!stream.timepoint, !stream.resource<external>, index) {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %2 = stream.resource.alloc uninitialized : !stream.resource<external>{%1}
  %3 = arith.index_castui %arg2 : index to i64
  %4 = arith.trunci %3 : i64 to i32
  %5 = arith.shrui %3, %c32_i64 : i64
  %6 = arith.trunci %5 : i64 to i32
  %7 = arith.index_castui %arg3 : index to i64
  %8 = arith.trunci %7 : i64 to i32
  %9 = arith.shrui %7, %c32_i64 : i64
  %10 = arith.trunci %9 : i64 to i32
  %11 = arith.index_castui %arg6 : index to i64
  %12 = arith.trunci %11 : i64 to i32
  %13 = arith.shrui %11, %c32_i64 : i64
  %14 = arith.trunci %13 : i64 to i32
  %15 = arith.index_castui %arg7 : index to i64
  %16 = arith.trunci %15 : i64 to i32
  %17 = arith.shrui %15, %c32_i64 : i64
  %18 = arith.trunci %17 : i64 to i32
  %19 = stream.cmd.execute with(%arg0 as %arg8: !stream.resource<external>{%arg1}, %arg4 as %arg9: !stream.resource<external>{%arg5}, %2 as %arg10: !stream.resource<external>{%1}) {
    stream.cmd.dispatch @_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0[%c2](%4, %6, %8, %10, %12, %14, %16, %18 : i32, i32, i32, i32, i32, i32, i32, i32) {
      ro %arg8[%c0 for %arg1] : !stream.resource<external>{%arg1},
      ro %arg9[%c0 for %arg5] : !stream.resource<external>{%arg5},
      rw %arg10[%c0 for %1] : !stream.resource<external>{%1}
    } attributes {hal.interface.bindings = [#hal.interface.binding<0, 0>, #hal.interface.binding<0, 1>, #hal.interface.binding<0, 2>]}
  } => !stream.timepoint
  return %19, %2, %1 : !stream.timepoint, !stream.resource<external>, index
}

// -----// IR Dump After TypePropagation (iree-codegen-type-propagation) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After BubbleUpOrdinalOps (iree-codegen-bubble-up-ordinal-ops) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After BufferizeCopyOnlyDispatches (iree-codegen-bufferize-copy-only-dispatches) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After DecomposeSoftmax (iree-linalg-ext-decompose-softmax) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After RematerializeParallelOps (iree-codegen-rematerialize-parallel-ops) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After ExpandArithF16ToF32 (iree-llvmcpu-expand-f16-op-to-f32) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After CPUMaterializeEncoding (iree-cpu-materialize-encoding) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRef (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After TileAndDistributeToWorkgroups (iree-codegen-tile-and-distribute-to-workgroups) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
  hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
  ^bb0(%arg0: !hal.device, %arg1: index):
    %c1 = arith.constant 1 : index
    hal.return %arg1, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0() {
      %c32_i64 = arith.constant 32 : i64
      %c0 = arith.constant 0 : index
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = hal.interface.constant.load[4] : i32
      %5 = hal.interface.constant.load[5] : i32
      %6 = hal.interface.constant.load[6] : i32
      %7 = hal.interface.constant.load[7] : i32
      %8 = arith.extui %1 : i32 to i64
      %9 = arith.shli %8, %c32_i64 : i64
      %10 = arith.extui %0 : i32 to i64
      %11 = arith.ori %10, %9 : i64
      %12 = arith.index_castui %11 : i64 to index
      %13 = arith.extui %3 : i32 to i64
      %14 = arith.shli %13, %c32_i64 : i64
      %15 = arith.extui %2 : i32 to i64
      %16 = arith.ori %15, %14 : i64
      %17 = arith.index_castui %16 : i64 to index
      %18 = arith.extui %5 : i32 to i64
      %19 = arith.shli %18, %c32_i64 : i64
      %20 = arith.extui %4 : i32 to i64
      %21 = arith.ori %20, %19 : i64
      %22 = arith.index_castui %21 : i64 to index
      %23 = arith.extui %7 : i32 to i64
      %24 = arith.shli %23, %c32_i64 : i64
      %25 = arith.extui %6 : i32 to i64
      %26 = arith.ori %25, %24 : i64
      %27 = arith.index_castui %26 : i64 to index
      %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
      %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
      %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %31 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
      %32 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
      %33 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
      %34 = flow.dispatch.tensor.load %28, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
      %35 = flow.dispatch.tensor.load %29, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
      %36 = tensor.empty(%31, %32) : tensor<?x?xf32>
      %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%34, %35 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%36 : tensor<?x?xf32>) (%31, %32, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
      flow.dispatch.tensor.store %37, %30, offsets = [%33, %33], sizes = [%31, %32], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
      return
    }
  }
}

// -----// IR Dump After ConvertToDestinationPassingStyle (iree-codegen-convert-to-destination-passing-style) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %31 = arith.extui %0 : i32 to i64
  %32 = arith.extui %1 : i32 to i64
  %33 = arith.shli %32, %c32_i64 : i64
  %34 = arith.ori %31, %33 : i64
  %35 = arith.index_castui %34 : i64 to index
  %36 = arith.extui %2 : i32 to i64
  %37 = arith.extui %3 : i32 to i64
  %38 = arith.shli %37, %c32_i64 : i64
  %39 = arith.ori %36, %38 : i64
  %40 = arith.index_castui %39 : i64 to index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %41 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %35, %workgroup_count_x]
  %42 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%35, %workgroup_id_x, %workgroup_count_x]
  %43 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%40, %workgroup_id_x, %35, %workgroup_count_x]
  %44 = flow.dispatch.tensor.load %30, offsets = [%41, %41], sizes = [%42, %43], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%35, %40} -> tensor<?x?xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %workgroup_count_x_1 = hal.interface.workgroup.count[0] : index
  %45 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x_0, %workgroup_count_x_1]
  %46 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x_0, %12, %workgroup_count_x_1]
  %47 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x_0, %12, %workgroup_count_x_1]
  %48 = flow.dispatch.tensor.load %28, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %49 = flow.dispatch.tensor.load %29, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %50 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%48, %49 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%44 : tensor<?x?xf32>) (%45, %46, %workgroup_id_x_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %50, %30, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After FoldAffineMinInDistributedLoops (iree-codegen-fold-affinemin-in-distributed-loops) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %31 = arith.extui %0 : i32 to i64
  %32 = arith.extui %1 : i32 to i64
  %33 = arith.shli %32, %c32_i64 : i64
  %34 = arith.ori %31, %33 : i64
  %35 = arith.index_castui %34 : i64 to index
  %36 = arith.extui %2 : i32 to i64
  %37 = arith.extui %3 : i32 to i64
  %38 = arith.shli %37, %c32_i64 : i64
  %39 = arith.ori %36, %38 : i64
  %40 = arith.index_castui %39 : i64 to index
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %41 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %35, %workgroup_count_x]
  %42 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%35, %workgroup_id_x, %workgroup_count_x]
  %43 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%40, %workgroup_id_x, %35, %workgroup_count_x]
  %44 = flow.dispatch.tensor.load %30, offsets = [%41, %41], sizes = [%42, %43], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%35, %40} -> tensor<?x?xf32>
  %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
  %workgroup_count_x_1 = hal.interface.workgroup.count[0] : index
  %45 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x_0, %workgroup_count_x_1]
  %46 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x_0, %12, %workgroup_count_x_1]
  %47 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x_0, %12, %workgroup_count_x_1]
  %48 = flow.dispatch.tensor.load %28, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %49 = flow.dispatch.tensor.load %29, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %50 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%48, %49 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%44 : tensor<?x?xf32>) (%45, %46, %workgroup_id_x_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %50, %30, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %31 = arith.extui %0 : i32 to i64
    %32 = arith.extui %1 : i32 to i64
    %33 = arith.shli %32, %c32_i64 : i64
    %34 = arith.ori %31, %33 : i64
    %35 = arith.index_castui %34 : i64 to index
    %36 = arith.extui %2 : i32 to i64
    %37 = arith.extui %3 : i32 to i64
    %38 = arith.shli %37, %c32_i64 : i64
    %39 = arith.ori %36, %38 : i64
    %40 = arith.index_castui %39 : i64 to index
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %41 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %35, %workgroup_count_x]
    %42 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%35, %workgroup_id_x, %workgroup_count_x]
    %43 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%40, %workgroup_id_x, %35, %workgroup_count_x]
    %44 = flow.dispatch.tensor.load %30, offsets = [%41, %41], sizes = [%42, %43], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %workgroup_id_x_0 = hal.interface.workgroup.id[0] : index
    %workgroup_count_x_1 = hal.interface.workgroup.count[0] : index
    %45 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x_0, %workgroup_count_x_1]
    %46 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x_0, %12, %workgroup_count_x_1]
    %47 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x_0, %12, %workgroup_count_x_1]
    %48 = flow.dispatch.tensor.load %28, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %49 = flow.dispatch.tensor.load %29, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %50 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%48, %49 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%44 : tensor<?x?xf32>) (%45, %46, %workgroup_id_x_0 : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %50, %30, offsets = [%47, %47], sizes = [%45, %46], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After FuseTensorPadWithConsumer (iree-codegen-fuse-tensor-pad-with-consumer) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After ConcretizePadResultShape (iree-codegen-concretize-pad-result-shape) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After TileAndDecomposeAttention (iree-linalg-ext-tile-and-decompose-attention) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After TileAndDecomposeWinogradTransform (iree-linalg-ext-tile-and-decompose-winograd) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
  %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
  %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
  flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
  return
}

// -----// IR Dump After EliminateEmptyTensors (iree-eliminate-empty-tensors) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After EmptyTensorToAllocTensor (empty-tensor-to-alloc-tensor) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17}
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27}
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %34 = flow.dispatch.tensor.load %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %35 = flow.dispatch.tensor.load %28, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%12, %17} -> tensor<?x?xf32>
    %36 = flow.dispatch.tensor.load %29, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : !flow.dispatch.tensor<readonly:tensor<?x?xf32>>{%22, %27} -> tensor<?x?xf32>
    %37 = iree_codegen.ukernel.generic "aie_matmul_f32" ins(%35, %36 : tensor<?x?xf32>, tensor<?x?xf32>) outs(%34 : tensor<?x?xf32>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0) -> tensor<?x?xf32>
    flow.dispatch.tensor.store %37, %30, offsets = [%31, %31], sizes = [%32, %33], strides = [1, 1] : tensor<?x?xf32> -> !flow.dispatch.tensor<readwrite:tensor<?x?xf32>>{%12, %17}
    return
  }
}

// -----// IR Dump After IREEComprehensiveBufferize (iree-codegen-iree-comprehensive-bufferize) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
    %subview_2 = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
    return
  }
}

// -----// IR Dump After ResolveShapedTypeResultDims (resolve-shaped-type-result-dims) //----- //
module {
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
    %subview_2 = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
    linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
    ^bb0(%in: f32, %out: f32):
      linalg.yield %in : f32
    }
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
  %subview_2 = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview_2 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
  linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  }
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
  return
}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
  iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
  return
}

// -----// IR Dump After LLVMCPULowerExecutableTarget (iree-llvmcpu-lower-executable-target) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
  hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
  ^bb0(%arg0: !hal.device, %arg1: index):
    %c1 = arith.constant 1 : index
    hal.return %arg1, %c1, %c1 : index, index, index
  }
  builtin.module {
    func.func @_matmul_aie_offload_dispatch_0() {
      %c32_i64 = arith.constant 32 : i64
      %c0 = arith.constant 0 : index
      %0 = hal.interface.constant.load[0] : i32
      %1 = hal.interface.constant.load[1] : i32
      %2 = hal.interface.constant.load[2] : i32
      %3 = hal.interface.constant.load[3] : i32
      %4 = hal.interface.constant.load[4] : i32
      %5 = hal.interface.constant.load[5] : i32
      %6 = hal.interface.constant.load[6] : i32
      %7 = hal.interface.constant.load[7] : i32
      %8 = arith.extui %1 : i32 to i64
      %9 = arith.shli %8, %c32_i64 : i64
      %10 = arith.extui %0 : i32 to i64
      %11 = arith.ori %10, %9 : i64
      %12 = arith.index_castui %11 : i64 to index
      %13 = arith.extui %3 : i32 to i64
      %14 = arith.shli %13, %c32_i64 : i64
      %15 = arith.extui %2 : i32 to i64
      %16 = arith.ori %15, %14 : i64
      %17 = arith.index_castui %16 : i64 to index
      %18 = arith.extui %5 : i32 to i64
      %19 = arith.shli %18, %c32_i64 : i64
      %20 = arith.extui %4 : i32 to i64
      %21 = arith.ori %20, %19 : i64
      %22 = arith.index_castui %21 : i64 to index
      %23 = arith.extui %7 : i32 to i64
      %24 = arith.shli %23, %c32_i64 : i64
      %25 = arith.extui %6 : i32 to i64
      %26 = arith.ori %25, %24 : i64
      %27 = arith.index_castui %26 : i64 to index
      %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
      memref.assume_alignment %28, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
      %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%22, %27}
      memref.assume_alignment %29, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
      %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>{%12, %17}
      memref.assume_alignment %30, 64 : memref<?x?xf32, #hal.descriptor_type<storage_buffer>>
      %workgroup_id_x = hal.interface.workgroup.id[0] : index
      %workgroup_count_x = hal.interface.workgroup.count[0] : index
      %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
      %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
      %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
      %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32, #hal.descriptor_type<storage_buffer>> to memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>
      iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>, memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>, #hal.descriptor_type<storage_buffer>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
      return
    }
  }
}

// -----// IR Dump After EraseHALDescriptorTypeFromMemRef (iree-codegen-erase-hal-descriptor-type-from-memref) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  iree_codegen.ukernel.generic "aie_matmul_f32" ins(%subview_0, %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>>, memref<?x?xf32, strided<[?, 1], offset: ?>>) outs(%subview : memref<?x?xf32, strided<[?, 1], offset: ?>>) (%32, %33, %workgroup_id_x : index, index, index) fn_def_attrs {hal.import.fields = ["processor_id", "processor_data"]} strided_outer_dims(0)
  return
}

// -----// IR Dump After LowerUKernelOpsToCalls (iree-codegen-lower-ukernel-ops-to-calls) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After LinalgExtToLoops (iree-linalg-ext-to-loops) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After LinalgExtToLoops (iree-linalg-ext-to-loops) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After MemrefCopyToLinalgPass (iree-codegen-memrefcopy-to-linalg) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After LinalgLowerToLoops (convert-linalg-to-loops) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After ConvertBf16ArithToF32 (iree-convert-bf16-arith-to-f32) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After ConvertBf16ToUInt16Buffers (iree-convert-bf16-to-uint16-buffers) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After CSE (cse) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After ArithBufferize (arith-bufferize) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After FoldTensorExtractOp (iree-codegen-fold-tensor-extract-op) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After ConvertComplexToStandard (convert-complex-to-standard) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %28, 64 : memref<?x?xf32>
    %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
    memref.assume_alignment %29, 64 : memref<?x?xf32>
    %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
    memref.assume_alignment %30, 64 : memref<?x?xf32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
    %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
    call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After HoistStaticallyBoundAllocations (iree-hoist-statically-bound-allocations) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After IREEExpandStridedMetadata (iree-codegen-expand-strided-metadata) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After PolynomialApproximationPass (iree-codegen-polynomial-approximation) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After HoistStaticallyBoundAllocations (iree-hoist-statically-bound-allocations) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %28, 64 : memref<?x?xf32>
  %29 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?x?xf32>{%22, %27}
  memref.assume_alignment %29, 64 : memref<?x?xf32>
  %30 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?x?xf32>{%12, %17}
  memref.assume_alignment %30, 64 : memref<?x?xf32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %31 = affine.apply affine_map<()[s0, s1, s2] -> (s0 * (s1 ceildiv s2))>()[%workgroup_id_x, %12, %workgroup_count_x]
  %32 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %33 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %subview = memref.subview %30[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_0 = memref.subview %28[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %subview_1 = memref.subview %29[%31, %31] [%32, %33] [1, 1] : memref<?x?xf32> to memref<?x?xf32, strided<[?, 1], offset: ?>>
  %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %subview_0 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_2, %offset_3, %sizes_4:2, %strides_5:2 = memref.extract_strided_metadata %subview_1 : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  %base_buffer_6, %offset_7, %sizes_8:2, %strides_9:2 = memref.extract_strided_metadata %subview : memref<?x?xf32, strided<[?, 1], offset: ?>> -> memref<f32>, index, index, index, index, index
  call @aie_matmul_f32(%base_buffer, %offset, %base_buffer_2, %offset_3, %base_buffer_6, %offset_7, %32, %33, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After IREEExpandStridedMetadata (iree-codegen-expand-strided-metadata) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %33 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%32}
  %reinterpret_cast_1 = memref.reinterpret_cast %33 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %34 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %35 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %37 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  %38 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %36, %reinterpret_cast_0, %37, %reinterpret_cast_1, %38, %34, %35, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After CleanupBufferAllocView (iree-codegen-cleanup-buffer-alloc-view) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %33 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%32}
  %reinterpret_cast_1 = memref.reinterpret_cast %33 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %34 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %35 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %37 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  %38 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %36, %reinterpret_cast_0, %37, %reinterpret_cast_1, %38, %34, %35, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After LLVMCPUCheckIRBeforeLLVMConversion (iree-llvmcpu-check-ir-before-llvm-conversion) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
    %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
    %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
    %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %32 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %33 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%32}
    %reinterpret_cast_1 = memref.reinterpret_cast %33 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %34 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %35 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %37 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
    %38 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    call @aie_matmul_f32(%reinterpret_cast, %36, %reinterpret_cast_0, %37, %reinterpret_cast_1, %38, %34, %35, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %33 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%32}
  %reinterpret_cast_1 = memref.reinterpret_cast %33 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %34 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %35 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %37 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  %38 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %36, %reinterpret_cast_0, %37, %reinterpret_cast_1, %38, %34, %35, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After CSE (cse) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %33 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%32}
  %reinterpret_cast_1 = memref.reinterpret_cast %33 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %34 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %35 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %37 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  %38 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %36, %reinterpret_cast_0, %37, %reinterpret_cast_1, %38, %34, %35, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After CSE (cse) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
  %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After ArithExpandOps (arith-expand) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
  %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After ExpandOps (memref-expand) //----- //
func.func @_matmul_aie_offload_dispatch_0() {
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %0 = hal.interface.constant.load[0] : i32
  %1 = hal.interface.constant.load[1] : i32
  %2 = hal.interface.constant.load[2] : i32
  %3 = hal.interface.constant.load[3] : i32
  %4 = hal.interface.constant.load[4] : i32
  %5 = hal.interface.constant.load[5] : i32
  %6 = hal.interface.constant.load[6] : i32
  %7 = hal.interface.constant.load[7] : i32
  %8 = arith.extui %1 : i32 to i64
  %9 = arith.shli %8, %c32_i64 : i64
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.ori %10, %9 : i64
  %12 = arith.index_castui %11 : i64 to index
  %13 = arith.extui %3 : i32 to i64
  %14 = arith.shli %13, %c32_i64 : i64
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.ori %15, %14 : i64
  %17 = arith.index_castui %16 : i64 to index
  %18 = arith.extui %5 : i32 to i64
  %19 = arith.shli %18, %c32_i64 : i64
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.ori %20, %19 : i64
  %22 = arith.index_castui %21 : i64 to index
  %23 = arith.extui %7 : i32 to i64
  %24 = arith.shli %23, %c32_i64 : i64
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.ori %25, %24 : i64
  %27 = arith.index_castui %26 : i64 to index
  %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
  %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
  %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
  %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
  %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
  %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
  %workgroup_id_x = hal.interface.workgroup.id[0] : index
  %workgroup_count_x = hal.interface.workgroup.count[0] : index
  %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
  %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
  %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
  call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
  return
}

// -----// IR Dump After FoldMemRefAliasOps (fold-memref-alias-ops) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
    %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
    %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
    %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
    %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
    call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After EmulateNarrowType (iree-codegen-emulate-narrow-type) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
    %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
    %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
    %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
    %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
    call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
    %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
    %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
    %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
    %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
    call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After CSE (cse) //----- //
module {
  func.func private @aie_matmul_f32(memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  func.func @_matmul_aie_offload_dispatch_0() {
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %0 = hal.interface.constant.load[0] : i32
    %1 = hal.interface.constant.load[1] : i32
    %2 = hal.interface.constant.load[2] : i32
    %3 = hal.interface.constant.load[3] : i32
    %4 = hal.interface.constant.load[4] : i32
    %5 = hal.interface.constant.load[5] : i32
    %6 = hal.interface.constant.load[6] : i32
    %7 = hal.interface.constant.load[7] : i32
    %8 = arith.extui %1 : i32 to i64
    %9 = arith.shli %8, %c32_i64 : i64
    %10 = arith.extui %0 : i32 to i64
    %11 = arith.ori %10, %9 : i64
    %12 = arith.index_castui %11 : i64 to index
    %13 = arith.extui %3 : i32 to i64
    %14 = arith.shli %13, %c32_i64 : i64
    %15 = arith.extui %2 : i32 to i64
    %16 = arith.ori %15, %14 : i64
    %17 = arith.index_castui %16 : i64 to index
    %18 = arith.extui %5 : i32 to i64
    %19 = arith.shli %18, %c32_i64 : i64
    %20 = arith.extui %4 : i32 to i64
    %21 = arith.ori %20, %19 : i64
    %22 = arith.index_castui %21 : i64 to index
    %23 = arith.extui %7 : i32 to i64
    %24 = arith.shli %23, %c32_i64 : i64
    %25 = arith.extui %6 : i32 to i64
    %26 = arith.ori %25, %24 : i64
    %27 = arith.index_castui %26 : i64 to index
    %28 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%12, %17]
    %29 = hal.interface.binding.subspan set(0) binding(0) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%28}
    %reinterpret_cast = memref.reinterpret_cast %29 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %30 = affine.apply affine_map<()[s0, s1] -> (s0 * s1)>()[%22, %27]
    %31 = hal.interface.binding.subspan set(0) binding(1) type(storage_buffer) alignment(64) offset(%c0) flags(ReadOnly) : memref<?xf32>{%30}
    %reinterpret_cast_0 = memref.reinterpret_cast %31 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %32 = hal.interface.binding.subspan set(0) binding(2) type(storage_buffer) alignment(64) offset(%c0) : memref<?xf32>{%28}
    %reinterpret_cast_1 = memref.reinterpret_cast %32 to offset: [0], sizes: [], strides: [] : memref<?xf32> to memref<f32>
    %workgroup_id_x = hal.interface.workgroup.id[0] : index
    %workgroup_count_x = hal.interface.workgroup.count[0] : index
    %33 = affine.min affine_map<()[s0, s1, s2] -> (s0 - s1 * (s0 ceildiv s2), s0 ceildiv s2)>()[%12, %workgroup_id_x, %workgroup_count_x]
    %34 = affine.min affine_map<()[s0, s1, s2, s3] -> (s0 - s1 * (s2 ceildiv s3), s2 ceildiv s3)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %35 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%17, %workgroup_id_x, %12, %workgroup_count_x]
    %36 = affine.apply affine_map<()[s0, s1, s2, s3] -> (s1 * (s2 ceildiv s3) + (s1 * (s2 ceildiv s3)) * s0)>()[%27, %workgroup_id_x, %12, %workgroup_count_x]
    call @aie_matmul_f32(%reinterpret_cast, %35, %reinterpret_cast_0, %36, %reinterpret_cast_1, %35, %33, %34, %workgroup_id_x) : (memref<f32>, index, memref<f32>, index, memref<f32>, index, index, index, index) -> ()
    return
  }
}

// -----// IR Dump After ConvertToLLVM (iree-convert-to-llvm) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32"} : i32
  llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true, sym_visibility = "private"}
  llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(1 : index) : i64
    %1 = llvm.mlir.constant(0 : i32) : i32
    %2 = llvm.mlir.constant(-1 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %7 = llvm.load %6 : !llvm.ptr -> i32
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %9 = llvm.extractvalue %8[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %10 = llvm.getelementptr %9[1] : (!llvm.ptr) -> !llvm.ptr, i32
    %11 = llvm.load %10 : !llvm.ptr -> i32
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %14 = llvm.getelementptr %13[2] : (!llvm.ptr) -> !llvm.ptr, i32
    %15 = llvm.load %14 : !llvm.ptr -> i32
    %16 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %17 = llvm.extractvalue %16[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %18 = llvm.getelementptr %17[3] : (!llvm.ptr) -> !llvm.ptr, i32
    %19 = llvm.load %18 : !llvm.ptr -> i32
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %22 = llvm.getelementptr %21[6] : (!llvm.ptr) -> !llvm.ptr, i32
    %23 = llvm.load %22 : !llvm.ptr -> i32
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %26 = llvm.getelementptr %25[7] : (!llvm.ptr) -> !llvm.ptr, i32
    %27 = llvm.load %26 : !llvm.ptr -> i32
    %28 = llvm.zext %11 : i32 to i64
    %29 = llvm.shl %28, %4  : i64
    %30 = llvm.zext %7 : i32 to i64
    %31 = llvm.or %30, %29  : i64
    %32 = llvm.zext %19 : i32 to i64
    %33 = llvm.shl %32, %4  : i64
    %34 = llvm.zext %15 : i32 to i64
    %35 = llvm.or %34, %33  : i64
    %36 = llvm.zext %27 : i32 to i64
    %37 = llvm.shl %36, %4  : i64
    %38 = llvm.zext %23 : i32 to i64
    %39 = llvm.or %38, %37  : i64
    %40 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %41 = llvm.extractvalue %40[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %42 = llvm.load %41 : !llvm.ptr -> !llvm.ptr
    %43 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %44 = llvm.extractvalue %43[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %45 = llvm.getelementptr %44[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %46 = llvm.load %45 : !llvm.ptr -> !llvm.ptr
    %47 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %48 = llvm.extractvalue %47[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %49 = llvm.getelementptr %48[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %50 = llvm.load %49 : !llvm.ptr -> !llvm.ptr
    %51 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %52 = llvm.extractvalue %51[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %53 = llvm.zext %52 : i32 to i64
    %54 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %55 = llvm.extractvalue %54[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %56 = llvm.zext %55 : i32 to i64
    %57 = llvm.icmp "sle" %31, %3 : i64
    %58 = llvm.sub %3, %31  : i64
    %59 = llvm.sub %31, %0  : i64
    %60 = llvm.select %57, %58, %59 : i1, i64
    %61 = llvm.sdiv %60, %56  : i64
    %62 = llvm.sub %3, %61  : i64
    %63 = llvm.add %61, %0  : i64
    %64 = llvm.select %57, %62, %63 : i1, i64
    %65 = llvm.mul %53, %64  : i64
    %66 = llvm.mul %65, %2  : i64
    %67 = llvm.add %31, %66  : i64
    %68 = llvm.icmp "sle" %31, %3 : i64
    %69 = llvm.sub %3, %31  : i64
    %70 = llvm.sub %31, %0  : i64
    %71 = llvm.select %68, %69, %70 : i1, i64
    %72 = llvm.sdiv %71, %56  : i64
    %73 = llvm.sub %3, %72  : i64
    %74 = llvm.add %72, %0  : i64
    %75 = llvm.select %68, %73, %74 : i1, i64
    %76 = llvm.icmp "slt" %67, %75 : i64
    %77 = llvm.select %76, %67, %75 : i1, i64
    %78 = llvm.icmp "sle" %31, %3 : i64
    %79 = llvm.sub %3, %31  : i64
    %80 = llvm.sub %31, %0  : i64
    %81 = llvm.select %78, %79, %80 : i1, i64
    %82 = llvm.sdiv %81, %56  : i64
    %83 = llvm.sub %3, %82  : i64
    %84 = llvm.add %82, %0  : i64
    %85 = llvm.select %78, %83, %84 : i1, i64
    %86 = llvm.mul %53, %85  : i64
    %87 = llvm.mul %86, %2  : i64
    %88 = llvm.add %35, %87  : i64
    %89 = llvm.icmp "sle" %31, %3 : i64
    %90 = llvm.sub %3, %31  : i64
    %91 = llvm.sub %31, %0  : i64
    %92 = llvm.select %89, %90, %91 : i1, i64
    %93 = llvm.sdiv %92, %56  : i64
    %94 = llvm.sub %3, %93  : i64
    %95 = llvm.add %93, %0  : i64
    %96 = llvm.select %89, %94, %95 : i1, i64
    %97 = llvm.icmp "slt" %88, %96 : i64
    %98 = llvm.select %97, %88, %96 : i1, i64
    %99 = llvm.icmp "sle" %31, %3 : i64
    %100 = llvm.sub %3, %31  : i64
    %101 = llvm.sub %31, %0  : i64
    %102 = llvm.select %99, %100, %101 : i1, i64
    %103 = llvm.sdiv %102, %56  : i64
    %104 = llvm.sub %3, %103  : i64
    %105 = llvm.add %103, %0  : i64
    %106 = llvm.select %99, %104, %105 : i1, i64
    %107 = llvm.mul %53, %106  : i64
    %108 = llvm.icmp "sle" %31, %3 : i64
    %109 = llvm.sub %3, %31  : i64
    %110 = llvm.sub %31, %0  : i64
    %111 = llvm.select %108, %109, %110 : i1, i64
    %112 = llvm.sdiv %111, %56  : i64
    %113 = llvm.sub %3, %112  : i64
    %114 = llvm.add %112, %0  : i64
    %115 = llvm.select %108, %113, %114 : i1, i64
    %116 = llvm.mul %53, %115  : i64
    %117 = llvm.mul %116, %35  : i64
    %118 = llvm.add %107, %117  : i64
    %119 = llvm.icmp "sle" %31, %3 : i64
    %120 = llvm.sub %3, %31  : i64
    %121 = llvm.sub %31, %0  : i64
    %122 = llvm.select %119, %120, %121 : i1, i64
    %123 = llvm.sdiv %122, %56  : i64
    %124 = llvm.sub %3, %123  : i64
    %125 = llvm.add %123, %0  : i64
    %126 = llvm.select %119, %124, %125 : i1, i64
    %127 = llvm.mul %53, %126  : i64
    %128 = llvm.icmp "sle" %31, %3 : i64
    %129 = llvm.sub %3, %31  : i64
    %130 = llvm.sub %31, %0  : i64
    %131 = llvm.select %128, %129, %130 : i1, i64
    %132 = llvm.sdiv %131, %56  : i64
    %133 = llvm.sub %3, %132  : i64
    %134 = llvm.add %132, %0  : i64
    %135 = llvm.select %128, %133, %134 : i1, i64
    %136 = llvm.mul %53, %135  : i64
    %137 = llvm.mul %136, %39  : i64
    %138 = llvm.add %127, %137  : i64
    %139 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %140 = llvm.extractvalue %139[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %141 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
    %142 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
    %143 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
    %144 = llvm.insertvalue %42, %143[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %145 = llvm.insertvalue %118, %144[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %146 = llvm.insertvalue %46, %145[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %147 = llvm.insertvalue %138, %146[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %148 = llvm.insertvalue %50, %147[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %149 = llvm.insertvalue %118, %148[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %150 = llvm.insertvalue %77, %149[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %151 = llvm.insertvalue %98, %150[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %152 = llvm.insertvalue %53, %151[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %153 = llvm.insertvalue %140, %152[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %154 = llvm.insertvalue %141, %153[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    llvm.store %154, %142 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
    %155 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
    %156 = llvm.load %155 : !llvm.ptr<i32>
    %157 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %158 = llvm.extractvalue %157[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %159 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %160 = llvm.extractvalue %159[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %161 = llvm.getelementptr %160[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %162 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %163 = llvm.extractvalue %162[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %164 = llvm.getelementptr %163[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %165 = llvm.load %164 : !llvm.ptr<ptr>
    %166 = llvm.load %161 : !llvm.ptr<ptr>
    %167 = llvm.mlir.null : !llvm.ptr
    %168 = llvm.call %158(%166, %142, %165, %167) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
    %169 = llvm.icmp "eq" %168, %1 : i32
    llvm.cond_br %169 weights([1, 0]), ^bb2, ^bb1(%168 : i32)
  ^bb1(%170: i32):  // pred: ^bb0
    llvm.return %170 : i32
  ^bb2:  // pred: ^bb0
    llvm.return %1 : i32
  }
}

// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32"} : i32
  llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true, sym_visibility = "private"}
  llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(1 : index) : i64
    %1 = llvm.mlir.constant(0 : i32) : i32
    %2 = llvm.mlir.constant(-1 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %7 = llvm.load %6 : !llvm.ptr -> i32
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %9 = llvm.extractvalue %8[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %10 = llvm.getelementptr %9[1] : (!llvm.ptr) -> !llvm.ptr, i32
    %11 = llvm.load %10 : !llvm.ptr -> i32
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %14 = llvm.getelementptr %13[2] : (!llvm.ptr) -> !llvm.ptr, i32
    %15 = llvm.load %14 : !llvm.ptr -> i32
    %16 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %17 = llvm.extractvalue %16[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %18 = llvm.getelementptr %17[3] : (!llvm.ptr) -> !llvm.ptr, i32
    %19 = llvm.load %18 : !llvm.ptr -> i32
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %22 = llvm.getelementptr %21[6] : (!llvm.ptr) -> !llvm.ptr, i32
    %23 = llvm.load %22 : !llvm.ptr -> i32
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %26 = llvm.getelementptr %25[7] : (!llvm.ptr) -> !llvm.ptr, i32
    %27 = llvm.load %26 : !llvm.ptr -> i32
    %28 = llvm.zext %11 : i32 to i64
    %29 = llvm.shl %28, %4  : i64
    %30 = llvm.zext %7 : i32 to i64
    %31 = llvm.or %30, %29  : i64
    %32 = llvm.zext %19 : i32 to i64
    %33 = llvm.shl %32, %4  : i64
    %34 = llvm.zext %15 : i32 to i64
    %35 = llvm.or %34, %33  : i64
    %36 = llvm.zext %27 : i32 to i64
    %37 = llvm.shl %36, %4  : i64
    %38 = llvm.zext %23 : i32 to i64
    %39 = llvm.or %38, %37  : i64
    %40 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %41 = llvm.extractvalue %40[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %42 = llvm.load %41 : !llvm.ptr -> !llvm.ptr
    %43 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %44 = llvm.extractvalue %43[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %45 = llvm.getelementptr %44[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %46 = llvm.load %45 : !llvm.ptr -> !llvm.ptr
    %47 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %48 = llvm.extractvalue %47[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %49 = llvm.getelementptr %48[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %50 = llvm.load %49 : !llvm.ptr -> !llvm.ptr
    %51 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %52 = llvm.extractvalue %51[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %53 = llvm.zext %52 : i32 to i64
    %54 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %55 = llvm.extractvalue %54[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %56 = llvm.zext %55 : i32 to i64
    %57 = llvm.icmp "sle" %31, %3 : i64
    %58 = llvm.sub %3, %31  : i64
    %59 = llvm.sub %31, %0  : i64
    %60 = llvm.select %57, %58, %59 : i1, i64
    %61 = llvm.sdiv %60, %56  : i64
    %62 = llvm.sub %3, %61  : i64
    %63 = llvm.add %61, %0  : i64
    %64 = llvm.select %57, %62, %63 : i1, i64
    %65 = llvm.mul %53, %64  : i64
    %66 = llvm.mul %65, %2  : i64
    %67 = llvm.add %31, %66  : i64
    %68 = llvm.icmp "sle" %31, %3 : i64
    %69 = llvm.sub %3, %31  : i64
    %70 = llvm.sub %31, %0  : i64
    %71 = llvm.select %68, %69, %70 : i1, i64
    %72 = llvm.sdiv %71, %56  : i64
    %73 = llvm.sub %3, %72  : i64
    %74 = llvm.add %72, %0  : i64
    %75 = llvm.select %68, %73, %74 : i1, i64
    %76 = llvm.icmp "slt" %67, %75 : i64
    %77 = llvm.select %76, %67, %75 : i1, i64
    %78 = llvm.icmp "sle" %31, %3 : i64
    %79 = llvm.sub %3, %31  : i64
    %80 = llvm.sub %31, %0  : i64
    %81 = llvm.select %78, %79, %80 : i1, i64
    %82 = llvm.sdiv %81, %56  : i64
    %83 = llvm.sub %3, %82  : i64
    %84 = llvm.add %82, %0  : i64
    %85 = llvm.select %78, %83, %84 : i1, i64
    %86 = llvm.mul %53, %85  : i64
    %87 = llvm.mul %86, %2  : i64
    %88 = llvm.add %35, %87  : i64
    %89 = llvm.icmp "sle" %31, %3 : i64
    %90 = llvm.sub %3, %31  : i64
    %91 = llvm.sub %31, %0  : i64
    %92 = llvm.select %89, %90, %91 : i1, i64
    %93 = llvm.sdiv %92, %56  : i64
    %94 = llvm.sub %3, %93  : i64
    %95 = llvm.add %93, %0  : i64
    %96 = llvm.select %89, %94, %95 : i1, i64
    %97 = llvm.icmp "slt" %88, %96 : i64
    %98 = llvm.select %97, %88, %96 : i1, i64
    %99 = llvm.icmp "sle" %31, %3 : i64
    %100 = llvm.sub %3, %31  : i64
    %101 = llvm.sub %31, %0  : i64
    %102 = llvm.select %99, %100, %101 : i1, i64
    %103 = llvm.sdiv %102, %56  : i64
    %104 = llvm.sub %3, %103  : i64
    %105 = llvm.add %103, %0  : i64
    %106 = llvm.select %99, %104, %105 : i1, i64
    %107 = llvm.mul %53, %106  : i64
    %108 = llvm.icmp "sle" %31, %3 : i64
    %109 = llvm.sub %3, %31  : i64
    %110 = llvm.sub %31, %0  : i64
    %111 = llvm.select %108, %109, %110 : i1, i64
    %112 = llvm.sdiv %111, %56  : i64
    %113 = llvm.sub %3, %112  : i64
    %114 = llvm.add %112, %0  : i64
    %115 = llvm.select %108, %113, %114 : i1, i64
    %116 = llvm.mul %53, %115  : i64
    %117 = llvm.mul %116, %35  : i64
    %118 = llvm.add %107, %117  : i64
    %119 = llvm.icmp "sle" %31, %3 : i64
    %120 = llvm.sub %3, %31  : i64
    %121 = llvm.sub %31, %0  : i64
    %122 = llvm.select %119, %120, %121 : i1, i64
    %123 = llvm.sdiv %122, %56  : i64
    %124 = llvm.sub %3, %123  : i64
    %125 = llvm.add %123, %0  : i64
    %126 = llvm.select %119, %124, %125 : i1, i64
    %127 = llvm.mul %53, %126  : i64
    %128 = llvm.icmp "sle" %31, %3 : i64
    %129 = llvm.sub %3, %31  : i64
    %130 = llvm.sub %31, %0  : i64
    %131 = llvm.select %128, %129, %130 : i1, i64
    %132 = llvm.sdiv %131, %56  : i64
    %133 = llvm.sub %3, %132  : i64
    %134 = llvm.add %132, %0  : i64
    %135 = llvm.select %128, %133, %134 : i1, i64
    %136 = llvm.mul %53, %135  : i64
    %137 = llvm.mul %136, %39  : i64
    %138 = llvm.add %127, %137  : i64
    %139 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %140 = llvm.extractvalue %139[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %141 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
    %142 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
    %143 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
    %144 = llvm.insertvalue %42, %143[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %145 = llvm.insertvalue %118, %144[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %146 = llvm.insertvalue %46, %145[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %147 = llvm.insertvalue %138, %146[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %148 = llvm.insertvalue %50, %147[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %149 = llvm.insertvalue %118, %148[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %150 = llvm.insertvalue %77, %149[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %151 = llvm.insertvalue %98, %150[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %152 = llvm.insertvalue %53, %151[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %153 = llvm.insertvalue %140, %152[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %154 = llvm.insertvalue %141, %153[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    llvm.store %154, %142 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
    %155 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
    %156 = llvm.load %155 : !llvm.ptr<i32>
    %157 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %158 = llvm.extractvalue %157[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %159 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %160 = llvm.extractvalue %159[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %161 = llvm.getelementptr %160[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %162 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %163 = llvm.extractvalue %162[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %164 = llvm.getelementptr %163[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %165 = llvm.load %164 : !llvm.ptr<ptr>
    %166 = llvm.load %161 : !llvm.ptr<ptr>
    %167 = llvm.mlir.null : !llvm.ptr
    %168 = llvm.call %158(%166, %142, %165, %167) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
    %169 = llvm.icmp "eq" %168, %1 : i32
    llvm.cond_br %169 weights([1, 0]), ^bb2, ^bb1(%168 : i32)
  ^bb1(%170: i32):  // pred: ^bb0
    llvm.return %170 : i32
  ^bb2:  // pred: ^bb0
    llvm.return %1 : i32
  }
}

// -----// IR Dump After LLVMCPUSynchronizeSymbolVisibility (iree-llvmcpu-synchronize-symbol-visibility) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
  llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(1 : index) : i64
    %1 = llvm.mlir.constant(0 : i32) : i32
    %2 = llvm.mlir.constant(-1 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %7 = llvm.load %6 : !llvm.ptr -> i32
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %9 = llvm.extractvalue %8[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %10 = llvm.getelementptr %9[1] : (!llvm.ptr) -> !llvm.ptr, i32
    %11 = llvm.load %10 : !llvm.ptr -> i32
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %14 = llvm.getelementptr %13[2] : (!llvm.ptr) -> !llvm.ptr, i32
    %15 = llvm.load %14 : !llvm.ptr -> i32
    %16 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %17 = llvm.extractvalue %16[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %18 = llvm.getelementptr %17[3] : (!llvm.ptr) -> !llvm.ptr, i32
    %19 = llvm.load %18 : !llvm.ptr -> i32
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %22 = llvm.getelementptr %21[6] : (!llvm.ptr) -> !llvm.ptr, i32
    %23 = llvm.load %22 : !llvm.ptr -> i32
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %26 = llvm.getelementptr %25[7] : (!llvm.ptr) -> !llvm.ptr, i32
    %27 = llvm.load %26 : !llvm.ptr -> i32
    %28 = llvm.zext %11 : i32 to i64
    %29 = llvm.shl %28, %4  : i64
    %30 = llvm.zext %7 : i32 to i64
    %31 = llvm.or %30, %29  : i64
    %32 = llvm.zext %19 : i32 to i64
    %33 = llvm.shl %32, %4  : i64
    %34 = llvm.zext %15 : i32 to i64
    %35 = llvm.or %34, %33  : i64
    %36 = llvm.zext %27 : i32 to i64
    %37 = llvm.shl %36, %4  : i64
    %38 = llvm.zext %23 : i32 to i64
    %39 = llvm.or %38, %37  : i64
    %40 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %41 = llvm.extractvalue %40[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %42 = llvm.load %41 : !llvm.ptr -> !llvm.ptr
    %43 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %44 = llvm.extractvalue %43[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %45 = llvm.getelementptr %44[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %46 = llvm.load %45 : !llvm.ptr -> !llvm.ptr
    %47 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %48 = llvm.extractvalue %47[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %49 = llvm.getelementptr %48[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %50 = llvm.load %49 : !llvm.ptr -> !llvm.ptr
    %51 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %52 = llvm.extractvalue %51[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %53 = llvm.zext %52 : i32 to i64
    %54 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %55 = llvm.extractvalue %54[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %56 = llvm.zext %55 : i32 to i64
    %57 = llvm.icmp "sle" %31, %3 : i64
    %58 = llvm.sub %3, %31  : i64
    %59 = llvm.sub %31, %0  : i64
    %60 = llvm.select %57, %58, %59 : i1, i64
    %61 = llvm.sdiv %60, %56  : i64
    %62 = llvm.sub %3, %61  : i64
    %63 = llvm.add %61, %0  : i64
    %64 = llvm.select %57, %62, %63 : i1, i64
    %65 = llvm.mul %53, %64  : i64
    %66 = llvm.mul %65, %2  : i64
    %67 = llvm.add %31, %66  : i64
    %68 = llvm.icmp "sle" %31, %3 : i64
    %69 = llvm.sub %3, %31  : i64
    %70 = llvm.sub %31, %0  : i64
    %71 = llvm.select %68, %69, %70 : i1, i64
    %72 = llvm.sdiv %71, %56  : i64
    %73 = llvm.sub %3, %72  : i64
    %74 = llvm.add %72, %0  : i64
    %75 = llvm.select %68, %73, %74 : i1, i64
    %76 = llvm.icmp "slt" %67, %75 : i64
    %77 = llvm.select %76, %67, %75 : i1, i64
    %78 = llvm.icmp "sle" %31, %3 : i64
    %79 = llvm.sub %3, %31  : i64
    %80 = llvm.sub %31, %0  : i64
    %81 = llvm.select %78, %79, %80 : i1, i64
    %82 = llvm.sdiv %81, %56  : i64
    %83 = llvm.sub %3, %82  : i64
    %84 = llvm.add %82, %0  : i64
    %85 = llvm.select %78, %83, %84 : i1, i64
    %86 = llvm.mul %53, %85  : i64
    %87 = llvm.mul %86, %2  : i64
    %88 = llvm.add %35, %87  : i64
    %89 = llvm.icmp "sle" %31, %3 : i64
    %90 = llvm.sub %3, %31  : i64
    %91 = llvm.sub %31, %0  : i64
    %92 = llvm.select %89, %90, %91 : i1, i64
    %93 = llvm.sdiv %92, %56  : i64
    %94 = llvm.sub %3, %93  : i64
    %95 = llvm.add %93, %0  : i64
    %96 = llvm.select %89, %94, %95 : i1, i64
    %97 = llvm.icmp "slt" %88, %96 : i64
    %98 = llvm.select %97, %88, %96 : i1, i64
    %99 = llvm.icmp "sle" %31, %3 : i64
    %100 = llvm.sub %3, %31  : i64
    %101 = llvm.sub %31, %0  : i64
    %102 = llvm.select %99, %100, %101 : i1, i64
    %103 = llvm.sdiv %102, %56  : i64
    %104 = llvm.sub %3, %103  : i64
    %105 = llvm.add %103, %0  : i64
    %106 = llvm.select %99, %104, %105 : i1, i64
    %107 = llvm.mul %53, %106  : i64
    %108 = llvm.icmp "sle" %31, %3 : i64
    %109 = llvm.sub %3, %31  : i64
    %110 = llvm.sub %31, %0  : i64
    %111 = llvm.select %108, %109, %110 : i1, i64
    %112 = llvm.sdiv %111, %56  : i64
    %113 = llvm.sub %3, %112  : i64
    %114 = llvm.add %112, %0  : i64
    %115 = llvm.select %108, %113, %114 : i1, i64
    %116 = llvm.mul %53, %115  : i64
    %117 = llvm.mul %116, %35  : i64
    %118 = llvm.add %107, %117  : i64
    %119 = llvm.icmp "sle" %31, %3 : i64
    %120 = llvm.sub %3, %31  : i64
    %121 = llvm.sub %31, %0  : i64
    %122 = llvm.select %119, %120, %121 : i1, i64
    %123 = llvm.sdiv %122, %56  : i64
    %124 = llvm.sub %3, %123  : i64
    %125 = llvm.add %123, %0  : i64
    %126 = llvm.select %119, %124, %125 : i1, i64
    %127 = llvm.mul %53, %126  : i64
    %128 = llvm.icmp "sle" %31, %3 : i64
    %129 = llvm.sub %3, %31  : i64
    %130 = llvm.sub %31, %0  : i64
    %131 = llvm.select %128, %129, %130 : i1, i64
    %132 = llvm.sdiv %131, %56  : i64
    %133 = llvm.sub %3, %132  : i64
    %134 = llvm.add %132, %0  : i64
    %135 = llvm.select %128, %133, %134 : i1, i64
    %136 = llvm.mul %53, %135  : i64
    %137 = llvm.mul %136, %39  : i64
    %138 = llvm.add %127, %137  : i64
    %139 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %140 = llvm.extractvalue %139[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %141 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
    %142 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
    %143 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
    %144 = llvm.insertvalue %42, %143[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %145 = llvm.insertvalue %118, %144[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %146 = llvm.insertvalue %46, %145[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %147 = llvm.insertvalue %138, %146[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %148 = llvm.insertvalue %50, %147[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %149 = llvm.insertvalue %118, %148[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %150 = llvm.insertvalue %77, %149[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %151 = llvm.insertvalue %98, %150[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %152 = llvm.insertvalue %53, %151[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %153 = llvm.insertvalue %140, %152[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %154 = llvm.insertvalue %141, %153[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    llvm.store %154, %142 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
    %155 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
    %156 = llvm.load %155 : !llvm.ptr<i32>
    %157 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %158 = llvm.extractvalue %157[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %159 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %160 = llvm.extractvalue %159[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %161 = llvm.getelementptr %160[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %162 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %163 = llvm.extractvalue %162[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %164 = llvm.getelementptr %163[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %165 = llvm.load %164 : !llvm.ptr<ptr>
    %166 = llvm.load %161 : !llvm.ptr<ptr>
    %167 = llvm.mlir.null : !llvm.ptr
    %168 = llvm.call %158(%166, %142, %165, %167) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
    %169 = llvm.icmp "eq" %168, %1 : i32
    llvm.cond_br %169 weights([1, 0]), ^bb2, ^bb1(%168 : i32)
  ^bb1(%170: i32):  // pred: ^bb0
    llvm.return %170 : i32
  ^bb2:  // pred: ^bb0
    llvm.return %1 : i32
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
  llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(1 : index) : i64
    %1 = llvm.mlir.constant(0 : i32) : i32
    %2 = llvm.mlir.constant(-1 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %7 = llvm.load %6 : !llvm.ptr -> i32
    %8 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %9 = llvm.extractvalue %8[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %10 = llvm.getelementptr %9[1] : (!llvm.ptr) -> !llvm.ptr, i32
    %11 = llvm.load %10 : !llvm.ptr -> i32
    %12 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %13 = llvm.extractvalue %12[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %14 = llvm.getelementptr %13[2] : (!llvm.ptr) -> !llvm.ptr, i32
    %15 = llvm.load %14 : !llvm.ptr -> i32
    %16 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %17 = llvm.extractvalue %16[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %18 = llvm.getelementptr %17[3] : (!llvm.ptr) -> !llvm.ptr, i32
    %19 = llvm.load %18 : !llvm.ptr -> i32
    %20 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %21 = llvm.extractvalue %20[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %22 = llvm.getelementptr %21[6] : (!llvm.ptr) -> !llvm.ptr, i32
    %23 = llvm.load %22 : !llvm.ptr -> i32
    %24 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %25 = llvm.extractvalue %24[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %26 = llvm.getelementptr %25[7] : (!llvm.ptr) -> !llvm.ptr, i32
    %27 = llvm.load %26 : !llvm.ptr -> i32
    %28 = llvm.zext %11 : i32 to i64
    %29 = llvm.shl %28, %4  : i64
    %30 = llvm.zext %7 : i32 to i64
    %31 = llvm.or %30, %29  : i64
    %32 = llvm.zext %19 : i32 to i64
    %33 = llvm.shl %32, %4  : i64
    %34 = llvm.zext %15 : i32 to i64
    %35 = llvm.or %34, %33  : i64
    %36 = llvm.zext %27 : i32 to i64
    %37 = llvm.shl %36, %4  : i64
    %38 = llvm.zext %23 : i32 to i64
    %39 = llvm.or %38, %37  : i64
    %40 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %41 = llvm.extractvalue %40[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %42 = llvm.load %41 : !llvm.ptr -> !llvm.ptr
    %43 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %44 = llvm.extractvalue %43[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %45 = llvm.getelementptr %44[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %46 = llvm.load %45 : !llvm.ptr -> !llvm.ptr
    %47 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %48 = llvm.extractvalue %47[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %49 = llvm.getelementptr %48[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %50 = llvm.load %49 : !llvm.ptr -> !llvm.ptr
    %51 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %52 = llvm.extractvalue %51[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %53 = llvm.zext %52 : i32 to i64
    %54 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %55 = llvm.extractvalue %54[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %56 = llvm.zext %55 : i32 to i64
    %57 = llvm.icmp "sle" %31, %3 : i64
    %58 = llvm.sub %3, %31  : i64
    %59 = llvm.sub %31, %0  : i64
    %60 = llvm.select %57, %58, %59 : i1, i64
    %61 = llvm.sdiv %60, %56  : i64
    %62 = llvm.sub %3, %61  : i64
    %63 = llvm.add %61, %0  : i64
    %64 = llvm.select %57, %62, %63 : i1, i64
    %65 = llvm.mul %53, %64  : i64
    %66 = llvm.mul %65, %2  : i64
    %67 = llvm.add %31, %66  : i64
    %68 = llvm.icmp "sle" %31, %3 : i64
    %69 = llvm.sub %3, %31  : i64
    %70 = llvm.sub %31, %0  : i64
    %71 = llvm.select %68, %69, %70 : i1, i64
    %72 = llvm.sdiv %71, %56  : i64
    %73 = llvm.sub %3, %72  : i64
    %74 = llvm.add %72, %0  : i64
    %75 = llvm.select %68, %73, %74 : i1, i64
    %76 = llvm.icmp "slt" %67, %75 : i64
    %77 = llvm.select %76, %67, %75 : i1, i64
    %78 = llvm.icmp "sle" %31, %3 : i64
    %79 = llvm.sub %3, %31  : i64
    %80 = llvm.sub %31, %0  : i64
    %81 = llvm.select %78, %79, %80 : i1, i64
    %82 = llvm.sdiv %81, %56  : i64
    %83 = llvm.sub %3, %82  : i64
    %84 = llvm.add %82, %0  : i64
    %85 = llvm.select %78, %83, %84 : i1, i64
    %86 = llvm.mul %53, %85  : i64
    %87 = llvm.mul %86, %2  : i64
    %88 = llvm.add %35, %87  : i64
    %89 = llvm.icmp "sle" %31, %3 : i64
    %90 = llvm.sub %3, %31  : i64
    %91 = llvm.sub %31, %0  : i64
    %92 = llvm.select %89, %90, %91 : i1, i64
    %93 = llvm.sdiv %92, %56  : i64
    %94 = llvm.sub %3, %93  : i64
    %95 = llvm.add %93, %0  : i64
    %96 = llvm.select %89, %94, %95 : i1, i64
    %97 = llvm.icmp "slt" %88, %96 : i64
    %98 = llvm.select %97, %88, %96 : i1, i64
    %99 = llvm.icmp "sle" %31, %3 : i64
    %100 = llvm.sub %3, %31  : i64
    %101 = llvm.sub %31, %0  : i64
    %102 = llvm.select %99, %100, %101 : i1, i64
    %103 = llvm.sdiv %102, %56  : i64
    %104 = llvm.sub %3, %103  : i64
    %105 = llvm.add %103, %0  : i64
    %106 = llvm.select %99, %104, %105 : i1, i64
    %107 = llvm.mul %53, %106  : i64
    %108 = llvm.icmp "sle" %31, %3 : i64
    %109 = llvm.sub %3, %31  : i64
    %110 = llvm.sub %31, %0  : i64
    %111 = llvm.select %108, %109, %110 : i1, i64
    %112 = llvm.sdiv %111, %56  : i64
    %113 = llvm.sub %3, %112  : i64
    %114 = llvm.add %112, %0  : i64
    %115 = llvm.select %108, %113, %114 : i1, i64
    %116 = llvm.mul %53, %115  : i64
    %117 = llvm.mul %116, %35  : i64
    %118 = llvm.add %107, %117  : i64
    %119 = llvm.icmp "sle" %31, %3 : i64
    %120 = llvm.sub %3, %31  : i64
    %121 = llvm.sub %31, %0  : i64
    %122 = llvm.select %119, %120, %121 : i1, i64
    %123 = llvm.sdiv %122, %56  : i64
    %124 = llvm.sub %3, %123  : i64
    %125 = llvm.add %123, %0  : i64
    %126 = llvm.select %119, %124, %125 : i1, i64
    %127 = llvm.mul %53, %126  : i64
    %128 = llvm.icmp "sle" %31, %3 : i64
    %129 = llvm.sub %3, %31  : i64
    %130 = llvm.sub %31, %0  : i64
    %131 = llvm.select %128, %129, %130 : i1, i64
    %132 = llvm.sdiv %131, %56  : i64
    %133 = llvm.sub %3, %132  : i64
    %134 = llvm.add %132, %0  : i64
    %135 = llvm.select %128, %133, %134 : i1, i64
    %136 = llvm.mul %53, %135  : i64
    %137 = llvm.mul %136, %39  : i64
    %138 = llvm.add %127, %137  : i64
    %139 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %140 = llvm.extractvalue %139[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %141 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
    %142 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
    %143 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
    %144 = llvm.insertvalue %42, %143[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %145 = llvm.insertvalue %118, %144[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %146 = llvm.insertvalue %46, %145[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %147 = llvm.insertvalue %138, %146[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %148 = llvm.insertvalue %50, %147[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %149 = llvm.insertvalue %118, %148[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %150 = llvm.insertvalue %77, %149[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %151 = llvm.insertvalue %98, %150[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %152 = llvm.insertvalue %53, %151[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %153 = llvm.insertvalue %140, %152[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %154 = llvm.insertvalue %141, %153[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    llvm.store %154, %142 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
    %155 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
    %156 = llvm.load %155 : !llvm.ptr<i32>
    %157 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %158 = llvm.extractvalue %157[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %159 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %160 = llvm.extractvalue %159[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %161 = llvm.getelementptr %160[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %162 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %163 = llvm.extractvalue %162[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %164 = llvm.getelementptr %163[%156] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %165 = llvm.load %164 : !llvm.ptr<ptr>
    %166 = llvm.load %161 : !llvm.ptr<ptr>
    %167 = llvm.mlir.null : !llvm.ptr
    %168 = llvm.call %158(%166, %142, %165, %167) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
    %169 = llvm.icmp "eq" %168, %1 : i32
    llvm.cond_br %169 weights([1, 0]), ^bb2, ^bb1(%168 : i32)
  ^bb1(%170: i32):  // pred: ^bb0
    llvm.return %170 : i32
  ^bb2:  // pred: ^bb0
    llvm.return %1 : i32
  }
}

// -----// IR Dump After CSE (cse) //----- //
module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
  llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
  llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
  llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
    %0 = llvm.mlir.constant(1 : index) : i64
    %1 = llvm.mlir.constant(0 : i32) : i32
    %2 = llvm.mlir.constant(-1 : index) : i64
    %3 = llvm.mlir.constant(0 : index) : i64
    %4 = llvm.mlir.constant(32 : i64) : i64
    %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
    %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %7 = llvm.load %6 : !llvm.ptr -> i32
    %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
    %9 = llvm.load %8 : !llvm.ptr -> i32
    %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
    %11 = llvm.load %10 : !llvm.ptr -> i32
    %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
    %13 = llvm.load %12 : !llvm.ptr -> i32
    %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
    %15 = llvm.load %14 : !llvm.ptr -> i32
    %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
    %17 = llvm.load %16 : !llvm.ptr -> i32
    %18 = llvm.zext %9 : i32 to i64
    %19 = llvm.shl %18, %4  : i64
    %20 = llvm.zext %7 : i32 to i64
    %21 = llvm.or %20, %19  : i64
    %22 = llvm.zext %13 : i32 to i64
    %23 = llvm.shl %22, %4  : i64
    %24 = llvm.zext %11 : i32 to i64
    %25 = llvm.or %24, %23  : i64
    %26 = llvm.zext %17 : i32 to i64
    %27 = llvm.shl %26, %4  : i64
    %28 = llvm.zext %15 : i32 to i64
    %29 = llvm.or %28, %27  : i64
    %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
    %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
    %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
    %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
    %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
    %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %38 = llvm.zext %37 : i32 to i64
    %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
    %40 = llvm.zext %39 : i32 to i64
    %41 = llvm.icmp "sle" %21, %3 : i64
    %42 = llvm.sub %3, %21  : i64
    %43 = llvm.sub %21, %0  : i64
    %44 = llvm.select %41, %42, %43 : i1, i64
    %45 = llvm.sdiv %44, %40  : i64
    %46 = llvm.sub %3, %45  : i64
    %47 = llvm.add %45, %0  : i64
    %48 = llvm.select %41, %46, %47 : i1, i64
    %49 = llvm.mul %38, %48  : i64
    %50 = llvm.mul %49, %2  : i64
    %51 = llvm.add %21, %50  : i64
    %52 = llvm.icmp "slt" %51, %48 : i64
    %53 = llvm.select %52, %51, %48 : i1, i64
    %54 = llvm.add %25, %50  : i64
    %55 = llvm.icmp "slt" %54, %48 : i64
    %56 = llvm.select %55, %54, %48 : i1, i64
    %57 = llvm.mul %49, %25  : i64
    %58 = llvm.add %49, %57  : i64
    %59 = llvm.mul %49, %29  : i64
    %60 = llvm.add %49, %59  : i64
    %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
    %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
    %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
    %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
    %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
    llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
    %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
    %77 = llvm.load %76 : !llvm.ptr<i32>
    %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
    %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
    %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
    %84 = llvm.load %83 : !llvm.ptr<ptr>
    %85 = llvm.load %81 : !llvm.ptr<ptr>
    %86 = llvm.mlir.null : !llvm.ptr
    %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
    %88 = llvm.icmp "eq" %87, %1 : i32
    llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
  ^bb1(%89: i32):  // pred: ^bb0
    llvm.return %89 : i32
  ^bb2:  // pred: ^bb0
    llvm.return %1 : i32
  }
}

// -----// IR Dump After AddFastMathFlags (iree-codegen-add-fast-math-flags) //----- //
llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}

// -----// IR Dump After AddFastMathFlags (iree-codegen-add-fast-math-flags) //----- //
llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
  %0 = llvm.mlir.constant(1 : index) : i64
  %1 = llvm.mlir.constant(0 : i32) : i32
  %2 = llvm.mlir.constant(-1 : index) : i64
  %3 = llvm.mlir.constant(0 : index) : i64
  %4 = llvm.mlir.constant(32 : i64) : i64
  %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
  %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
  %7 = llvm.load %6 : !llvm.ptr -> i32
  %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
  %9 = llvm.load %8 : !llvm.ptr -> i32
  %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
  %11 = llvm.load %10 : !llvm.ptr -> i32
  %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
  %13 = llvm.load %12 : !llvm.ptr -> i32
  %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
  %15 = llvm.load %14 : !llvm.ptr -> i32
  %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
  %17 = llvm.load %16 : !llvm.ptr -> i32
  %18 = llvm.zext %9 : i32 to i64
  %19 = llvm.shl %18, %4  : i64
  %20 = llvm.zext %7 : i32 to i64
  %21 = llvm.or %20, %19  : i64
  %22 = llvm.zext %13 : i32 to i64
  %23 = llvm.shl %22, %4  : i64
  %24 = llvm.zext %11 : i32 to i64
  %25 = llvm.or %24, %23  : i64
  %26 = llvm.zext %17 : i32 to i64
  %27 = llvm.shl %26, %4  : i64
  %28 = llvm.zext %15 : i32 to i64
  %29 = llvm.or %28, %27  : i64
  %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
  %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
  %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
  %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
  %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
  %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
  %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
  %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
  %38 = llvm.zext %37 : i32 to i64
  %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
  %40 = llvm.zext %39 : i32 to i64
  %41 = llvm.icmp "sle" %21, %3 : i64
  %42 = llvm.sub %3, %21  : i64
  %43 = llvm.sub %21, %0  : i64
  %44 = llvm.select %41, %42, %43 : i1, i64
  %45 = llvm.sdiv %44, %40  : i64
  %46 = llvm.sub %3, %45  : i64
  %47 = llvm.add %45, %0  : i64
  %48 = llvm.select %41, %46, %47 : i1, i64
  %49 = llvm.mul %38, %48  : i64
  %50 = llvm.mul %49, %2  : i64
  %51 = llvm.add %21, %50  : i64
  %52 = llvm.icmp "slt" %51, %48 : i64
  %53 = llvm.select %52, %51, %48 : i1, i64
  %54 = llvm.add %25, %50  : i64
  %55 = llvm.icmp "slt" %54, %48 : i64
  %56 = llvm.select %55, %54, %48 : i1, i64
  %57 = llvm.mul %49, %25  : i64
  %58 = llvm.add %49, %57  : i64
  %59 = llvm.mul %49, %29  : i64
  %60 = llvm.add %49, %59  : i64
  %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
  %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
  %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
  %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
  %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
  llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
  %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
  %77 = llvm.load %76 : !llvm.ptr<i32>
  %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
  %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
  %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
  %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
  %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
  %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
  %84 = llvm.load %83 : !llvm.ptr<ptr>
  %85 = llvm.load %81 : !llvm.ptr<ptr>
  %86 = llvm.mlir.null : !llvm.ptr
  %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
  %88 = llvm.icmp "eq" %87, %1 : i32
  llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
^bb1(%89: i32):  // pred: ^bb0
  llvm.return %89 : i32
^bb2:  // pred: ^bb0
  llvm.return %1 : i32
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateTargetExecutableVariantsPass (iree-hal-translate-target-executable-variants) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
  hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
  ^bb0(%arg0: !hal.device, %arg1: index):
    %c1 = arith.constant 1 : index
    hal.return %arg1, %c1, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
    llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
    llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(1 : index) : i64
      %1 = llvm.mlir.constant(0 : i32) : i32
      %2 = llvm.mlir.constant(-1 : index) : i64
      %3 = llvm.mlir.constant(0 : index) : i64
      %4 = llvm.mlir.constant(32 : i64) : i64
      %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %7 = llvm.load %6 : !llvm.ptr -> i32
      %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
      %9 = llvm.load %8 : !llvm.ptr -> i32
      %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
      %11 = llvm.load %10 : !llvm.ptr -> i32
      %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
      %13 = llvm.load %12 : !llvm.ptr -> i32
      %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
      %15 = llvm.load %14 : !llvm.ptr -> i32
      %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
      %17 = llvm.load %16 : !llvm.ptr -> i32
      %18 = llvm.zext %9 : i32 to i64
      %19 = llvm.shl %18, %4  : i64
      %20 = llvm.zext %7 : i32 to i64
      %21 = llvm.or %20, %19  : i64
      %22 = llvm.zext %13 : i32 to i64
      %23 = llvm.shl %22, %4  : i64
      %24 = llvm.zext %11 : i32 to i64
      %25 = llvm.or %24, %23  : i64
      %26 = llvm.zext %17 : i32 to i64
      %27 = llvm.shl %26, %4  : i64
      %28 = llvm.zext %15 : i32 to i64
      %29 = llvm.or %28, %27  : i64
      %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
      %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
      %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
      %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %38 = llvm.zext %37 : i32 to i64
      %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %40 = llvm.zext %39 : i32 to i64
      %41 = llvm.icmp "sle" %21, %3 : i64
      %42 = llvm.sub %3, %21  : i64
      %43 = llvm.sub %21, %0  : i64
      %44 = llvm.select %41, %42, %43 : i1, i64
      %45 = llvm.sdiv %44, %40  : i64
      %46 = llvm.sub %3, %45  : i64
      %47 = llvm.add %45, %0  : i64
      %48 = llvm.select %41, %46, %47 : i1, i64
      %49 = llvm.mul %38, %48  : i64
      %50 = llvm.mul %49, %2  : i64
      %51 = llvm.add %21, %50  : i64
      %52 = llvm.icmp "slt" %51, %48 : i64
      %53 = llvm.select %52, %51, %48 : i1, i64
      %54 = llvm.add %25, %50  : i64
      %55 = llvm.icmp "slt" %54, %48 : i64
      %56 = llvm.select %55, %54, %48 : i1, i64
      %57 = llvm.mul %49, %25  : i64
      %58 = llvm.add %49, %57  : i64
      %59 = llvm.mul %49, %29  : i64
      %60 = llvm.add %49, %59  : i64
      %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
      %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
      %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
      %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
      %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
      %77 = llvm.load %76 : !llvm.ptr<i32>
      %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
      %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %84 = llvm.load %83 : !llvm.ptr<ptr>
      %85 = llvm.load %81 : !llvm.ptr<ptr>
      %86 = llvm.mlir.null : !llvm.ptr
      %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
      %88 = llvm.icmp "eq" %87, %1 : i32
      llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
    ^bb1(%89: i32):  // pred: ^bb0
      llvm.return %89 : i32
    ^bb2:  // pred: ^bb0
      llvm.return %1 : i32
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::TranslateExecutablesPass (iree-hal-translate-executables) //----- //
hal.executable private @_matmul_aie_offload_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
    hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
    ^bb0(%arg0: !hal.device, %arg1: index):
      %c1 = arith.constant 1 : index
      hal.return %arg1, %c1, %c1 : index, index, index
    }
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
      llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
      llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
        %0 = llvm.mlir.constant(1 : index) : i64
        %1 = llvm.mlir.constant(0 : i32) : i32
        %2 = llvm.mlir.constant(-1 : index) : i64
        %3 = llvm.mlir.constant(0 : index) : i64
        %4 = llvm.mlir.constant(32 : i64) : i64
        %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %7 = llvm.load %6 : !llvm.ptr -> i32
        %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
        %9 = llvm.load %8 : !llvm.ptr -> i32
        %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
        %11 = llvm.load %10 : !llvm.ptr -> i32
        %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
        %13 = llvm.load %12 : !llvm.ptr -> i32
        %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
        %15 = llvm.load %14 : !llvm.ptr -> i32
        %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
        %17 = llvm.load %16 : !llvm.ptr -> i32
        %18 = llvm.zext %9 : i32 to i64
        %19 = llvm.shl %18, %4  : i64
        %20 = llvm.zext %7 : i32 to i64
        %21 = llvm.or %20, %19  : i64
        %22 = llvm.zext %13 : i32 to i64
        %23 = llvm.shl %22, %4  : i64
        %24 = llvm.zext %11 : i32 to i64
        %25 = llvm.or %24, %23  : i64
        %26 = llvm.zext %17 : i32 to i64
        %27 = llvm.shl %26, %4  : i64
        %28 = llvm.zext %15 : i32 to i64
        %29 = llvm.or %28, %27  : i64
        %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
        %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
        %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
        %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
        %38 = llvm.zext %37 : i32 to i64
        %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %40 = llvm.zext %39 : i32 to i64
        %41 = llvm.icmp "sle" %21, %3 : i64
        %42 = llvm.sub %3, %21  : i64
        %43 = llvm.sub %21, %0  : i64
        %44 = llvm.select %41, %42, %43 : i1, i64
        %45 = llvm.sdiv %44, %40  : i64
        %46 = llvm.sub %3, %45  : i64
        %47 = llvm.add %45, %0  : i64
        %48 = llvm.select %41, %46, %47 : i1, i64
        %49 = llvm.mul %38, %48  : i64
        %50 = llvm.mul %49, %2  : i64
        %51 = llvm.add %21, %50  : i64
        %52 = llvm.icmp "slt" %51, %48 : i64
        %53 = llvm.select %52, %51, %48 : i1, i64
        %54 = llvm.add %25, %50  : i64
        %55 = llvm.icmp "slt" %54, %48 : i64
        %56 = llvm.select %55, %54, %48 : i1, i64
        %57 = llvm.mul %49, %25  : i64
        %58 = llvm.add %49, %57  : i64
        %59 = llvm.mul %49, %29  : i64
        %60 = llvm.add %49, %59  : i64
        %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
        %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
        %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
        %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
        %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
        %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
        %77 = llvm.load %76 : !llvm.ptr<i32>
        %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
        %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
        %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
        %84 = llvm.load %83 : !llvm.ptr<ptr>
        %85 = llvm.load %81 : !llvm.ptr<ptr>
        %86 = llvm.mlir.null : !llvm.ptr
        %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
        %88 = llvm.icmp "eq" %87, %1 : i32
        llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
      ^bb1(%89: i32):  // pred: ^bb0
        llvm.return %89 : i32
      ^bb2:  // pred: ^bb0
        llvm.return %1 : i32
      }
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::{anonymous}::ConvertToHALPass (iree-hal-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c0 = arith.constant 0 : index
    %c1_i32_3 = arith.constant 1 : i32
    %c553648160_i32_4 = arith.constant 553648160 : i32
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32_4) encoding(%c1_i32_3) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
        ^bb1(%89: i32):  // pred: ^bb0
          llvm.return %89 : i32
        ^bb2:  // pred: ^bb0
          llvm.return %1 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64_1 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_0 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %18 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    hal.device.switch<%18 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%18 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      %c0_2 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c2_3 = arith.constant 2 : index
      %c0_4 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_4] bindings([
        %c0_2 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2_3 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      %c1_5 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1_5, %c1_5])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %19 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_0 : !hal.device> affinity(%c-1_i64_1) wait(%19) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::FixupLegacySyncPass (iree-hal-fixup-legacy-sync) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator_2 : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c0 = arith.constant 0 : index
    %c1_i32_3 = arith.constant 1 : i32
    %c553648160_i32_4 = arith.constant 553648160 : i32
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32_4) encoding(%c1_i32_3) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
        ^bb1(%89: i32):  // pred: ^bb0
          llvm.return %89 : i32
        ^bb2:  // pred: ^bb0
          llvm.return %1 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %device_0 = hal.ex.shared_device : !hal.device
    %c-1_i64_1 = arith.constant -1 : i64
    %cmd = hal.command_buffer.create device(%device_0 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %18 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    hal.device.switch<%18 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%18 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      %c0_2 = arith.constant 0 : index
      %c1 = arith.constant 1 : index
      %c2_3 = arith.constant 2 : index
      %c0_4 = arith.constant 0 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0_4] bindings([
        %c0_2 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2_3 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      %c1_5 = arith.constant 1 : index
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1_5, %c1_5])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %19 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_0 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_0 : !hal.device> affinity(%c-1_i64_1) wait(%19) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %c-1_i32 = arith.constant -1 : i32
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %c0 = arith.constant 0 : index
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
        ^bb1(%89: i32):  // pred: ^bb0
          llvm.return %89 : i32
        ^bb2:  // pred: ^bb0
          llvm.return %1 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %c-1_i64 = arith.constant -1 : i64
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %18 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    hal.device.switch<%18 : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%18 : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      %c1 = arith.constant 1 : index
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %19 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%19) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
        ^bb1(%89: i32):  // pred: ^bb0
          llvm.return %89 : i32
        ^bb2:  // pred: ^bb0
          llvm.return %1 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb2, ^bb1(%87 : i32)
        ^bb1(%89: i32):  // pred: ^bb0
          llvm.return %89 : i32
        ^bb2:  // pred: ^bb0
          llvm.return %1 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %c1 = arith.constant 1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
    %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
    hal.return
  }
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After LLVMCPULinkExecutables (iree-llvmcpu-link-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
hal.executable private @_matmul_aie_offload_dispatch_0 {
  hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
    hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
    ^bb0(%arg0: !hal.device, %arg1: index):
      %c1 = arith.constant 1 : index
      hal.return %arg1, %c1, %c1 : index, index, index
    }
    builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
      llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
      llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
      llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
        %0 = llvm.mlir.constant(1 : index) : i64
        %1 = llvm.mlir.constant(0 : i32) : i32
        %2 = llvm.mlir.constant(-1 : index) : i64
        %3 = llvm.mlir.constant(0 : index) : i64
        %4 = llvm.mlir.constant(32 : i64) : i64
        %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
        %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %7 = llvm.load %6 : !llvm.ptr -> i32
        %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
        %9 = llvm.load %8 : !llvm.ptr -> i32
        %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
        %11 = llvm.load %10 : !llvm.ptr -> i32
        %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
        %13 = llvm.load %12 : !llvm.ptr -> i32
        %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
        %15 = llvm.load %14 : !llvm.ptr -> i32
        %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
        %17 = llvm.load %16 : !llvm.ptr -> i32
        %18 = llvm.zext %9 : i32 to i64
        %19 = llvm.shl %18, %4  : i64
        %20 = llvm.zext %7 : i32 to i64
        %21 = llvm.or %20, %19  : i64
        %22 = llvm.zext %13 : i32 to i64
        %23 = llvm.shl %22, %4  : i64
        %24 = llvm.zext %11 : i32 to i64
        %25 = llvm.or %24, %23  : i64
        %26 = llvm.zext %17 : i32 to i64
        %27 = llvm.shl %26, %4  : i64
        %28 = llvm.zext %15 : i32 to i64
        %29 = llvm.or %28, %27  : i64
        %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
        %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
        %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
        %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
        %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
        %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
        %38 = llvm.zext %37 : i32 to i64
        %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
        %40 = llvm.zext %39 : i32 to i64
        %41 = llvm.icmp "sle" %21, %3 : i64
        %42 = llvm.sub %3, %21  : i64
        %43 = llvm.sub %21, %0  : i64
        %44 = llvm.select %41, %42, %43 : i1, i64
        %45 = llvm.sdiv %44, %40  : i64
        %46 = llvm.sub %3, %45  : i64
        %47 = llvm.add %45, %0  : i64
        %48 = llvm.select %41, %46, %47 : i1, i64
        %49 = llvm.mul %38, %48  : i64
        %50 = llvm.mul %49, %2  : i64
        %51 = llvm.add %21, %50  : i64
        %52 = llvm.icmp "slt" %51, %48 : i64
        %53 = llvm.select %52, %51, %48 : i1, i64
        %54 = llvm.add %25, %50  : i64
        %55 = llvm.icmp "slt" %54, %48 : i64
        %56 = llvm.select %55, %54, %48 : i1, i64
        %57 = llvm.mul %49, %25  : i64
        %58 = llvm.add %49, %57  : i64
        %59 = llvm.mul %49, %29  : i64
        %60 = llvm.add %49, %59  : i64
        %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
        %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
        %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
        %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
        %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
        llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
        %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
        %77 = llvm.load %76 : !llvm.ptr<i32>
        %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
        %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
        %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
        %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
        %84 = llvm.load %83 : !llvm.ptr<ptr>
        %85 = llvm.load %81 : !llvm.ptr<ptr>
        %86 = llvm.mlir.null : !llvm.ptr
        %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
        %88 = llvm.icmp "eq" %87, %1 : i32
        llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
      ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
        llvm.return %89 : i32
      }
    }
  }
}

// -----// IR Dump After LLVMCPUAssignConstantOrdinals (iree-llvmcpu-assign-constant-ordinals) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> {
  hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
  ^bb0(%arg0: !hal.device, %arg1: index):
    %c1 = arith.constant 1 : index
    hal.return %arg1, %c1, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.mlir.global internal @__import_ordinal_aie_matmul_f32() {addr_space = 0 : i32, hal.executable.import.key = "aie_matmul_f32", sym_visibility = "private"} : i32
    llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
    llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(1 : index) : i64
      %1 = llvm.mlir.constant(0 : i32) : i32
      %2 = llvm.mlir.constant(-1 : index) : i64
      %3 = llvm.mlir.constant(0 : index) : i64
      %4 = llvm.mlir.constant(32 : i64) : i64
      %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %7 = llvm.load %6 : !llvm.ptr -> i32
      %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
      %9 = llvm.load %8 : !llvm.ptr -> i32
      %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
      %11 = llvm.load %10 : !llvm.ptr -> i32
      %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
      %13 = llvm.load %12 : !llvm.ptr -> i32
      %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
      %15 = llvm.load %14 : !llvm.ptr -> i32
      %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
      %17 = llvm.load %16 : !llvm.ptr -> i32
      %18 = llvm.zext %9 : i32 to i64
      %19 = llvm.shl %18, %4  : i64
      %20 = llvm.zext %7 : i32 to i64
      %21 = llvm.or %20, %19  : i64
      %22 = llvm.zext %13 : i32 to i64
      %23 = llvm.shl %22, %4  : i64
      %24 = llvm.zext %11 : i32 to i64
      %25 = llvm.or %24, %23  : i64
      %26 = llvm.zext %17 : i32 to i64
      %27 = llvm.shl %26, %4  : i64
      %28 = llvm.zext %15 : i32 to i64
      %29 = llvm.or %28, %27  : i64
      %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
      %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
      %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
      %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %38 = llvm.zext %37 : i32 to i64
      %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %40 = llvm.zext %39 : i32 to i64
      %41 = llvm.icmp "sle" %21, %3 : i64
      %42 = llvm.sub %3, %21  : i64
      %43 = llvm.sub %21, %0  : i64
      %44 = llvm.select %41, %42, %43 : i1, i64
      %45 = llvm.sdiv %44, %40  : i64
      %46 = llvm.sub %3, %45  : i64
      %47 = llvm.add %45, %0  : i64
      %48 = llvm.select %41, %46, %47 : i1, i64
      %49 = llvm.mul %38, %48  : i64
      %50 = llvm.mul %49, %2  : i64
      %51 = llvm.add %21, %50  : i64
      %52 = llvm.icmp "slt" %51, %48 : i64
      %53 = llvm.select %52, %51, %48 : i1, i64
      %54 = llvm.add %25, %50  : i64
      %55 = llvm.icmp "slt" %54, %48 : i64
      %56 = llvm.select %55, %54, %48 : i1, i64
      %57 = llvm.mul %49, %25  : i64
      %58 = llvm.add %49, %57  : i64
      %59 = llvm.mul %49, %29  : i64
      %60 = llvm.add %49, %59  : i64
      %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
      %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
      %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
      %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
      %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
      %77 = llvm.load %76 : !llvm.ptr<i32>
      %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
      %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %84 = llvm.load %83 : !llvm.ptr<ptr>
      %85 = llvm.load %81 : !llvm.ptr<ptr>
      %86 = llvm.mlir.null : !llvm.ptr
      %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
      %88 = llvm.icmp "eq" %87, %1 : i32
      llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
    ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
      llvm.return %89 : i32
    }
  }
}

// -----// IR Dump After LLVMCPUAssignImportOrdinals (iree-llvmcpu-assign-import-ordinals) //----- //
hal.executable.variant public @embedded_elf_x86_64, target = <"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}> attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
  hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>) attributes {translation_info = #iree_codegen.translation_info<CPUDefault>} {
  ^bb0(%arg0: !hal.device, %arg1: index):
    %c1 = arith.constant 1 : index
    hal.return %arg1, %c1, %c1 : index, index, index
  }
  builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
    llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
    llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
    llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
      %0 = llvm.mlir.constant(1 : index) : i64
      %1 = llvm.mlir.constant(0 : i32) : i32
      %2 = llvm.mlir.constant(-1 : index) : i64
      %3 = llvm.mlir.constant(0 : index) : i64
      %4 = llvm.mlir.constant(32 : i64) : i64
      %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
      %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %7 = llvm.load %6 : !llvm.ptr -> i32
      %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
      %9 = llvm.load %8 : !llvm.ptr -> i32
      %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
      %11 = llvm.load %10 : !llvm.ptr -> i32
      %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
      %13 = llvm.load %12 : !llvm.ptr -> i32
      %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
      %15 = llvm.load %14 : !llvm.ptr -> i32
      %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
      %17 = llvm.load %16 : !llvm.ptr -> i32
      %18 = llvm.zext %9 : i32 to i64
      %19 = llvm.shl %18, %4  : i64
      %20 = llvm.zext %7 : i32 to i64
      %21 = llvm.or %20, %19  : i64
      %22 = llvm.zext %13 : i32 to i64
      %23 = llvm.shl %22, %4  : i64
      %24 = llvm.zext %11 : i32 to i64
      %25 = llvm.or %24, %23  : i64
      %26 = llvm.zext %17 : i32 to i64
      %27 = llvm.shl %26, %4  : i64
      %28 = llvm.zext %15 : i32 to i64
      %29 = llvm.or %28, %27  : i64
      %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
      %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
      %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
      %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
      %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
      %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %38 = llvm.zext %37 : i32 to i64
      %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
      %40 = llvm.zext %39 : i32 to i64
      %41 = llvm.icmp "sle" %21, %3 : i64
      %42 = llvm.sub %3, %21  : i64
      %43 = llvm.sub %21, %0  : i64
      %44 = llvm.select %41, %42, %43 : i1, i64
      %45 = llvm.sdiv %44, %40  : i64
      %46 = llvm.sub %3, %45  : i64
      %47 = llvm.add %45, %0  : i64
      %48 = llvm.select %41, %46, %47 : i1, i64
      %49 = llvm.mul %38, %48  : i64
      %50 = llvm.mul %49, %2  : i64
      %51 = llvm.add %21, %50  : i64
      %52 = llvm.icmp "slt" %51, %48 : i64
      %53 = llvm.select %52, %51, %48 : i1, i64
      %54 = llvm.add %25, %50  : i64
      %55 = llvm.icmp "slt" %54, %48 : i64
      %56 = llvm.select %55, %54, %48 : i1, i64
      %57 = llvm.mul %49, %25  : i64
      %58 = llvm.add %49, %57  : i64
      %59 = llvm.mul %49, %29  : i64
      %60 = llvm.add %49, %59  : i64
      %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
      %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
      %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
      %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
      %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
      llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
      %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
      %77 = llvm.load %76 : !llvm.ptr<i32>
      %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
      %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
      %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
      %84 = llvm.load %83 : !llvm.ptr<ptr>
      %85 = llvm.load %81 : !llvm.ptr<ptr>
      %86 = llvm.mlir.null : !llvm.ptr
      %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
      %88 = llvm.icmp "eq" %87, %1 : i32
      llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
    ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
      llvm.return %89 : i32
    }
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkTargetExecutablesPass (iree-hal-link-target-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::LinkExecutablesPass (iree-hal-link-executables) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      hal.command_buffer.dispatch.symbol<%cmd : !hal.command_buffer> target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64::@_matmul_aie_offload_dispatch_0) workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ResolveExportOrdinalsPass (iree-hal-resolve-export-ordinals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %pipeline_layout = hal.pipeline_layout.lookup device(%device : !hal.device) layout(#pipeline_layout) : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%pipeline_layout : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      %19 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %exe = hal.executable.lookup device(%19 : !hal.device) executable(@_matmul_aie_offload_dispatch_0) : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%exe : !hal.executable)[0] workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MaterializeResourceCachesPass (iree-hal-materialize-resource-caches) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %0 = hal.device.switch<%device : !hal.device> -> !hal.executable
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
      hal.return %exe : !hal.executable
    },
    #hal.match.always {
      %1 = util.null : !hal.executable
      hal.return %1 : !hal.executable
    }
    util.global.store %0, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    hal.device.switch<%device : !hal.device>
    #hal.device.match.executable.format<"embedded-elf-x86_64"> {
      %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
      hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
      hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
        %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
        %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
        %c2 = (%buffer : !hal.buffer)[%c0, %1]
      ])
      %19 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
      %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
      hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
      hal.return
    }
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb5(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %true = arith.constant true
  cf.cond_br %true, ^bb3, ^bb4
^bb3:  // pred: ^bb2
  %0 = util.null : !hal.executable
  cf.br ^bb5(%0 : !hal.executable)
^bb4:  // pred: ^bb2
  util.unreachable "device not supported in the compiled configuration"
^bb5(%1: !hal.executable):  // 2 preds: ^bb1, ^bb3
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::InlineDeviceSwitchesPass (iree-hal-inline-device-switches) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %c1 = arith.constant 1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  %18 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  cf.br ^bb3
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
^bb3:  // pred: ^bb1
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %19 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%19) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::MemoizeDeviceQueriesPass (iree-hal-memoize-device-queries) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb5(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %true = arith.constant true
    cf.cond_br %true, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %0 = util.null : !hal.executable
    cf.br ^bb5(%0 : !hal.executable)
  ^bb4:  // pred: ^bb2
    util.unreachable "device not supported in the compiled configuration"
  ^bb5(%1: !hal.executable):  // 2 preds: ^bb1, ^bb3
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0_ok = util.global.load @_device_query_0_ok : i1
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    %18 = hal.command_buffer.device<%cmd : !hal.command_buffer> : !hal.device
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  ^bb3:  // pred: ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %19 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%19) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb5(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %true = arith.constant true
    cf.cond_br %true, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %0 = util.null : !hal.executable
    cf.br ^bb5(%0 : !hal.executable)
  ^bb4:  // pred: ^bb2
    util.unreachable "device not supported in the compiled configuration"
  ^bb5(%1: !hal.executable):  // 2 preds: ^bb1, ^bb3
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    cf.br ^bb3
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  ^bb3:  // pred: ^bb1
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %ok, @_device_query_0_ok : i1
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.global.store %ok, @_device_query_0_ok : i1
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %c1 = arith.constant 1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_device_query_0_ok : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.global.store %ok, @_device_query_0_ok : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::ElideRedundantCommandsPass (iree-hal-elide-redundant-commands) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    util.initializer.return
  }
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.initializer.return
  }
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer {
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    util.initializer.return
  }
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  util.global.store %value, @_device_query_0 : i1
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  %device = hal.ex.shared_device : !hal.device
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %device = hal.ex.shared_device : !hal.device
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After CombineInitializers (iree-util-combine-initializers) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#pipeline_layout = #hal.pipeline.layout<push_constants = 8, sets = [<0, bindings = [<0, storage_buffer, ReadOnly>, <1, storage_buffer, ReadOnly>, <2, storage_buffer>]>]>
#translation = #iree_codegen.translation_info<CPUDefault>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.variant public @embedded_elf_x86_64, target = #executable_target_embedded_elf_x86_64_ attributes {hal.executable.imports = [["aie_matmul_f32", false]]} {
      hal.executable.export public @_matmul_aie_offload_dispatch_0 ordinal(0) layout(#pipeline_layout) attributes {translation_info = #translation} {
      ^bb0(%arg0: !hal.device, %arg1: index):
        %c1 = arith.constant 1 : index
        hal.return %arg1, %c1, %c1 : index, index, index
      }
      builtin.module attributes {llvm.data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", llvm.target_triple = "x86_64-unknown-unknown-eabi-elf"} {
        llvm.mlir.global internal constant @__import_ordinal_aie_matmul_f32(0 : i32) {addr_space = 0 : i32, sym_visibility = "private"} : i32
        llvm.func @aie_matmul_f32(!llvm.ptr, i64, !llvm.ptr, i64, !llvm.ptr, i64, i64, i64, i64) attributes {hal.import.fields = ["processor_id", "processor_data"], llvm.bareptr = true}
        llvm.func @_matmul_aie_offload_dispatch_0(%arg0: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg1: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}, %arg2: !llvm.ptr {llvm.align = 16 : i64, llvm.noalias}) -> i32 {
          %0 = llvm.mlir.constant(1 : index) : i64
          %1 = llvm.mlir.constant(0 : i32) : i32
          %2 = llvm.mlir.constant(-1 : index) : i64
          %3 = llvm.mlir.constant(0 : index) : i64
          %4 = llvm.mlir.constant(32 : i64) : i64
          %5 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)>
          %6 = llvm.extractvalue %5[9] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %7 = llvm.load %6 : !llvm.ptr -> i32
          %8 = llvm.getelementptr %6[1] : (!llvm.ptr) -> !llvm.ptr, i32
          %9 = llvm.load %8 : !llvm.ptr -> i32
          %10 = llvm.getelementptr %6[2] : (!llvm.ptr) -> !llvm.ptr, i32
          %11 = llvm.load %10 : !llvm.ptr -> i32
          %12 = llvm.getelementptr %6[3] : (!llvm.ptr) -> !llvm.ptr, i32
          %13 = llvm.load %12 : !llvm.ptr -> i32
          %14 = llvm.getelementptr %6[6] : (!llvm.ptr) -> !llvm.ptr, i32
          %15 = llvm.load %14 : !llvm.ptr -> i32
          %16 = llvm.getelementptr %6[7] : (!llvm.ptr) -> !llvm.ptr, i32
          %17 = llvm.load %16 : !llvm.ptr -> i32
          %18 = llvm.zext %9 : i32 to i64
          %19 = llvm.shl %18, %4  : i64
          %20 = llvm.zext %7 : i32 to i64
          %21 = llvm.or %20, %19  : i64
          %22 = llvm.zext %13 : i32 to i64
          %23 = llvm.shl %22, %4  : i64
          %24 = llvm.zext %11 : i32 to i64
          %25 = llvm.or %24, %23  : i64
          %26 = llvm.zext %17 : i32 to i64
          %27 = llvm.shl %26, %4  : i64
          %28 = llvm.zext %15 : i32 to i64
          %29 = llvm.or %28, %27  : i64
          %30 = llvm.extractvalue %5[10] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %31 = llvm.load %30 : !llvm.ptr -> !llvm.ptr
          %32 = llvm.getelementptr %30[1] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %33 = llvm.load %32 : !llvm.ptr -> !llvm.ptr
          %34 = llvm.getelementptr %30[2] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr
          %35 = llvm.load %34 : !llvm.ptr -> !llvm.ptr
          %36 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)>
          %37 = llvm.extractvalue %36[0] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %38 = llvm.zext %37 : i32 to i64
          %39 = llvm.extractvalue %5[4] : !llvm.struct<"iree_hal_executable_dispatch_state_v0_t", (i32, i32, i16, i16, i32, i32, i16, i8, i8, ptr, ptr, ptr)> 
          %40 = llvm.zext %39 : i32 to i64
          %41 = llvm.icmp "sle" %21, %3 : i64
          %42 = llvm.sub %3, %21  : i64
          %43 = llvm.sub %21, %0  : i64
          %44 = llvm.select %41, %42, %43 : i1, i64
          %45 = llvm.sdiv %44, %40  : i64
          %46 = llvm.sub %3, %45  : i64
          %47 = llvm.add %45, %0  : i64
          %48 = llvm.select %41, %46, %47 : i1, i64
          %49 = llvm.mul %38, %48  : i64
          %50 = llvm.mul %49, %2  : i64
          %51 = llvm.add %21, %50  : i64
          %52 = llvm.icmp "slt" %51, %48 : i64
          %53 = llvm.select %52, %51, %48 : i1, i64
          %54 = llvm.add %25, %50  : i64
          %55 = llvm.icmp "slt" %54, %48 : i64
          %56 = llvm.select %55, %54, %48 : i1, i64
          %57 = llvm.mul %49, %25  : i64
          %58 = llvm.add %49, %57  : i64
          %59 = llvm.mul %49, %29  : i64
          %60 = llvm.add %49, %59  : i64
          %61 = llvm.extractvalue %36[4] : !llvm.struct<"iree_hal_executable_workgroup_state_v0_t", (i32, i32, i16, i16, i32, ptr, i32)> 
          %62 = llvm.getelementptr inbounds %arg0[4] : (!llvm.ptr) -> !llvm.ptr, !llvm.ptr<struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>>
          %63 = llvm.alloca %0 x !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> : (i64) -> !llvm.ptr
          %64 = llvm.mlir.undef : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>
          %65 = llvm.insertvalue %31, %64[0] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %66 = llvm.insertvalue %58, %65[1] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %67 = llvm.insertvalue %33, %66[2] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %68 = llvm.insertvalue %60, %67[3] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %69 = llvm.insertvalue %35, %68[4] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %70 = llvm.insertvalue %58, %69[5] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %71 = llvm.insertvalue %53, %70[6] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %72 = llvm.insertvalue %56, %71[7] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %73 = llvm.insertvalue %38, %72[8] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %74 = llvm.insertvalue %61, %73[9] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          %75 = llvm.insertvalue %62, %74[10] : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)> 
          llvm.store %75, %63 : !llvm.struct<(ptr, i64, ptr, i64, ptr, i64, i64, i64, i64, i32, ptr)>, !llvm.ptr
          %76 = llvm.mlir.addressof @__import_ordinal_aie_matmul_f32 : !llvm.ptr<i32>
          %77 = llvm.load %76 : !llvm.ptr<i32>
          %78 = llvm.load %arg0 : !llvm.ptr -> !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)>
          %79 = llvm.extractvalue %78[1] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %80 = llvm.extractvalue %78[2] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %81 = llvm.getelementptr %80[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %82 = llvm.extractvalue %78[3] : !llvm.struct<"iree_hal_executable_environment_v0_t", (ptr, ptr<func<i32 (ptr, ptr, ptr, ptr)>>, ptr<ptr>, ptr<ptr>, struct<"iree_hal_processor_v0_t", (array<8 x i64>)>)> 
          %83 = llvm.getelementptr %82[%77] : (!llvm.ptr<ptr>, i32) -> !llvm.ptr<ptr>
          %84 = llvm.load %83 : !llvm.ptr<ptr>
          %85 = llvm.load %81 : !llvm.ptr<ptr>
          %86 = llvm.mlir.null : !llvm.ptr
          %87 = llvm.call %79(%85, %63, %84, %86) : !llvm.ptr<func<i32 (ptr, ptr, ptr, ptr)>>, (!llvm.ptr, !llvm.ptr, !llvm.ptr, !llvm.ptr) -> i32
          %88 = llvm.icmp "eq" %87, %1 : i32
          llvm.cond_br %88 weights([1, 0]), ^bb1(%1 : i32), ^bb1(%87 : i32)
        ^bb1(%89: i32):  // 2 preds: ^bb0, ^bb0
          llvm.return %89 : i32
        }
      }
    }
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeTargetExecutablesPass (iree-hal-serialize-target-executables) //----- //
hal.executable private @_matmul_aie_offload_dispatch_0 {
  hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
}

// -----// IR Dump After mlir::iree_compiler::IREE::HAL::SerializeExecutablesPass (iree-hal-serialize-executables) //----- //
hal.executable private @_matmul_aie_offload_dispatch_0 {
  hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
}

// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %device_0 = hal.ex.shared_device : !hal.device
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device_0 : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %device_1 = hal.ex.shared_device : !hal.device
    %pipeline_layout = hal.pipeline_layout.create device(%device_1 : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %device_2 = hal.ex.shared_device : !hal.device
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device_2 : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    cf.br ^bb4
  ^bb4:  // pred: ^bb3
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    util.global.store %value, @_device_query_0 : i1
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %_descriptor_set_layout_0 = util.global.load @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%_descriptor_set_layout_0]) : !hal.pipeline_layout
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    %_device_query_0 = util.global.load @_device_query_0 : i1
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c2 = arith.constant 2 : index
    %c4 = arith.constant 4 : index
    %c0 = arith.constant 0 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %c2 = arith.constant 2 : index
  %c4 = arith.constant 4 : index
  %c0 = arith.constant 0 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_descriptor_set_layout_0 : !hal.descriptor_set_layout
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %descriptor_set_layout, @_descriptor_set_layout_0 : !hal.descriptor_set_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068090000000000000000000040003800070040001400120006000000040000004000000000000000400000000000000040000000000000008801000000000000880100000000000008000000000000000100000004000000000000000000000000000000000000000000000000000000180400000000000018040000000000000010000000000000010000000500000020040000000000002014000000000000201400000000000011010000000000001101000000000000001000000000000001000000060000004005000000000000402500000000000040250000000000006001000000000000600100000000000000100000000000000200000006000000E005000000000000E025000000000000E025000000000000C000000000000000C000000000000000080000000000000052E57464040000004005000000000000402500000000000040250000000000006001000000000000C00A000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120007002015000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279000000000000482500000000000008000000000000007003000000000000582500000000000008000000000000008F0300000000000060250000000000000800000000000000201400000000000068250000000000000800000000000000700300000000000070250000000000000800000000000000A40300000000000080250000000000000800000000000000A503000000000000902500000000000008000000000000004025000000000000A02500000000000008000000000000005825000000000000B02500000000000008000000000000006025000000000000B8250000000000000800000000000000A003000000000000C02500000000000008000000000000006825000000000000C82500000000000008000000000000007025000000000000D025000000000000080000000000000078250000000000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30006169655F6D61746D756C5F66333200000000000000006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000001400000000000000017A5200017810011B0C070890010000240000001C00000040100000F200000000410E108602430D064783068C058E048F0302E60C0708001000000044000000181100001100000000000000000000000000000000000000554889E5415741564154534989F8448B660C488B4618488B76204C8B5018488B084C8B48084C8B3E4C8B7608488B5E108B7A0C448B1A4889CA48F7DA488D41FF4885C9480F4EC24889C248C1EA207407489949F7FCEB0531D241F7F44889C248F7DA48FFC04885C9480F4EC24889C2490FAFD34829D14839C1480F4DC84D89CC4929D44939C44C0F4DE049FFC14C0FAFCA49FFC24C0FAFD2498D40204889E2488D72A04889F44C897AA04C894AA84C8972B04C8952B848895AC04C894AC848894AD04C8962D84C895AE0897AE8488942F0498B4010498B4818488B11488B3831C941FF5008488D65E05B415C415E415F5DC3CCCCCCCCCCCCCCCCCCCCCCCCCCCC31C083FF03488D0D64100000480F44C1C300000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000B000000170000000000000000000000000000000000000000000000000000000100000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000380100000000000009000000000000001800000000000000F9FFFF6F000000000D000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F80100000000000000000000000000000000000000000000011101250E1305030E1017B44219110112060000022E001101120640186E0E030E3A0B3B0B49133F190000032400030E3E0B0B0B0000004700000004000000000008013B0000002C0004000000000000002014000000000000F2000000022014000000000000F200000001561C0000001C0000000101430000000300000000050400696E74006D61746D756C5F6169655F6F66666C6F61642E6D6C6972005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30004952454500310000000200000000004B000000260000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F300000000000160000000200000000004B00000043000000696E7400000000007200000004002F000000010101FB0E0D000101010100000001000001006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000000000090220140000000000000105200AD6053906BA05204A050A060318743D050803714A050B4B050F030966024713050ACB7578060B02511202090001014952454500000000000000000000000000000000000000000000000000000000002300000000020900E0250000000000000000000000000000010000001200070020150000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E65685F6672616D65002E74657874002E646174612E72656C2E726F002E64796E616D6963002E64656275675F616262726576002E64656275675F696E666F002E64656275675F737472002E64656275675F7075626E616D6573002E64656275675F7075627479706573002E64656275675F6C696E65002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F0000000300000002000000000000001002000000000000100200000000000023000000000000000000000000000000010000000000000000000000000000001700000004000000020000000000000038020000000000003802000000000000380100000000000001000000000000000800000000000000180000000000000021000000010000000200000000000000700300000000000070030000000000004D0000000000000000000000000000000800000000000000000000000000000029000000010000000200000000000000C003000000000000C0030000000000005800000000000000000000000000000008000000000000000000000000000000330000000100000006000000000000002014000000000000200400000000000011010000000000000000000000000000100000000000000000000000000000003900000001000000030000000000000040250000000000004005000000000000A00000000000000000000000000000001000000000000000000000000000000046000000060000000300000000000000E025000000000000E005000000000000C0000000000000000300000000000000080000000000000010000000000000004F0000000100000000000000000000000000000000000000A00600000000000037000000000000000000000000000000010000000000000000000000000000005D0000000100000000000000000000000000000000000000D7060000000000004B00000000000000000000000000000001000000000000000000000000000000690000000100000030000000000000000000000000000000220700000000000040000000000000000000000000000000010000000000000001000000000000007400000001000000000000000000000000000000000000006207000000000000350000000000000000000000000000000100000000000000000000000000000084000000010000000000000000000000000000000000000097070000000000001A00000000000000000000000000000001000000000000000000000000000000940000000100000000000000000000000000000000000000B1070000000000007600000000000000000000000000000001000000000000000000000000000000A0000000010000003000000000000000000000000000000027080000000000000500000000000000000000000000000001000000000000000100000000000000A9000000020000000000000000000000000000000000000030080000000000004800000000000000130000000200000008000000000000001800000000000000B100000003000000000000000000000000000000000000007808000000000000C300000000000000000000000000000001000000000000000000000000000000BB00000003000000000000000000000000000000000000003B090000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After IPO (iree-util-ipo) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], iree.fixedpoint.iteration = 0 : index} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After FixedPointIterator (iree-util-fixed-point-iterator) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
    %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
  func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c0 = arith.constant 0 : index
    %c4 = arith.constant 4 : index
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = arith.muli %arg2, %c4 : index
    %1 = arith.muli %0, %arg3 : index
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
    %2 = arith.index_castui %arg2 : index to i64
    %3 = arith.trunci %2 : i64 to i32
    %4 = arith.shrui %2, %c32_i64 : i64
    %5 = arith.trunci %4 : i64 to i32
    %6 = arith.index_castui %arg3 : index to i64
    %7 = arith.trunci %6 : i64 to i32
    %8 = arith.shrui %6, %c32_i64 : i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.index_castui %arg6 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %arg7 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
      %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
      %c2 = (%buffer : !hal.buffer)[%c0, %1]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %18 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
    return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func private @_matmul_aie_offload(%arg0: !hal.buffer, %arg1: index, %arg2: index, %arg3: index, %arg4: !hal.buffer, %arg5: index, %arg6: index, %arg7: index) -> (!hal.fence, !hal.buffer, index) {
  %c1 = arith.constant 1 : index
  %c-1_i64 = arith.constant -1 : i64
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %c4 = arith.constant 4 : index
  %c2 = arith.constant 2 : index
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %0 = arith.muli %arg2, %c4 : index
  %1 = arith.muli %0, %arg3 : index
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  %buffer = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%1}
  %2 = arith.index_castui %arg2 : index to i64
  %3 = arith.trunci %2 : i64 to i32
  %4 = arith.shrui %2, %c32_i64 : i64
  %5 = arith.trunci %4 : i64 to i32
  %6 = arith.index_castui %arg3 : index to i64
  %7 = arith.trunci %6 : i64 to i32
  %8 = arith.shrui %6, %c32_i64 : i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.index_castui %arg6 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %arg7 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%3, %5, %7, %9, %11, %13, %15, %17]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%arg0 : !hal.buffer)[%c0, %arg1], 
    %c1 = (%arg4 : !hal.buffer)[%c0, %arg5], 
    %c2 = (%buffer : !hal.buffer)[%c0, %1]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %18 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%18) signal(%fence) commands([%cmd])
  return %fence, %buffer, %1 : !hal.fence, !hal.buffer, index
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %8:3 = call @_matmul_aie_offload(%buffer, %3, %0, %1, %buffer_0, %7, %4, %5) : (!hal.buffer, index, index, index, !hal.buffer, index, index, index) -> (!hal.fence, !hal.buffer, index)
  %status = hal.fence.await until([%8#0]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%8#1 : !hal.buffer)[%c0, %8#2] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c2 = arith.constant 2 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %8 = arith.muli %0, %c4 : index
    %9 = arith.muli %8, %1 : index
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %1 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.index_castui %4 : index to i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.shrui %18, %c32_i64 : i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.index_castui %5 : index to i64
    %23 = arith.trunci %22 : i64 to i32
    %24 = arith.shrui %22, %c32_i64 : i64
    %25 = arith.trunci %24 : i64 to i32
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %26 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c2 = arith.constant 2 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %8 = arith.muli %0, %c4 : index
    %9 = arith.muli %8, %1 : index
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %1 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.index_castui %4 : index to i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.shrui %18, %c32_i64 : i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.index_castui %5 : index to i64
    %23 = arith.trunci %22 : i64 to i32
    %24 = arith.shrui %22, %c32_i64 : i64
    %25 = arith.trunci %24 : i64 to i32
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %26 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068090000000000000000000040003800070040001400120006000000040000004000000000000000400000000000000040000000000000008801000000000000880100000000000008000000000000000100000004000000000000000000000000000000000000000000000000000000180400000000000018040000000000000010000000000000010000000500000020040000000000002014000000000000201400000000000011010000000000001101000000000000001000000000000001000000060000004005000000000000402500000000000040250000000000006001000000000000600100000000000000100000000000000200000006000000E005000000000000E025000000000000E025000000000000C000000000000000C000000000000000080000000000000052E57464040000004005000000000000402500000000000040250000000000006001000000000000C00A000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120007002015000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279000000000000482500000000000008000000000000007003000000000000582500000000000008000000000000008F0300000000000060250000000000000800000000000000201400000000000068250000000000000800000000000000700300000000000070250000000000000800000000000000A40300000000000080250000000000000800000000000000A503000000000000902500000000000008000000000000004025000000000000A02500000000000008000000000000005825000000000000B02500000000000008000000000000006025000000000000B8250000000000000800000000000000A003000000000000C02500000000000008000000000000006825000000000000C82500000000000008000000000000007025000000000000D025000000000000080000000000000078250000000000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30006169655F6D61746D756C5F66333200000000000000006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000001400000000000000017A5200017810011B0C070890010000240000001C00000040100000F200000000410E108602430D064783068C058E048F0302E60C0708001000000044000000181100001100000000000000000000000000000000000000554889E5415741564154534989F8448B660C488B4618488B76204C8B5018488B084C8B48084C8B3E4C8B7608488B5E108B7A0C448B1A4889CA48F7DA488D41FF4885C9480F4EC24889C248C1EA207407489949F7FCEB0531D241F7F44889C248F7DA48FFC04885C9480F4EC24889C2490FAFD34829D14839C1480F4DC84D89CC4929D44939C44C0F4DE049FFC14C0FAFCA49FFC24C0FAFD2498D40204889E2488D72A04889F44C897AA04C894AA84C8972B04C8952B848895AC04C894AC848894AD04C8962D84C895AE0897AE8488942F0498B4010498B4818488B11488B3831C941FF5008488D65E05B415C415E415F5DC3CCCCCCCCCCCCCCCCCCCCCCCCCCCC31C083FF03488D0D64100000480F44C1C300000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000B000000170000000000000000000000000000000000000000000000000000000100000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000380100000000000009000000000000001800000000000000F9FFFF6F000000000D000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F80100000000000000000000000000000000000000000000011101250E1305030E1017B44219110112060000022E001101120640186E0E030E3A0B3B0B49133F190000032400030E3E0B0B0B0000004700000004000000000008013B0000002C0004000000000000002014000000000000F2000000022014000000000000F200000001561C0000001C0000000101430000000300000000050400696E74006D61746D756C5F6169655F6F66666C6F61642E6D6C6972005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30004952454500310000000200000000004B000000260000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F300000000000160000000200000000004B00000043000000696E7400000000007200000004002F000000010101FB0E0D000101010100000001000001006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000000000090220140000000000000105200AD6053906BA05204A050A060318743D050803714A050B4B050F030966024713050ACB7578060B02511202090001014952454500000000000000000000000000000000000000000000000000000000002300000000020900E0250000000000000000000000000000010000001200070020150000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E65685F6672616D65002E74657874002E646174612E72656C2E726F002E64796E616D6963002E64656275675F616262726576002E64656275675F696E666F002E64656275675F737472002E64656275675F7075626E616D6573002E64656275675F7075627479706573002E64656275675F6C696E65002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F0000000300000002000000000000001002000000000000100200000000000023000000000000000000000000000000010000000000000000000000000000001700000004000000020000000000000038020000000000003802000000000000380100000000000001000000000000000800000000000000180000000000000021000000010000000200000000000000700300000000000070030000000000004D0000000000000000000000000000000800000000000000000000000000000029000000010000000200000000000000C003000000000000C0030000000000005800000000000000000000000000000008000000000000000000000000000000330000000100000006000000000000002014000000000000200400000000000011010000000000000000000000000000100000000000000000000000000000003900000001000000030000000000000040250000000000004005000000000000A00000000000000000000000000000001000000000000000000000000000000046000000060000000300000000000000E025000000000000E005000000000000C0000000000000000300000000000000080000000000000010000000000000004F0000000100000000000000000000000000000000000000A00600000000000037000000000000000000000000000000010000000000000000000000000000005D0000000100000000000000000000000000000000000000D7060000000000004B00000000000000000000000000000001000000000000000000000000000000690000000100000030000000000000000000000000000000220700000000000040000000000000000000000000000000010000000000000001000000000000007400000001000000000000000000000000000000000000006207000000000000350000000000000000000000000000000100000000000000000000000000000084000000010000000000000000000000000000000000000097070000000000001A00000000000000000000000000000001000000000000000000000000000000940000000100000000000000000000000000000000000000B1070000000000007600000000000000000000000000000001000000000000000000000000000000A0000000010000003000000000000000000000000000000027080000000000000500000000000000000000000000000001000000000000000100000000000000A9000000020000000000000000000000000000000000000030080000000000004800000000000000130000000200000008000000000000001800000000000000B100000003000000000000000000000000000000000000007808000000000000C300000000000000000000000000000001000000000000000000000000000000BB00000003000000000000000000000000000000000000003B090000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SCFForLoopCanonicalization (scf-for-loop-canonicalization) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopCoalescing (affine-loop-coalescing) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After LoopInvariantCodeMotion (loop-invariant-code-motion) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ArithUnsignedWhenEquivalent (arith-unsigned-when-equivalent) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %8 = arith.muli %0, %c4 : index
  %9 = arith.muli %8, %1 : index
  %device_1 = hal.ex.shared_device : !hal.device
  %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
  %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
  %10 = arith.index_castui %0 : index to i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.shrui %10, %c32_i64 : i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.index_castui %1 : index to i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.shrui %14, %c32_i64 : i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.index_castui %4 : index to i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.shrui %18, %c32_i64 : i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.index_castui %5 : index to i64
  %23 = arith.trunci %22 : i64 to i32
  %24 = arith.shrui %22, %c32_i64 : i64
  %25 = arith.trunci %24 : i64 to i32
  %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %26 = util.null : !hal.fence
  %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After PropagateSubranges (iree-util-propagate-subranges) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c2 = arith.constant 2 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %8 = arith.muli %0, %c4 : index
    %9 = arith.muli %8, %1 : index
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %1 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.index_castui %4 : index to i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.shrui %18, %c32_i64 : i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.index_castui %5 : index to i64
    %23 = arith.trunci %22 : i64 to i32
    %24 = arith.shrui %22, %c32_i64 : i64
    %25 = arith.trunci %24 : i64 to i32
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %26 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c2 = arith.constant 2 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %8 = arith.muli %0, %c4 : index
    %9 = arith.muli %8, %1 : index
    %device_1 = hal.ex.shared_device : !hal.device
    %allocator_2 = hal.device.allocator<%device_1 : !hal.device> : !hal.allocator
    %buffer_3 = hal.allocator.allocate<%allocator_2 : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%9}
    %10 = arith.index_castui %0 : index to i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.shrui %10, %c32_i64 : i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.index_castui %1 : index to i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.shrui %14, %c32_i64 : i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.index_castui %4 : index to i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.shrui %18, %c32_i64 : i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.index_castui %5 : index to i64
    %23 = arith.trunci %22 : i64 to i32
    %24 = arith.shrui %22, %c32_i64 : i64
    %25 = arith.trunci %24 : i64 to i32
    %cmd = hal.command_buffer.create device(%device_1 : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%11, %13, %15, %17, %19, %21, %23, %25]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_3 : !hal.buffer)[%c0, %9]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %26 = util.null : !hal.fence
    %fence = hal.fence.create device(%device_1 : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device_1 : !hal.device> affinity(%c-1_i64) wait(%26) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_3 : !hal.buffer)[%c0, %9] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c2 = arith.constant 2 : index
    %c32_i64 = arith.constant 32 : i64
    %c-1_i64 = arith.constant -1 : i64
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c-1_i32 = arith.constant -1 : i32
    %c4 = arith.constant 4 : index
    %c1_i32 = arith.constant 1 : i32
    %c553648160_i32 = arith.constant 553648160 : i32
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %buffer_1 = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%3}
    %8 = arith.index_castui %0 : index to i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.shrui %8, %c32_i64 : i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.index_castui %1 : index to i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.shrui %12, %c32_i64 : i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.index_castui %4 : index to i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.shrui %16, %c32_i64 : i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.index_castui %5 : index to i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.shrui %20, %c32_i64 : i64
    %23 = arith.trunci %22 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%9, %11, %13, %15, %17, %19, %21, %23]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %3]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %24 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%24) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
util.initializer {
  %device = hal.ex.shared_device : !hal.device
  %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
  %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
  %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
  util.global.store %value, @_device_query_0 : i1
  util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
  cf.cond_br %value, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
  cf.br ^bb3(%exe : !hal.executable)
^bb2:  // pred: ^bb0
  %0 = util.null : !hal.executable
  cf.br ^bb3(%0 : !hal.executable)
^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
  util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer.return
}

// -----// IR Dump After SimplifyGlobalAccesses (iree-util-simplify-global-accesses) //----- //
func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
  %_device_query_0 = util.global.load @_device_query_0 : i1
  %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
  %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  %c2 = arith.constant 2 : index
  %c32_i64 = arith.constant 32 : i64
  %c-1_i64 = arith.constant -1 : i64
  %c1 = arith.constant 1 : index
  %c0 = arith.constant 0 : index
  %c-1_i32 = arith.constant -1 : i32
  %c4 = arith.constant 4 : index
  %c1_i32 = arith.constant 1 : i32
  %c553648160_i32 = arith.constant 553648160 : i32
  %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
  %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
  %device = hal.ex.shared_device : !hal.device
  %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
  hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
  %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
  hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
  %6 = arith.muli %4, %c4 : index
  %7 = arith.muli %6, %5 : index
  %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
  hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
  %buffer_1 = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%3}
  %8 = arith.index_castui %0 : index to i64
  %9 = arith.trunci %8 : i64 to i32
  %10 = arith.shrui %8, %c32_i64 : i64
  %11 = arith.trunci %10 : i64 to i32
  %12 = arith.index_castui %1 : index to i64
  %13 = arith.trunci %12 : i64 to i32
  %14 = arith.shrui %12, %c32_i64 : i64
  %15 = arith.trunci %14 : i64 to i32
  %16 = arith.index_castui %4 : index to i64
  %17 = arith.trunci %16 : i64 to i32
  %18 = arith.shrui %16, %c32_i64 : i64
  %19 = arith.trunci %18 : i64 to i32
  %20 = arith.index_castui %5 : index to i64
  %21 = arith.trunci %20 : i64 to i32
  %22 = arith.shrui %20, %c32_i64 : i64
  %23 = arith.trunci %22 : i64 to i32
  %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
  cf.cond_br %_device_query_0, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%9, %11, %13, %15, %17, %19, %21, %23]) : i32, i32, i32, i32, i32, i32, i32, i32
  hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
    %c0 = (%buffer : !hal.buffer)[%c0, %3], 
    %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
    %c2 = (%buffer_1 : !hal.buffer)[%c0, %3]
  ])
  hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
  hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
  hal.command_buffer.finalize<%cmd : !hal.command_buffer>
  %24 = util.null : !hal.fence
  %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
  hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%24) signal(%fence) commands([%cmd])
  %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
  util.status.check_ok %status, "failed to wait on timepoint"
  %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
  return %view : !hal.buffer_view
^bb2:  // pred: ^bb0
  util.unreachable "device not supported in the compiled configuration"
}

// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %buffer_1 = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%3}
    %8 = arith.index_castui %0 : index to i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.shrui %8, %c32_i64 : i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.index_castui %1 : index to i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.shrui %12, %c32_i64 : i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.index_castui %4 : index to i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.shrui %16, %c32_i64 : i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.index_castui %5 : index to i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.shrui %20, %c32_i64 : i64
    %23 = arith.trunci %22 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%9, %11, %13, %15, %17, %19, %21, %23]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %3]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %24 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%24) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %buffer_1 = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%3}
    %8 = arith.index_castui %0 : index to i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.shrui %8, %c32_i64 : i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.index_castui %1 : index to i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.shrui %12, %c32_i64 : i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.index_castui %4 : index to i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.shrui %16, %c32_i64 : i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.index_castui %5 : index to i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.shrui %20, %c32_i64 : i64
    %23 = arith.trunci %22 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%9, %11, %13, %15, %17, %19, %21, %23]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %3]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %24 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%24) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu]} {
  util.global private @_device_query_0 : i1
  util.global private @_pipeline_layout_0 : !hal.pipeline_layout
  util.global private @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
  util.initializer {
    %device = hal.ex.shared_device : !hal.device
    %ok, %value = hal.device.query<%device : !hal.device> key("hal.executable.format" :: "embedded-elf-x86_64") : i1, i1 = false
    %descriptor_set_layout = hal.descriptor_set_layout.create device(%device : !hal.device) flags("None") bindings([#hal.descriptor_set.binding<0, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<1, storage_buffer, ReadOnly>, #hal.descriptor_set.binding<2, storage_buffer>]) : !hal.descriptor_set_layout
    %pipeline_layout = hal.pipeline_layout.create device(%device : !hal.device) push_constants(8) layouts([%descriptor_set_layout]) : !hal.pipeline_layout
    util.global.store %value, @_device_query_0 : i1
    util.global.store %pipeline_layout, @_pipeline_layout_0 : !hal.pipeline_layout
    cf.cond_br %value, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %exe = hal.executable.create device(%device : !hal.device) target(@_matmul_aie_offload_dispatch_0::@embedded_elf_x86_64) layouts([%_pipeline_layout_0]) : !hal.executable
    cf.br ^bb3(%exe : !hal.executable)
  ^bb2:  // pred: ^bb0
    %0 = util.null : !hal.executable
    cf.br ^bb3(%0 : !hal.executable)
  ^bb3(%1: !hal.executable):  // 2 preds: ^bb1, ^bb2
    util.global.store %1, @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    util.initializer.return
  }
  func.func @matmul_aie_offload(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -> !hal.buffer_view attributes {iree.abi.stub} {
    %c553648160_i32 = arith.constant 553648160 : i32
    %c1_i32 = arith.constant 1 : i32
    %c4 = arith.constant 4 : index
    %c-1_i32 = arith.constant -1 : i32
    %c0 = arith.constant 0 : index
    %c1 = arith.constant 1 : index
    %c-1_i64 = arith.constant -1 : i64
    %c32_i64 = arith.constant 32 : i64
    %c2 = arith.constant 2 : index
    %_device_query_0 = util.global.load @_device_query_0 : i1
    %_pipeline_layout_0 = util.global.load @_pipeline_layout_0 : !hal.pipeline_layout
    %_executable__matmul_aie_offload_dispatch_0 = util.global.load @_executable__matmul_aie_offload_dispatch_0 : !hal.executable
    %0 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[0] : index
    %1 = hal.buffer_view.dim<%arg0 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg0 : !hal.buffer_view> message("input 0") shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %buffer = hal.buffer_view.buffer<%arg0 : !hal.buffer_view> : !hal.buffer
    %device = hal.ex.shared_device : !hal.device
    %allocator = hal.device.allocator<%device : !hal.device> : !hal.allocator
    hal.buffer.assert<%buffer : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%3) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %4 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[0] : index
    %5 = hal.buffer_view.dim<%arg1 : !hal.buffer_view>[1] : index
    hal.buffer_view.assert<%arg1 : !hal.buffer_view> message("input 1") shape([%4, %5]) type(%c553648160_i32) encoding(%c1_i32)
    %6 = arith.muli %4, %c4 : index
    %7 = arith.muli %6, %5 : index
    %buffer_0 = hal.buffer_view.buffer<%arg1 : !hal.buffer_view> : !hal.buffer
    hal.buffer.assert<%buffer_0 : !hal.buffer> message("tensor") allocator(%allocator : !hal.allocator) minimum_length(%7) type(DeviceVisible) usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage")
    %buffer_1 = hal.allocator.allocate<%allocator : !hal.allocator> affinity(%c-1_i64) type("HostVisible|DeviceVisible|DeviceLocal") usage("TransferSource|TransferTarget|Transfer|DispatchStorageRead|DispatchStorageWrite|DispatchStorage|MappingScoped|MappingAccessRandom|Mapping") : !hal.buffer{%3}
    %8 = arith.index_castui %0 : index to i64
    %9 = arith.trunci %8 : i64 to i32
    %10 = arith.shrui %8, %c32_i64 : i64
    %11 = arith.trunci %10 : i64 to i32
    %12 = arith.index_castui %1 : index to i64
    %13 = arith.trunci %12 : i64 to i32
    %14 = arith.shrui %12, %c32_i64 : i64
    %15 = arith.trunci %14 : i64 to i32
    %16 = arith.index_castui %4 : index to i64
    %17 = arith.trunci %16 : i64 to i32
    %18 = arith.shrui %16, %c32_i64 : i64
    %19 = arith.trunci %18 : i64 to i32
    %20 = arith.index_castui %5 : index to i64
    %21 = arith.trunci %20 : i64 to i32
    %22 = arith.shrui %20, %c32_i64 : i64
    %23 = arith.trunci %22 : i64 to i32
    %cmd = hal.command_buffer.create device(%device : !hal.device) mode("OneShot|AllowInlineExecution") categories("Transfer|Dispatch") : !hal.command_buffer
    cf.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    hal.command_buffer.push_constants<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout) offset(0) values([%9, %11, %13, %15, %17, %19, %21, %23]) : i32, i32, i32, i32, i32, i32, i32, i32
    hal.command_buffer.push_descriptor_set<%cmd : !hal.command_buffer> layout(%_pipeline_layout_0 : !hal.pipeline_layout)[%c0] bindings([
      %c0 = (%buffer : !hal.buffer)[%c0, %3], 
      %c1 = (%buffer_0 : !hal.buffer)[%c0, %7], 
      %c2 = (%buffer_1 : !hal.buffer)[%c0, %3]
    ])
    hal.command_buffer.dispatch<%cmd : !hal.command_buffer> target(%_executable__matmul_aie_offload_dispatch_0 : !hal.executable)[0] workgroups([%c2, %c1, %c1])
    hal.command_buffer.execution_barrier<%cmd : !hal.command_buffer> source("Dispatch|Transfer|CommandRetire") target("CommandIssue|Dispatch|Transfer") flags("None")
    hal.command_buffer.finalize<%cmd : !hal.command_buffer>
    %24 = util.null : !hal.fence
    %fence = hal.fence.create device(%device : !hal.device) flags("None") : !hal.fence
    hal.device.queue.execute<%device : !hal.device> affinity(%c-1_i64) wait(%24) signal(%fence) commands([%cmd])
    %status = hal.fence.await until([%fence]) timeout_millis(%c-1_i32) : i32
    util.status.check_ok %status, "failed to wait on timepoint"
    %view = hal.buffer_view.create buffer(%buffer_1 : !hal.buffer)[%c0, %3] shape([%0, %1]) type(%c553648160_i32) encoding(%c1_i32) : !hal.buffer_view
    return %view : !hal.buffer_view
  ^bb2:  // pred: ^bb0
    util.unreachable "device not supported in the compiled configuration"
  }
  hal.executable private @_matmul_aie_offload_dispatch_0 {
    hal.executable.binary public @embedded_elf_x86_64 attributes {data = dense<"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"> : vector<3688xi8>, format = "embedded-elf-x86_64", mime_type = "application/x-elf"}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ConversionPass (iree-vm-conversion) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.initializer {
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %buffer = vm.rodata.inline "_utf8_hal_executable_format_EAB228F999C2D3A1" {alignment = 1 : i64} : !vm.buffer = "hal.executable.format"
      %buffer_0 = vm.rodata.inline "_utf8_embedded_elf_x86_64_9FD8733DA4A6F228" {alignment = 1 : i64} : !vm.buffer = "embedded-elf-x86_64"
      %0:2 = vm.call @hal.device.query.i64(%ref, %buffer, %buffer_0) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %c1 = vm.const.i32 1
      %2 = vm.and.i32 %1, %c1 : i32
      %zero = vm.const.i32.zero
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %c1_1 = vm.const.i32 1
      %zero_2 = vm.const.i32.zero
      %zero_3 = vm.const.i32.zero
      %c7 = vm.const.i32 7
      %c1_4 = vm.const.i32 1
      %c1_5 = vm.const.i32 1
      %c7_6 = vm.const.i32 7
      %c1_7 = vm.const.i32 1
      %c2 = vm.const.i32 2
      %c7_8 = vm.const.i32 7
      %zero_9 = vm.const.i32.zero
      %ref_10 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_2, [(%zero_3, %c7, %c1_4), (%c1_5, %c7_6, %c1_7), (%c2, %c7_8, %zero_9)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %c8 = vm.const.i32 8
      %ref_11 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_10]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_11, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %buffer_12 = vm.rodata.inline "_utf8_embedded_elf_x86_64_9FD8733DA4A6F228" {alignment = 1 : i64} : !vm.buffer = "embedded-elf-x86_64"
      %null = vm.const.ref.zero : !vm.buffer
      %ref_13 = vm.call.variadic @hal.executable.create(%ref, %buffer_12, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_13 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      %null_14 = vm.const.ref.zero : !vm.ref<!hal.executable>
      vm.br ^bb3(%null_14 : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero = vm.const.i64.zero
      %c1_0 = vm.const.i64 1
      %c-1_1 = vm.const.i64 -1
      %c32 = vm.const.i64 32
      %c2 = vm.const.i64 2
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %zero_2 = vm.const.i32.zero
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_2) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %c1_3 = vm.const.i32 1
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %buffer = vm.rodata.inline "_utf8_input_0_5FD512E67BEFDEEC" {alignment = 1 : i64} : !vm.buffer = "input 0"
      vm.call.variadic @hal.buffer_view.assert(%arg0, %buffer, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %buffer_6 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16 = vm.const.i32 16
      %c3075 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref, %buffer_6, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %zero_7 = vm.const.i32.zero
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero_7) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %c1_8 = vm.const.i32 1
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1_8) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %buffer_9 = vm.rodata.inline "_utf8_input_1_1DAF04E823826B1B" {alignment = 1 : i64} : !vm.buffer = "input 1"
      vm.call.variadic @hal.buffer_view.assert(%arg1, %buffer_9, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_10 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %buffer_11 = vm.rodata.inline "_utf8_tensor_3C6209B4FD120BDC" {alignment = 1 : i64} : !vm.buffer = "tensor"
      %c16_12 = vm.const.i32 16
      %c3075_13 = vm.const.i32 3075
      vm.call @hal.buffer.assert(%ref_10, %buffer_11, %ref_5, %7, %c16_12, %c3075_13) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %c50 = vm.const.i32 50
      %c150998019 = vm.const.i32 150998019
      %ref_14 = vm.call @hal.allocator.allocate(%ref_5, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %c32_15 = vm.const.i32 32
      %9 = vm.shr.i64.u %0, %c32_15 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %c32_16 = vm.const.i32 32
      %12 = vm.shr.i64.u %1, %c32_16 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %c32_17 = vm.const.i32 32
      %15 = vm.shr.i64.u %4, %c32_17 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %c32_18 = vm.const.i32 32
      %18 = vm.shr.i64.u %5, %c32_18 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %c17 = vm.const.i32 17
      %c3 = vm.const.i32 3
      %zero_19 = vm.const.i32.zero
      %ref_20 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero_19) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %zero_21 = vm.const.i32.zero
      vm.call.variadic @hal.command_buffer.push_constants(%ref_20, %_pipeline_layout_0, %zero_21, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      %zero_22 = vm.const.i32.zero
      %zero_23 = vm.const.i32.zero
      %zero_24 = vm.const.i32.zero
      %c1_25 = vm.const.i32 1
      %c2_26 = vm.const.i32 2
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_20, %_pipeline_layout_0, %zero_22, [(%zero_23, %zero_24, %ref, %zero, %3), (%c1_25, %zero_24, %ref_10, %zero, %7), (%c2_26, %zero_24, %ref_14, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      %zero_27 = vm.const.i32.zero
      %c2_28 = vm.const.i32 2
      %c1_29 = vm.const.i32 1
      %c1_30 = vm.const.i32 1
      vm.call @hal.command_buffer.dispatch(%ref_20, %_executable__matmul_aie_offload_dispatch_0, %zero_27, %c2_28, %c1_29, %c1_30) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      %c28 = vm.const.i32 28
      %c13 = vm.const.i32 13
      %zero_31 = vm.const.i32.zero
      vm.call @hal.command_buffer.execution_barrier(%ref_20, %c28, %c13, %zero_31) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_20) : (!vm.ref<!hal.command_buffer>) -> ()
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %zero_32 = vm.const.i32.zero
      %ref_33 = vm.call @hal.fence.create(%ref_4, %zero_32) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_33, [%ref_20]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_33]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_fail %20, "failed to wait on timepoint"
      %ref_34 = vm.call.variadic @hal.buffer_view.create(%ref_14, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_34 : !vm.ref<!hal.buffer_view>
    ^bb2:  // pred: ^bb0
      %c2_35 = vm.const.i32 2
      vm.fail %c2_35, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::HoistInlinedRodataPass (iree-vm-hoist-inlined-rodata) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %c1_0 = vm.const.i32 1
    %zero_1 = vm.const.i32.zero
    %zero_2 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_3 = vm.const.i32 1
    %c1_4 = vm.const.i32 1
    %c7_5 = vm.const.i32 7
    %c1_6 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_7 = vm.const.i32 7
    %zero_8 = vm.const.i32.zero
    %ref_9 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_1, [(%zero_2, %c7, %c1_3), (%c1_4, %c7_5, %c1_6), (%c2, %c7_7, %zero_8)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %c8 = vm.const.i32 8
    %ref_10 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_9]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_10, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_11 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_0, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_11 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_12 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_12 : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC_1 {alignment = 1 : i64} "tensor"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero = vm.const.i64.zero
    %c1_0 = vm.const.i64 1
    %c-1_1 = vm.const.i64 -1
    %c32 = vm.const.i64 32
    %c2 = vm.const.i64 2
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %zero_2 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_2) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_3 = vm.const.i32 1
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_6 = vm.const.i32.zero
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_7 = vm.const.i32 1
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1_7) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_8 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_1 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC_1 : !vm.buffer
    %c16_9 = vm.const.i32 16
    %c3075_10 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_8, %_utf8_tensor_3C6209B4FD120BDC_1, %ref_5, %7, %c16_9, %c3075_10) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %c50 = vm.const.i32 50
    %c150998019 = vm.const.i32 150998019
    %ref_11 = vm.call @hal.allocator.allocate(%ref_5, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_12 = vm.const.i32 32
    %9 = vm.shr.i64.u %0, %c32_12 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %c32_13 = vm.const.i32 32
    %12 = vm.shr.i64.u %1, %c32_13 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %c32_14 = vm.const.i32 32
    %15 = vm.shr.i64.u %4, %c32_14 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %c32_15 = vm.const.i32 32
    %18 = vm.shr.i64.u %5, %c32_15 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_16 = vm.const.i32.zero
    %ref_17 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero_16) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %zero_18 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_constants(%ref_17, %_pipeline_layout_0, %zero_18, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    %zero_19 = vm.const.i32.zero
    %zero_20 = vm.const.i32.zero
    %zero_21 = vm.const.i32.zero
    %c1_22 = vm.const.i32 1
    %c2_23 = vm.const.i32 2
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_17, %_pipeline_layout_0, %zero_19, [(%zero_20, %zero_21, %ref, %zero, %3), (%c1_22, %zero_21, %ref_8, %zero, %7), (%c2_23, %zero_21, %ref_11, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_24 = vm.const.i32.zero
    %c2_25 = vm.const.i32 2
    %c1_26 = vm.const.i32 1
    %c1_27 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_17, %_executable__matmul_aie_offload_dispatch_0, %zero_24, %c2_25, %c1_26, %c1_27) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_28 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_17, %c28, %c13, %zero_28) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_17) : (!vm.ref<!hal.command_buffer>) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_29 = vm.const.i32.zero
    %ref_30 = vm.call @hal.fence.create(%ref_4, %zero_29) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_30, [%ref_17]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_30]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %20, "failed to wait on timepoint"
    %ref_31 = vm.call.variadic @hal.buffer_view.create(%ref_11, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_31 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    %c2_32 = vm.const.i32 2
    vm.fail %c2_32, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DeduplicateRodataPass (iree-vm-deduplicate-rodata) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %c1 = vm.const.i32 1
    %2 = vm.and.i32 %1, %c1 : i32
    %zero = vm.const.i32.zero
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %c1_0 = vm.const.i32 1
    %zero_1 = vm.const.i32.zero
    %zero_2 = vm.const.i32.zero
    %c7 = vm.const.i32 7
    %c1_3 = vm.const.i32 1
    %c1_4 = vm.const.i32 1
    %c7_5 = vm.const.i32 7
    %c1_6 = vm.const.i32 1
    %c2 = vm.const.i32 2
    %c7_7 = vm.const.i32 7
    %zero_8 = vm.const.i32.zero
    %ref_9 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero_1, [(%zero_2, %c7, %c1_3), (%c1_4, %c7_5, %c1_6), (%c2, %c7_7, %zero_8)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %c8 = vm.const.i32 8
    %ref_10 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_9]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_10, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_11 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %null = vm.const.ref.zero : !vm.buffer
    %ref_12 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_11, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_12 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    %null_13 = vm.const.ref.zero : !vm.ref<!hal.executable>
    vm.br ^bb3(%null_13 : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero = vm.const.i64.zero
    %c1_0 = vm.const.i64 1
    %c-1_1 = vm.const.i64 -1
    %c32 = vm.const.i64 32
    %c2 = vm.const.i64 2
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %zero_2 = vm.const.i32.zero
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero_2) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_3 = vm.const.i32 1
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1_3) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_4 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_5 = vm.call @hal.device.allocator(%ref_4) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16 = vm.const.i32 16
    %c3075 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_5, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %zero_6 = vm.const.i32.zero
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero_6) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %c1_7 = vm.const.i32 1
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1_7) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_8 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %_utf8_tensor_3C6209B4FD120BDC_9 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    %c16_10 = vm.const.i32 16
    %c3075_11 = vm.const.i32 3075
    vm.call @hal.buffer.assert(%ref_8, %_utf8_tensor_3C6209B4FD120BDC_9, %ref_5, %7, %c16_10, %c3075_11) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %c50 = vm.const.i32 50
    %c150998019 = vm.const.i32 150998019
    %ref_12 = vm.call @hal.allocator.allocate(%ref_5, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %c32_13 = vm.const.i32 32
    %9 = vm.shr.i64.u %0, %c32_13 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %c32_14 = vm.const.i32 32
    %12 = vm.shr.i64.u %1, %c32_14 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %c32_15 = vm.const.i32 32
    %15 = vm.shr.i64.u %4, %c32_15 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %c32_16 = vm.const.i32 32
    %18 = vm.shr.i64.u %5, %c32_16 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %c17 = vm.const.i32 17
    %c3 = vm.const.i32 3
    %zero_17 = vm.const.i32.zero
    %ref_18 = vm.call @hal.command_buffer.create(%ref_4, %c17, %c3, %zero_17) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %zero_19 = vm.const.i32.zero
    vm.call.variadic @hal.command_buffer.push_constants(%ref_18, %_pipeline_layout_0, %zero_19, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    %zero_20 = vm.const.i32.zero
    %zero_21 = vm.const.i32.zero
    %zero_22 = vm.const.i32.zero
    %c1_23 = vm.const.i32 1
    %c2_24 = vm.const.i32 2
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_18, %_pipeline_layout_0, %zero_20, [(%zero_21, %zero_22, %ref, %zero, %3), (%c1_23, %zero_22, %ref_8, %zero, %7), (%c2_24, %zero_22, %ref_12, %zero, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    %zero_25 = vm.const.i32.zero
    %c2_26 = vm.const.i32 2
    %c1_27 = vm.const.i32 1
    %c1_28 = vm.const.i32 1
    vm.call @hal.command_buffer.dispatch(%ref_18, %_executable__matmul_aie_offload_dispatch_0, %zero_25, %c2_26, %c1_27, %c1_28) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    %c28 = vm.const.i32 28
    %c13 = vm.const.i32 13
    %zero_29 = vm.const.i32.zero
    vm.call @hal.command_buffer.execution_barrier(%ref_18, %c28, %c13, %zero_29) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_18) : (!vm.ref<!hal.command_buffer>) -> ()
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %zero_30 = vm.const.i32.zero
    %ref_31 = vm.call @hal.fence.create(%ref_4, %zero_30) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_4, %c-1_1, %null, %ref_31, [%ref_18]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_31]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_fail %20, "failed to wait on timepoint"
    %ref_32 = vm.call.variadic @hal.buffer_view.create(%ref_12, %zero, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_32 : !vm.ref<!hal.buffer_view>
  ^bb2:  // pred: ^bb0
    %c2_33 = vm.const.i32 2
    vm.fail %c2_33, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_3 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %ref_4 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228_3, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_4 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %_utf8_tensor_3C6209B4FD120BDC_5 = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC_5, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_6 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_7 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_7, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_7, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_6, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_7, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_7, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_7) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_8 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_8, [%ref_7]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_8]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3(%20 : i32), ^bb2
    ^bb2:  // pred: ^bb1
      %ref_9 = vm.call.variadic @hal.buffer_view.create(%ref_6, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_9 : !vm.ref<!hal.buffer_view>
    ^bb3(%21: i32):  // pred: ^bb1
      vm.fail %21, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3(%20 : i32), ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3(%21: i32):  // pred: ^bb1
      vm.fail %21, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068090000000000000000000040003800070040001400120006000000040000004000000000000000400000000000000040000000000000008801000000000000880100000000000008000000000000000100000004000000000000000000000000000000000000000000000000000000180400000000000018040000000000000010000000000000010000000500000020040000000000002014000000000000201400000000000011010000000000001101000000000000001000000000000001000000060000004005000000000000402500000000000040250000000000006001000000000000600100000000000000100000000000000200000006000000E005000000000000E025000000000000E025000000000000C000000000000000C000000000000000080000000000000052E57464040000004005000000000000402500000000000040250000000000006001000000000000C00A000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120007002015000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279000000000000482500000000000008000000000000007003000000000000582500000000000008000000000000008F0300000000000060250000000000000800000000000000201400000000000068250000000000000800000000000000700300000000000070250000000000000800000000000000A40300000000000080250000000000000800000000000000A503000000000000902500000000000008000000000000004025000000000000A02500000000000008000000000000005825000000000000B02500000000000008000000000000006025000000000000B8250000000000000800000000000000A003000000000000C02500000000000008000000000000006825000000000000C82500000000000008000000000000007025000000000000D025000000000000080000000000000078250000000000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30006169655F6D61746D756C5F66333200000000000000006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000001400000000000000017A5200017810011B0C070890010000240000001C00000040100000F200000000410E108602430D064783068C058E048F0302E60C0708001000000044000000181100001100000000000000000000000000000000000000554889E5415741564154534989F8448B660C488B4618488B76204C8B5018488B084C8B48084C8B3E4C8B7608488B5E108B7A0C448B1A4889CA48F7DA488D41FF4885C9480F4EC24889C248C1EA207407489949F7FCEB0531D241F7F44889C248F7DA48FFC04885C9480F4EC24889C2490FAFD34829D14839C1480F4DC84D89CC4929D44939C44C0F4DE049FFC14C0FAFCA49FFC24C0FAFD2498D40204889E2488D72A04889F44C897AA04C894AA84C8972B04C8952B848895AC04C894AC848894AD04C8962D84C895AE0897AE8488942F0498B4010498B4818488B11488B3831C941FF5008488D65E05B415C415E415F5DC3CCCCCCCCCCCCCCCCCCCCCCCCCCCC31C083FF03488D0D64100000480F44C1C300000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000B000000170000000000000000000000000000000000000000000000000000000100000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000380100000000000009000000000000001800000000000000F9FFFF6F000000000D000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F80100000000000000000000000000000000000000000000011101250E1305030E1017B44219110112060000022E001101120640186E0E030E3A0B3B0B49133F190000032400030E3E0B0B0B0000004700000004000000000008013B0000002C0004000000000000002014000000000000F2000000022014000000000000F200000001561C0000001C0000000101430000000300000000050400696E74006D61746D756C5F6169655F6F66666C6F61642E6D6C6972005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30004952454500310000000200000000004B000000260000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F300000000000160000000200000000004B00000043000000696E7400000000007200000004002F000000010101FB0E0D000101010100000001000001006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000000000090220140000000000000105200AD6053906BA05204A050A060318743D050803714A050B4B050F030966024713050ACB7578060B02511202090001014952454500000000000000000000000000000000000000000000000000000000002300000000020900E0250000000000000000000000000000010000001200070020150000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E65685F6672616D65002E74657874002E646174612E72656C2E726F002E64796E616D6963002E64656275675F616262726576002E64656275675F696E666F002E64656275675F737472002E64656275675F7075626E616D6573002E64656275675F7075627479706573002E64656275675F6C696E65002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F0000000300000002000000000000001002000000000000100200000000000023000000000000000000000000000000010000000000000000000000000000001700000004000000020000000000000038020000000000003802000000000000380100000000000001000000000000000800000000000000180000000000000021000000010000000200000000000000700300000000000070030000000000004D0000000000000000000000000000000800000000000000000000000000000029000000010000000200000000000000C003000000000000C0030000000000005800000000000000000000000000000008000000000000000000000000000000330000000100000006000000000000002014000000000000200400000000000011010000000000000000000000000000100000000000000000000000000000003900000001000000030000000000000040250000000000004005000000000000A00000000000000000000000000000001000000000000000000000000000000046000000060000000300000000000000E025000000000000E005000000000000C0000000000000000300000000000000080000000000000010000000000000004F0000000100000000000000000000000000000000000000A00600000000000037000000000000000000000000000000010000000000000000000000000000005D0000000100000000000000000000000000000000000000D7060000000000004B00000000000000000000000000000001000000000000000000000000000000690000000100000030000000000000000000000000000000220700000000000040000000000000000000000000000000010000000000000001000000000000007400000001000000000000000000000000000000000000006207000000000000350000000000000000000000000000000100000000000000000000000000000084000000010000000000000000000000000000000000000097070000000000001A00000000000000000000000000000001000000000000000000000000000000940000000100000000000000000000000000000000000000B1070000000000007600000000000000000000000000000001000000000000000000000000000000A0000000010000003000000000000000000000000000000027080000000000000500000000000000000000000000000001000000000000000100000000000000A9000000020000000000000000000000000000000000000030080000000000004800000000000000130000000200000008000000000000001800000000000000B100000003000000000000000000000000000000000000007808000000000000C300000000000000000000000000000001000000000000000000000000000000BB00000003000000000000000000000000000000000000003B090000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::ResolveRodataLoadsPass (iree-vm-resolve-rodata-loads) //----- //
vm.module public @module {
  vm.global.i32 private @_device_query_0 : i32
  vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.initializer {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
  vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
  vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
  vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
  vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
  vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
  vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
  vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
  vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
  vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
  vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
  vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
  vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.initializer {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c8 = vm.const.i32 8
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.cond_br %3, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
  %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c32 = vm.const.i32 32
  %c150998019 = vm.const.i32 150998019
  %c50 = vm.const.i32 50
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %zero = vm.const.i32.zero
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %c4 = vm.const.i64 4
  %c-1 = vm.const.i32 -1
  %zero_0 = vm.const.i64.zero
  %c-1_1 = vm.const.i64 -1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %2 = vm.mul.i64 %0, %c4 : i64
  %3 = vm.mul.i64 %2, %1 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %6 = vm.mul.i64 %4, %c4 : i64
  %7 = vm.mul.i64 %6, %5 : i64
  %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %8 = vm.trunc.i64.i32 %0 : i64 -> i32
  %9 = vm.shr.i64.u %0, %c32 : i64
  %10 = vm.trunc.i64.i32 %9 : i64 -> i32
  %11 = vm.trunc.i64.i32 %1 : i64 -> i32
  %12 = vm.shr.i64.u %1, %c32 : i64
  %13 = vm.trunc.i64.i32 %12 : i64 -> i32
  %14 = vm.trunc.i64.i32 %4 : i64 -> i32
  %15 = vm.shr.i64.u %4, %c32 : i64
  %16 = vm.trunc.i64.i32 %15 : i64 -> i32
  %17 = vm.trunc.i64.i32 %5 : i64 -> i32
  %18 = vm.shr.i64.u %5, %c32 : i64
  %19 = vm.trunc.i64.i32 %18 : i64 -> i32
  %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.cond_br %_device_query_0, ^bb1, ^bb4
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %20, ^bb3, ^bb2
^bb2:  // pred: ^bb1
  %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_8 : !vm.ref<!hal.buffer_view>
^bb3:  // pred: ^bb1
  vm.fail %20, "failed to wait on timepoint"
^bb4:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

// -----// IR Dump After Inliner (inline) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.ex.file.from_memory(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %access : i32, %buffer : !vm.buffer, %offset : i64, %length : i64, %flags : i32) -> !vm.ref<!hal.file>
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.allocator.import(%allocator : !vm.ref<!hal.allocator>, %try : i32, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %source : !vm.buffer, %offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer.subspan(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i64) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer.length(%buffer : !vm.ref<!hal.buffer>) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer.load(%source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %length : i32) -> i32
    vm.import private @hal.buffer.store(%value : i32, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.element_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.encoding_type(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.rank(%buffer_view : !vm.ref<!hal.buffer_view>) -> i32 attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.buffer_view.trace(%key : !vm.buffer, %operands : !vm.ref<!hal.buffer_view> ...)
    vm.import private @hal.channel.create(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %flags : i32, %id : !vm.buffer, %group : !vm.buffer, %rank : i32, %count : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.split(%channel : !vm.ref<!hal.channel>, %color : i32, %key : i32, %flags : i32) -> !vm.ref<!hal.channel> attributes {nosideeffects}
    vm.import private @hal.channel.rank_and_count(%channel : !vm.ref<!hal.channel>) -> (i32, i32) attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.begin_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>, %label : !vm.buffer)
    vm.import private @hal.command_buffer.end_debug_group(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.fill_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %pattern : i32, %pattern_length : i32)
    vm.import private @hal.command_buffer.copy_buffer(%command_buffer : !vm.ref<!hal.command_buffer>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64)
    vm.import private @hal.command_buffer.collective(%command_buffer : !vm.ref<!hal.command_buffer>, %channel : !vm.ref<!hal.channel>, %op : i32, %param : i32, %send_buffer : !vm.ref<!hal.buffer>, %send_offset : i64, %send_length : i64, %recv_buffer : !vm.ref<!hal.buffer>, %recv_offset : i64, %recv_length : i64, %element_count : i64)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.command_buffer.dispatch.indirect(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroups_buffer : !vm.ref<!hal.buffer>, %workgroups_offset : i64)
    vm.import private @hal.command_buffer.execute.commands(%command_buffer : !vm.ref<!hal.command_buffer>, %commands : !vm.ref<!hal.command_buffer>, %bindings : tuple<!vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.alloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %pool : i32, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer>
    vm.import private @hal.device.queue.dealloca(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %buffer : !vm.ref<!hal.buffer>)
    vm.import private @hal.device.queue.read(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_file : !vm.ref<!hal.file>, %source_offset : i64, %target_buffer : !vm.ref<!hal.buffer>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.write(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %source_buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %target_file : !vm.ref<!hal.file>, %target_offset : i64, %length : i64, %flags : i32)
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.device.queue.flush(%device : !vm.ref<!hal.device>, %queue_affinity : i64)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.join(%fences : !vm.ref<!hal.fence> ...) -> !vm.ref<!hal.fence> attributes {nosideeffects}
    vm.import private @hal.fence.query(%fence : !vm.ref<!hal.fence>) -> i32
    vm.import private @hal.fence.signal(%fence : !vm.ref<!hal.fence>)
    vm.import private @hal.fence.fail(%fence : !vm.ref<!hal.fence>, %status : i32)
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After SymbolDCE (symbol-dce) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"0x7F454C4602010100000000000000000003003E00010000000000000000000000400000000000000068090000000000000000000040003800070040001400120006000000040000004000000000000000400000000000000040000000000000008801000000000000880100000000000008000000000000000100000004000000000000000000000000000000000000000000000000000000180400000000000018040000000000000010000000000000010000000500000020040000000000002014000000000000201400000000000011010000000000001101000000000000001000000000000001000000060000004005000000000000402500000000000040250000000000006001000000000000600100000000000000100000000000000200000006000000E005000000000000E025000000000000E025000000000000C000000000000000C000000000000000080000000000000052E57464040000004005000000000000402500000000000040250000000000006001000000000000C00A000000000000010000000000000051E574640600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000120007002015000000000000110000000000000002000000020000000000000001000000000000000000000000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279000000000000482500000000000008000000000000007003000000000000582500000000000008000000000000008F0300000000000060250000000000000800000000000000201400000000000068250000000000000800000000000000700300000000000070250000000000000800000000000000A40300000000000080250000000000000800000000000000A503000000000000902500000000000008000000000000004025000000000000A02500000000000008000000000000005825000000000000B02500000000000008000000000000006025000000000000B8250000000000000800000000000000A003000000000000C02500000000000008000000000000006825000000000000C82500000000000008000000000000007025000000000000D025000000000000080000000000000078250000000000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30006169655F6D61746D756C5F66333200000000000000006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000001400000000000000017A5200017810011B0C070890010000240000001C00000040100000F200000000410E108602430D064783068C058E048F0302E60C0708001000000044000000181100001100000000000000000000000000000000000000554889E5415741564154534989F8448B660C488B4618488B76204C8B5018488B084C8B48084C8B3E4C8B7608488B5E108B7A0C448B1A4889CA48F7DA488D41FF4885C9480F4EC24889C248C1EA207407489949F7FCEB0531D241F7F44889C248F7DA48FFC04885C9480F4EC24889C2490FAFD34829D14839C1480F4DC84D89CC4929D44939C44C0F4DE049FFC14C0FAFCA49FFC24C0FAFD2498D40204889E2488D72A04889F44C897AA04C894AA84C8972B04C8952B848895AC04C894AC848894AD04C8962D84C895AE0897AE8488942F0498B4010498B4818488B11488B3831C941FF5008488D65E05B415C415E415F5DC3CCCCCCCCCCCCCCCCCCCCCCCCCCCC31C083FF03488D0D64100000480F44C1C300000000000000000000000000000003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000B000000170000000000000000000000000000000000000000000000000000000100000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001E000000000000000800000000000000FBFFFF6F000000000100000000000000070000000000000038020000000000000800000000000000380100000000000009000000000000001800000000000000F9FFFF6F000000000D000000000000000600000000000000C8010000000000000B000000000000001800000000000000050000000000000010020000000000000A0000000000000023000000000000000400000000000000F80100000000000000000000000000000000000000000000011101250E1305030E1017B44219110112060000022E001101120640186E0E030E3A0B3B0B49133F190000032400030E3E0B0B0B0000004700000004000000000008013B0000002C0004000000000000002014000000000000F2000000022014000000000000F200000001561C0000001C0000000101430000000300000000050400696E74006D61746D756C5F6169655F6F66666C6F61642E6D6C6972005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F30004952454500310000000200000000004B000000260000005F6D61746D756C5F6169655F6F66666C6F61645F64697370617463685F300000000000160000000200000000004B00000043000000696E7400000000007200000004002F000000010101FB0E0D000101010100000001000001006D61746D756C5F6169655F6F66666C6F61642E6D6C6972000000000000090220140000000000000105200AD6053906BA05204A050A060318743D050803714A050B4B050F030966024713050ACB7578060B02511202090001014952454500000000000000000000000000000000000000000000000000000000002300000000020900E0250000000000000000000000000000010000001200070020150000000000001100000000000000002E64796E73796D002E68617368002E64796E737472002E72656C612E64796E002E726F64617461002E65685F6672616D65002E74657874002E646174612E72656C2E726F002E64796E616D6963002E64656275675F616262726576002E64656275675F696E666F002E64656275675F737472002E64656275675F7075626E616D6573002E64656275675F7075627479706573002E64656275675F6C696E65002E636F6D6D656E74002E73796D746162002E7368737472746162002E7374727461620000697265655F68616C5F65786563757461626C655F6C6962726172795F7175657279005F44594E414D4943000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000B0000000200000000000000C801000000000000C801000000000000300000000000000003000000010000000800000000000000180000000000000009000000050000000200000000000000F801000000000000F80100000000000018000000000000000100000000000000040000000000000004000000000000000F0000000300000002000000000000001002000000000000100200000000000023000000000000000000000000000000010000000000000000000000000000001700000004000000020000000000000038020000000000003802000000000000380100000000000001000000000000000800000000000000180000000000000021000000010000000200000000000000700300000000000070030000000000004D0000000000000000000000000000000800000000000000000000000000000029000000010000000200000000000000C003000000000000C0030000000000005800000000000000000000000000000008000000000000000000000000000000330000000100000006000000000000002014000000000000200400000000000011010000000000000000000000000000100000000000000000000000000000003900000001000000030000000000000040250000000000004005000000000000A00000000000000000000000000000001000000000000000000000000000000046000000060000000300000000000000E025000000000000E005000000000000C0000000000000000300000000000000080000000000000010000000000000004F0000000100000000000000000000000000000000000000A00600000000000037000000000000000000000000000000010000000000000000000000000000005D0000000100000000000000000000000000000000000000D7060000000000004B00000000000000000000000000000001000000000000000000000000000000690000000100000030000000000000000000000000000000220700000000000040000000000000000000000000000000010000000000000001000000000000007400000001000000000000000000000000000000000000006207000000000000350000000000000000000000000000000100000000000000000000000000000084000000010000000000000000000000000000000000000097070000000000001A00000000000000000000000000000001000000000000000000000000000000940000000100000000000000000000000000000000000000B1070000000000007600000000000000000000000000000001000000000000000000000000000000A0000000010000003000000000000000000000000000000027080000000000000500000000000000000000000000000001000000000000000100000000000000A9000000020000000000000000000000000000000000000030080000000000004800000000000000130000000200000008000000000000001800000000000000B100000003000000000000000000000000000000000000007808000000000000C300000000000000000000000000000001000000000000000000000000000000BB00000003000000000000000000000000000000000000003B090000000000002C00000000000000000000000000000001000000000000000000000000000000"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After ApplyPatterns (iree-util-apply-patterns) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After FoldGlobals (iree-util-fold-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After FuseGlobals (iree-util-fuse-globals) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private @_device_query_0 : i32
    vm.global.ref private @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.initializer {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After CSE (cse) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
    vm.export @__deinit
    vm.func private @__deinit() {
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
#executable_target_embedded_elf_x86_64_ = #hal.executable.target<"llvm-cpu", "embedded-elf-x86_64", {cpu = "generic", cpu_features = "", data_layout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128", native_vector_size = 16 : index, target_triple = "x86_64-unknown-unknown-eabi-elf", ukernels = false}>
#device_target_llvm_cpu = #hal.device.target<"llvm-cpu", {executable_targets = [#executable_target_embedded_elf_x86_64_]}>
module attributes {hal.device.targets = [#device_target_llvm_cpu], vm.toplevel} {
  vm.module public @module {
    vm.global.i32 private mutable @_device_query_0 : i32
    vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
    vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
    vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
    vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
    vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
    vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
    vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
      %null = vm.const.ref.zero : !vm.ref<!hal.fence>
      %c13 = vm.const.i32 13
      %c28 = vm.const.i32 28
      %c2 = vm.const.i32 2
      %c3 = vm.const.i32 3
      %c17 = vm.const.i32 17
      %c32 = vm.const.i32 32
      %c150998019 = vm.const.i32 150998019
      %c50 = vm.const.i32 50
      %c3075 = vm.const.i32 3075
      %c16 = vm.const.i32 16
      %zero = vm.const.i32.zero
      %c553648160 = vm.const.i32 553648160
      %c1 = vm.const.i32 1
      %c4 = vm.const.i64 4
      %c-1 = vm.const.i32 -1
      %zero_0 = vm.const.i64.zero
      %c-1_1 = vm.const.i64 -1
      %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %2 = vm.mul.i64 %0, %c4 : i64
      %3 = vm.mul.i64 %2, %1 : i64
      %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
      %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
      vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
      %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
      vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
      %6 = vm.mul.i64 %4, %c4 : i64
      %7 = vm.mul.i64 %6, %5 : i64
      %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
      vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
      %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
      %8 = vm.trunc.i64.i32 %0 : i64 -> i32
      %9 = vm.shr.i64.u %0, %c32 : i64
      %10 = vm.trunc.i64.i32 %9 : i64 -> i32
      %11 = vm.trunc.i64.i32 %1 : i64 -> i32
      %12 = vm.shr.i64.u %1, %c32 : i64
      %13 = vm.trunc.i64.i32 %12 : i64 -> i32
      %14 = vm.trunc.i64.i32 %4 : i64 -> i32
      %15 = vm.shr.i64.u %4, %c32 : i64
      %16 = vm.trunc.i64.i32 %15 : i64 -> i32
      %17 = vm.trunc.i64.i32 %5 : i64 -> i32
      %18 = vm.shr.i64.u %5, %c32 : i64
      %19 = vm.trunc.i64.i32 %18 : i64 -> i32
      %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
      vm.cond_br %_device_query_0, ^bb1, ^bb4
    ^bb1:  // pred: ^bb0
      vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
      vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
      vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
      vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
      %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
      vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
      %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
      vm.cond_br %20, ^bb3, ^bb2
    ^bb2:  // pred: ^bb1
      %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
      vm.return %ref_8 : !vm.ref<!hal.buffer_view>
    ^bb3:  // pred: ^bb1
      vm.fail %20, "failed to wait on timepoint"
    ^bb4:  // pred: ^bb0
      vm.fail %c2, "device not supported in the compiled configuration"
    }
    vm.export @matmul_aie_offload attributes {iree.abi.stub}
    vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
    vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
    vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
    vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
    vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
    vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
    vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
    vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
    vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
    vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
    vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
    vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
    vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
    vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
    vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
    vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
    vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
    vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
    vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
    vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
    vm.export @__init
    vm.func private @__init() {
      %null = vm.const.ref.zero : !vm.ref<!hal.executable>
      %null_0 = vm.const.ref.zero : !vm.buffer
      %c8 = vm.const.i32 8
      %c2 = vm.const.i32 2
      %c7 = vm.const.i32 7
      %zero = vm.const.i32.zero
      %c1 = vm.const.i32 1
      %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
      %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
      %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
      %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
      %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
      %2 = vm.and.i32 %1, %c1 : i32
      %3 = vm.select.i32 %0#0, %2, %zero : i32
      %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
      %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
      vm.global.store.i32 %3, @_device_query_0 : i32
      vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      vm.cond_br %3, ^bb1, ^bb2
    ^bb1:  // pred: ^bb0
      %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
      %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
      %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
      vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
    ^bb2:  // pred: ^bb0
      vm.br ^bb3(%null : !vm.ref<!hal.executable>)
    ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
      vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
      vm.return
    }
  }
}


// -----// IR Dump After mlir::iree_compiler::IREE::VM::GlobalInitializationPass (iree-vm-global-initialization) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
  vm.export @__deinit
  vm.func private @__deinit() {
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::DropEmptyModuleInitializersPass (iree-vm-drop-empty-module-initializers) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.br ^bb4
  ^bb4:  // pred: ^bb3
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
  %null = vm.const.ref.zero : !vm.ref<!hal.fence>
  %c13 = vm.const.i32 13
  %c28 = vm.const.i32 28
  %c2 = vm.const.i32 2
  %c3 = vm.const.i32 3
  %c17 = vm.const.i32 17
  %c32 = vm.const.i32 32
  %c150998019 = vm.const.i32 150998019
  %c50 = vm.const.i32 50
  %c3075 = vm.const.i32 3075
  %c16 = vm.const.i32 16
  %zero = vm.const.i32.zero
  %c553648160 = vm.const.i32 553648160
  %c1 = vm.const.i32 1
  %c4 = vm.const.i64 4
  %c-1 = vm.const.i32 -1
  %zero_0 = vm.const.i64.zero
  %c-1_1 = vm.const.i64 -1
  %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %2 = vm.mul.i64 %0, %c4 : i64
  %3 = vm.mul.i64 %2, %1 : i64
  %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
  %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
  vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
  %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
  vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
  %6 = vm.mul.i64 %4, %c4 : i64
  %7 = vm.mul.i64 %6, %5 : i64
  %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
  vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
  %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
  %8 = vm.trunc.i64.i32 %0 : i64 -> i32
  %9 = vm.shr.i64.u %0, %c32 : i64
  %10 = vm.trunc.i64.i32 %9 : i64 -> i32
  %11 = vm.trunc.i64.i32 %1 : i64 -> i32
  %12 = vm.shr.i64.u %1, %c32 : i64
  %13 = vm.trunc.i64.i32 %12 : i64 -> i32
  %14 = vm.trunc.i64.i32 %4 : i64 -> i32
  %15 = vm.shr.i64.u %4, %c32 : i64
  %16 = vm.trunc.i64.i32 %15 : i64 -> i32
  %17 = vm.trunc.i64.i32 %5 : i64 -> i32
  %18 = vm.shr.i64.u %5, %c32 : i64
  %19 = vm.trunc.i64.i32 %18 : i64 -> i32
  %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
  vm.cond_br %_device_query_0, ^bb1, ^bb4
^bb1:  // pred: ^bb0
  vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
  vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
  vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
  %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
  vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
  %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
  vm.cond_br %20, ^bb3, ^bb2
^bb2:  // pred: ^bb1
  %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
  vm.return %ref_8 : !vm.ref<!hal.buffer_view>
^bb3:  // pred: ^bb1
  vm.fail %20, "failed to wait on timepoint"
^bb4:  // pred: ^bb0
  vm.fail %c2, "device not supported in the compiled configuration"
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.func private @__init() {
  %null = vm.const.ref.zero : !vm.ref<!hal.executable>
  %null_0 = vm.const.ref.zero : !vm.buffer
  %c8 = vm.const.i32 8
  %c2 = vm.const.i32 2
  %c7 = vm.const.i32 7
  %zero = vm.const.i32.zero
  %c1 = vm.const.i32 1
  %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
  %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
  %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
  %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
  %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
  %2 = vm.and.i32 %1, %c1 : i32
  %3 = vm.select.i32 %0#0, %2, %zero : i32
  %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
  %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
  vm.global.store.i32 %3, @_device_query_0 : i32
  vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.cond_br %3, ^bb1, ^bb2
^bb1:  // pred: ^bb0
  %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
  %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
  vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
^bb2:  // pred: ^bb0
  vm.br ^bb3(%null : !vm.ref<!hal.executable>)
^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
  vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.return
}

// -----// IR Dump After Inliner (inline) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After CSE (cse) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After Canonicalizer (canonicalize) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After DropCompilerHints (iree-util-drop-compiler-hints) //----- //
vm.module public @module {
  vm.global.i32 private mutable @_device_query_0 : i32
  vm.global.ref private mutable @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf"} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32)
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...)
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer>
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>)
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32)
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...)
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32)
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...)
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence>
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects}
  vm.export @__init
  vm.func private @__init() {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

// -----// IR Dump After mlir::iree_compiler::IREE::VM::OrdinalAllocationPass (iree-vm-ordinal-allocation) //----- //
vm.module public @module attributes {ordinal_counts = #vm.ordinal_counts<import_funcs = 21, export_funcs = 2, internal_funcs = 2, global_bytes = 4, global_refs = 2, rodatas = 6, rwdatas = 0>} {
  vm.global.i32 private mutable @_device_query_0 {ordinal = 0 : i32} : i32
  vm.global.ref private mutable @_pipeline_layout_0 {ordinal = 0 : i32} : !vm.ref<!hal.pipeline_layout>
  vm.global.ref private mutable @_executable__matmul_aie_offload_dispatch_0 {ordinal = 1 : i32} : !vm.ref<!hal.executable>
  vm.rodata private @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 {alignment = 16 : i64, mime_type = "application/x-elf", ordinal = 0 : i32} dense<"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"> : vector<3688xi8>
  vm.rodata private @_utf8_hal_executable_format_EAB228F999C2D3A1 {alignment = 1 : i64, ordinal = 1 : i32} "hal.executable.format"
  vm.rodata private @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 {alignment = 1 : i64, ordinal = 2 : i32} "embedded-elf-x86_64"
  vm.rodata private @_utf8_input_0_5FD512E67BEFDEEC {alignment = 1 : i64, ordinal = 3 : i32} "input 0"
  vm.rodata private @_utf8_tensor_3C6209B4FD120BDC {alignment = 1 : i64, ordinal = 4 : i32} "tensor"
  vm.rodata private @_utf8_input_1_1DAF04E823826B1B {alignment = 1 : i64, ordinal = 5 : i32} "input 1"
  vm.func private @matmul_aie_offload(%arg0: !vm.ref<!hal.buffer_view>, %arg1: !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer_view> attributes {ordinal = 0 : i32} {
    %null = vm.const.ref.zero : !vm.ref<!hal.fence>
    %c13 = vm.const.i32 13
    %c28 = vm.const.i32 28
    %c2 = vm.const.i32 2
    %c3 = vm.const.i32 3
    %c17 = vm.const.i32 17
    %c32 = vm.const.i32 32
    %c150998019 = vm.const.i32 150998019
    %c50 = vm.const.i32 50
    %c3075 = vm.const.i32 3075
    %c16 = vm.const.i32 16
    %zero = vm.const.i32.zero
    %c553648160 = vm.const.i32 553648160
    %c1 = vm.const.i32 1
    %c4 = vm.const.i64 4
    %c-1 = vm.const.i32 -1
    %zero_0 = vm.const.i64.zero
    %c-1_1 = vm.const.i64 -1
    %_device_query_0 = vm.global.load.i32 @_device_query_0 : i32
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_executable__matmul_aie_offload_dispatch_0 = vm.global.load.ref @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    %0 = vm.call @hal.buffer_view.dim(%arg0, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %1 = vm.call @hal.buffer_view.dim(%arg0, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_0_5FD512E67BEFDEEC = vm.const.ref.rodata @_utf8_input_0_5FD512E67BEFDEEC : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg0, %_utf8_input_0_5FD512E67BEFDEEC, %c553648160, %c1, [%0, %1]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %2 = vm.mul.i64 %0, %c4 : i64
    %3 = vm.mul.i64 %2, %1 : i64
    %ref = vm.call @hal.buffer_view.buffer(%arg0) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    %ref_2 = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %ref_3 = vm.call @hal.device.allocator(%ref_2) {nosideeffects} : (!vm.ref<!hal.device>) -> !vm.ref<!hal.allocator>
    %_utf8_tensor_3C6209B4FD120BDC = vm.const.ref.rodata @_utf8_tensor_3C6209B4FD120BDC : !vm.buffer
    vm.call @hal.buffer.assert(%ref, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %3, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %4 = vm.call @hal.buffer_view.dim(%arg1, %zero) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %5 = vm.call @hal.buffer_view.dim(%arg1, %c1) {nosideeffects} : (!vm.ref<!hal.buffer_view>, i32) -> i64
    %_utf8_input_1_1DAF04E823826B1B = vm.const.ref.rodata @_utf8_input_1_1DAF04E823826B1B : !vm.buffer
    vm.call.variadic @hal.buffer_view.assert(%arg1, %_utf8_input_1_1DAF04E823826B1B, %c553648160, %c1, [%4, %5]) : (!vm.ref<!hal.buffer_view>, !vm.buffer, i32, i32, i64 ...)
    %6 = vm.mul.i64 %4, %c4 : i64
    %7 = vm.mul.i64 %6, %5 : i64
    %ref_4 = vm.call @hal.buffer_view.buffer(%arg1) {nosideeffects} : (!vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer>
    vm.call @hal.buffer.assert(%ref_4, %_utf8_tensor_3C6209B4FD120BDC, %ref_3, %7, %c16, %c3075) : (!vm.ref<!hal.buffer>, !vm.buffer, !vm.ref<!hal.allocator>, i64, i32, i32) -> ()
    %ref_5 = vm.call @hal.allocator.allocate(%ref_3, %c-1_1, %c50, %c150998019, %3) : (!vm.ref<!hal.allocator>, i64, i32, i32, i64) -> !vm.ref<!hal.buffer>
    %8 = vm.trunc.i64.i32 %0 : i64 -> i32
    %9 = vm.shr.i64.u %0, %c32 : i64
    %10 = vm.trunc.i64.i32 %9 : i64 -> i32
    %11 = vm.trunc.i64.i32 %1 : i64 -> i32
    %12 = vm.shr.i64.u %1, %c32 : i64
    %13 = vm.trunc.i64.i32 %12 : i64 -> i32
    %14 = vm.trunc.i64.i32 %4 : i64 -> i32
    %15 = vm.shr.i64.u %4, %c32 : i64
    %16 = vm.trunc.i64.i32 %15 : i64 -> i32
    %17 = vm.trunc.i64.i32 %5 : i64 -> i32
    %18 = vm.shr.i64.u %5, %c32 : i64
    %19 = vm.trunc.i64.i32 %18 : i64 -> i32
    %ref_6 = vm.call @hal.command_buffer.create(%ref_2, %c17, %c3, %zero) : (!vm.ref<!hal.device>, i32, i32, i32) -> !vm.ref<!hal.command_buffer>
    vm.cond_br %_device_query_0, ^bb1, ^bb4
  ^bb1:  // pred: ^bb0
    vm.call.variadic @hal.command_buffer.push_constants(%ref_6, %_pipeline_layout_0, %zero, [%8, %10, %11, %13, %14, %16, %17, %19]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, i32 ...)
    vm.call.variadic @hal.command_buffer.push_descriptor_set(%ref_6, %_pipeline_layout_0, %zero, [(%zero, %zero, %ref, %zero_0, %3), (%c1, %zero, %ref_4, %zero_0, %7), (%c2, %zero, %ref_5, %zero_0, %3)]) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.pipeline_layout>, i32, tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...)
    vm.call @hal.command_buffer.dispatch(%ref_6, %_executable__matmul_aie_offload_dispatch_0, %zero, %c2, %c1, %c1) : (!vm.ref<!hal.command_buffer>, !vm.ref<!hal.executable>, i32, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.execution_barrier(%ref_6, %c28, %c13, %zero) : (!vm.ref<!hal.command_buffer>, i32, i32, i32) -> ()
    vm.call @hal.command_buffer.finalize(%ref_6) : (!vm.ref<!hal.command_buffer>) -> ()
    %ref_7 = vm.call @hal.fence.create(%ref_2, %zero) : (!vm.ref<!hal.device>, i32) -> !vm.ref<!hal.fence>
    vm.call.variadic @hal.device.queue.execute(%ref_2, %c-1_1, %null, %ref_7, [%ref_6]) : (!vm.ref<!hal.device>, i64, !vm.ref<!hal.fence>, !vm.ref<!hal.fence>, !vm.ref<!hal.command_buffer> ...)
    %20 = vm.call.variadic @hal.fence.await(%c-1, [%ref_7]) : (i32, !vm.ref<!hal.fence> ...) -> i32
    vm.cond_br %20, ^bb3, ^bb2
  ^bb2:  // pred: ^bb1
    %ref_8 = vm.call.variadic @hal.buffer_view.create(%ref_5, %zero_0, %3, %c553648160, %c1, [%0, %1]) {nosideeffects} : (!vm.ref<!hal.buffer>, i64, i64, i32, i32, i64 ...) -> !vm.ref<!hal.buffer_view>
    vm.return %ref_8 : !vm.ref<!hal.buffer_view>
  ^bb3:  // pred: ^bb1
    vm.fail %20, "failed to wait on timepoint"
  ^bb4:  // pred: ^bb0
    vm.fail %c2, "device not supported in the compiled configuration"
  }
  vm.export @matmul_aie_offload attributes {iree.abi.stub, ordinal = 0 : i32}
  vm.import private @hal.ex.shared_device() -> !vm.ref<!hal.device> attributes {nosideeffects, ordinal = 0 : i32}
  vm.import private @hal.allocator.allocate(%allocator : !vm.ref<!hal.allocator>, %queue_affinity : i64, %memory_types : i32, %buffer_usage : i32, %allocation_size : i64) -> !vm.ref<!hal.buffer> attributes {minimum_version = 1 : i32, ordinal = 1 : i32}
  vm.import private @hal.buffer.assert(%buffer : !vm.ref<!hal.buffer>, %message : !vm.buffer, %allocator : !vm.ref<!hal.allocator>, %minimum_length : i64, %memory_types : i32, %buffer_usage : i32) attributes {ordinal = 2 : i32}
  vm.import private @hal.buffer_view.create(%buffer : !vm.ref<!hal.buffer>, %source_offset : i64, %source_length : i64, %element_type : i32, %encoding_type : i32, %shape : i64 ...) -> !vm.ref<!hal.buffer_view> attributes {nosideeffects, ordinal = 3 : i32}
  vm.import private @hal.buffer_view.assert(%buffer_view : !vm.ref<!hal.buffer_view>, %message : !vm.buffer, %element_type : i32, %encoding_type : i32, %shape : i64 ...) attributes {ordinal = 4 : i32}
  vm.import private @hal.buffer_view.buffer(%buffer_view : !vm.ref<!hal.buffer_view>) -> !vm.ref<!hal.buffer> attributes {nosideeffects, ordinal = 5 : i32}
  vm.import private @hal.buffer_view.dim(%buffer_view : !vm.ref<!hal.buffer_view>, %index : i32) -> i64 attributes {nosideeffects, ordinal = 6 : i32}
  vm.import private @hal.command_buffer.create(%device : !vm.ref<!hal.device>, %modes : i32, %command_categories : i32, %binding_capacity : i32) -> !vm.ref<!hal.command_buffer> attributes {ordinal = 7 : i32}
  vm.import private @hal.command_buffer.finalize(%command_buffer : !vm.ref<!hal.command_buffer>) attributes {ordinal = 8 : i32}
  vm.import private @hal.command_buffer.execution_barrier(%command_buffer : !vm.ref<!hal.command_buffer>, %source_stage_mask : i32, %target_stage_mask : i32, %flags : i32) attributes {ordinal = 9 : i32}
  vm.import private @hal.command_buffer.push_constants(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %offset : i32, %values : i32 ...) attributes {ordinal = 10 : i32}
  vm.import private @hal.command_buffer.push_descriptor_set(%command_buffer : !vm.ref<!hal.command_buffer>, %pipeline_layout : !vm.ref<!hal.pipeline_layout>, %set : i32, %bindings : tuple<i32, i32, !vm.ref<!hal.buffer>, i64, i64> ...) attributes {ordinal = 11 : i32}
  vm.import private @hal.command_buffer.dispatch(%command_buffer : !vm.ref<!hal.command_buffer>, %executable : !vm.ref<!hal.executable>, %entry_point : i32, %workgroup_x : i32, %workgroup_y : i32, %workgroup_z : i32) attributes {ordinal = 12 : i32}
  vm.import private @hal.descriptor_set_layout.create(%device : !vm.ref<!hal.device>, %flags : i32, %bindings : tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout> attributes {nosideeffects, ordinal = 13 : i32}
  vm.import private @hal.device.allocator(%device : !vm.ref<!hal.device>) -> !vm.ref<!hal.allocator> attributes {nosideeffects, ordinal = 14 : i32}
  vm.import private @hal.device.query.i64(%device : !vm.ref<!hal.device>, %category : !vm.buffer, %key : !vm.buffer) -> (i32, i64) attributes {nosideeffects, ordinal = 15 : i32}
  vm.import private @hal.device.queue.execute(%device : !vm.ref<!hal.device>, %queue_affinity : i64, %wait_fence : !vm.ref<!hal.fence>, %signal_fence : !vm.ref<!hal.fence>, %command_buffers : !vm.ref<!hal.command_buffer> ...) attributes {ordinal = 16 : i32}
  vm.import private @hal.executable.create(%device : !vm.ref<!hal.device>, %executable_format : !vm.buffer, %executable_data : !vm.buffer, %constants : !vm.buffer, %pipeline_layouts : !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable> attributes {nosideeffects, ordinal = 17 : i32}
  vm.import private @hal.fence.create(%device : !vm.ref<!hal.device>, %flags : i32) -> !vm.ref<!hal.fence> attributes {ordinal = 18 : i32}
  vm.import private @hal.fence.await(%timeout_millis : i32, %fences : !vm.ref<!hal.fence> ...) -> i32 attributes {ordinal = 19 : i32, vm.yield}
  vm.import private @hal.pipeline_layout.create(%device : !vm.ref<!hal.device>, %push_constants : i32, %set_layouts : !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout> attributes {nosideeffects, ordinal = 20 : i32}
  vm.export @__init attributes {ordinal = 1 : i32}
  vm.func private @__init() attributes {ordinal = 1 : i32} {
    %null = vm.const.ref.zero : !vm.ref<!hal.executable>
    %null_0 = vm.const.ref.zero : !vm.buffer
    %c8 = vm.const.i32 8
    %c2 = vm.const.i32 2
    %c7 = vm.const.i32 7
    %zero = vm.const.i32.zero
    %c1 = vm.const.i32 1
    %ref = vm.call @hal.ex.shared_device() {nosideeffects} : () -> !vm.ref<!hal.device>
    %_utf8_hal_executable_format_EAB228F999C2D3A1 = vm.const.ref.rodata @_utf8_hal_executable_format_EAB228F999C2D3A1 : !vm.buffer
    %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 = vm.const.ref.rodata @_utf8_embedded_elf_x86_64_9FD8733DA4A6F228 : !vm.buffer
    %0:2 = vm.call @hal.device.query.i64(%ref, %_utf8_hal_executable_format_EAB228F999C2D3A1, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer) -> (i32, i64)
    %1 = vm.trunc.i64.i32 %0#1 : i64 -> i32
    %2 = vm.and.i32 %1, %c1 : i32
    %3 = vm.select.i32 %0#0, %2, %zero : i32
    %ref_1 = vm.call.variadic @hal.descriptor_set_layout.create(%ref, %zero, [(%zero, %c7, %c1), (%c1, %c7, %c1), (%c2, %c7, %zero)]) {nosideeffects} : (!vm.ref<!hal.device>, i32, tuple<i32, i32, i32> ...) -> !vm.ref<!hal.descriptor_set_layout>
    %ref_2 = vm.call.variadic @hal.pipeline_layout.create(%ref, %c8, [%ref_1]) {nosideeffects} : (!vm.ref<!hal.device>, i32, !vm.ref<!hal.descriptor_set_layout> ...) -> !vm.ref<!hal.pipeline_layout>
    vm.global.store.i32 %3, @_device_query_0 : i32
    vm.global.store.ref %ref_2, @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    vm.cond_br %3, ^bb1, ^bb2
  ^bb1:  // pred: ^bb0
    %_pipeline_layout_0 = vm.global.load.ref @_pipeline_layout_0 : !vm.ref<!hal.pipeline_layout>
    %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 = vm.const.ref.rodata @_matmul_aie_offload_dispatch_0_embedded_elf_x86_64 : !vm.buffer
    %ref_3 = vm.call.variadic @hal.executable.create(%ref, %_utf8_embedded_elf_x86_64_9FD8733DA4A6F228, %_matmul_aie_offload_dispatch_0_embedded_elf_x86_64, %null_0, [%_pipeline_layout_0]) {nosideeffects} : (!vm.ref<!hal.device>, !vm.buffer, !vm.buffer, !vm.buffer, !vm.ref<!hal.pipeline_layout> ...) -> !vm.ref<!hal.executable>
    vm.br ^bb3(%ref_3 : !vm.ref<!hal.executable>)
  ^bb2:  // pred: ^bb0
    vm.br ^bb3(%null : !vm.ref<!hal.executable>)
  ^bb3(%4: !vm.ref<!hal.executable>):  // 2 preds: ^bb1, ^bb2
    vm.global.store.ref %4, @_executable__matmul_aie_offload_dispatch_0 : !vm.ref<!hal.executable>
    vm.return
  }
}

